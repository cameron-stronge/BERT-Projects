{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"running_experiments_optimizing_model_structure.ipynb","provenance":[],"mount_file_id":"1Sn0PDhEKjkQr1mc92qzjENYXhDNGwFQo","authorship_tag":"ABX9TyNywcuV2L+uvoZYoGAnbtw0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"40b35177a66d443a9436f53adb6ba85d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_d2692e4031fa4baab1c3dc2c744aa84b","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_5d602471fdbe426f9ffff0afc1a9d94e","IPY_MODEL_cdc26a4f3b7c4cfeadd91d9d0d4073cf","IPY_MODEL_d1b5c8ee535b494baadcd2cc823c81a9"]}},"d2692e4031fa4baab1c3dc2c744aa84b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5d602471fdbe426f9ffff0afc1a9d94e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_dcf1159663c1490391f8f70d7e814d37","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c592d10f5f114c3b8956bdf16e8618d0"}},"cdc26a4f3b7c4cfeadd91d9d0d4073cf":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_b0206816dca04698b821bb5fa33d5888","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":480,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":480,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_828018f93c5a45d49aaa57b425fc0152"}},"d1b5c8ee535b494baadcd2cc823c81a9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_0ce244702c654c4dbcd56dce691902be","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 480/480 [00:00&lt;00:00, 12.4kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_65d110011f8e4fa289e8f328a409ccd7"}},"dcf1159663c1490391f8f70d7e814d37":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c592d10f5f114c3b8956bdf16e8618d0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b0206816dca04698b821bb5fa33d5888":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"828018f93c5a45d49aaa57b425fc0152":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0ce244702c654c4dbcd56dce691902be":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"65d110011f8e4fa289e8f328a409ccd7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5865448e12f342428f1db5cffea4e802":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_78088dd0a245458d8f757259593ffd31","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_47a94615cd4245fd8fe30b7239c15a1f","IPY_MODEL_791d6a2528924273a359ca0b440e7b4c","IPY_MODEL_e8fee998920745b5bad1a51fa8efc89b"]}},"78088dd0a245458d8f757259593ffd31":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"47a94615cd4245fd8fe30b7239c15a1f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_94895c0297f44cb8b85eab505a8d56f2","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_692f2b7bd8d441488a879cf749fbb63d"}},"791d6a2528924273a359ca0b440e7b4c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_dfbec7d114f54f41ab966f0d086a5999","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":898823,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":898823,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_09f4d86992ad4e00b11ee540d1ded979"}},"e8fee998920745b5bad1a51fa8efc89b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_87bd9c16125f433d847961194de9a514","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 899k/899k [00:01&lt;00:00, 1.28MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_29929e23961e40b0b69de20915dc16e1"}},"94895c0297f44cb8b85eab505a8d56f2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"692f2b7bd8d441488a879cf749fbb63d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"dfbec7d114f54f41ab966f0d086a5999":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"09f4d86992ad4e00b11ee540d1ded979":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"87bd9c16125f433d847961194de9a514":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"29929e23961e40b0b69de20915dc16e1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9fa399f436ee4f699c525c82956b5877":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_5b980274f44544d9977a898a77b99409","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_32b65c13765540fb8902c0c2323c77b9","IPY_MODEL_3b8afbfcc8004dab922f5f4855acfb2a","IPY_MODEL_d8321b9cad2144d48af6f3d350709470"]}},"5b980274f44544d9977a898a77b99409":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"32b65c13765540fb8902c0c2323c77b9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_3ab87334e1c843af81388699092f90d4","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2125a571ae6f456fa91ca15c9a041cf0"}},"3b8afbfcc8004dab922f5f4855acfb2a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_a52a4a0043504b51a195c9bb1a45e854","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":456318,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":456318,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_74de4fac18b54f78924715fec3c5fb2c"}},"d8321b9cad2144d48af6f3d350709470":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_fb7b00a3de354ba7b97780bcc4f6c6af","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 456k/456k [00:00&lt;00:00, 702kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ba9ff7eb2cc3449ab0a68e2bdf4964f3"}},"3ab87334e1c843af81388699092f90d4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"2125a571ae6f456fa91ca15c9a041cf0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a52a4a0043504b51a195c9bb1a45e854":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"74de4fac18b54f78924715fec3c5fb2c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fb7b00a3de354ba7b97780bcc4f6c6af":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"ba9ff7eb2cc3449ab0a68e2bdf4964f3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ce85f3ec51f94affb5a7ab691b8c879e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_5db334475c324668b99f6dd84be824f0","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_97dab9355cc54bf09e0aba318c5b78b8","IPY_MODEL_e472009d71d84021b685fc3891e675ea","IPY_MODEL_58b9e95fc6504889afc3a4f6122dbd5a"]}},"5db334475c324668b99f6dd84be824f0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"97dab9355cc54bf09e0aba318c5b78b8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ec659763b5f547eeaa003884eb929139","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ad4a8df5e088411683f524c79b5fa869"}},"e472009d71d84021b685fc3891e675ea":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_64b1e57c597f4ba19c210c22fd7312eb","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1355863,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1355863,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0708bc82af814b32a93597178b4256f8"}},"58b9e95fc6504889afc3a4f6122dbd5a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_37cba868b4ac4731b77377f563e45155","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.36M/1.36M [00:01&lt;00:00, 1.09MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_46843e008f824c1e882e8dc2b3262a1c"}},"ec659763b5f547eeaa003884eb929139":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"ad4a8df5e088411683f524c79b5fa869":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"64b1e57c597f4ba19c210c22fd7312eb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"0708bc82af814b32a93597178b4256f8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"37cba868b4ac4731b77377f563e45155":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"46843e008f824c1e882e8dc2b3262a1c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b8cd72d96c9b4900b42cbcb612bd1d9a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_15200f54de1c452a9d3c3ec17aeaab48","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_93d5402880064b338cc7268e20d12e16","IPY_MODEL_4fa2657f2e264c83861e2e74bc26b211","IPY_MODEL_785f6c2ece1f421ebc938dd915b4b5a5"]}},"15200f54de1c452a9d3c3ec17aeaab48":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"93d5402880064b338cc7268e20d12e16":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a93d2bfc9a5a48dc83fd8c0b1b289709","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4918cfaeb1b742f382b37d71e2b7cb6e"}},"4fa2657f2e264c83861e2e74bc26b211":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_8ea5c37d4af54a56b9e20fc0a5b0c9bf","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1057,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1057,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7c872722b330486a9c4c12460ca8ba98"}},"785f6c2ece1f421ebc938dd915b4b5a5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_83136f24e1ee4bfc91830fe16e142323","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1057/1057 [00:02&lt;00:00, 491.05ex/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d626e65710cf4eb7a29ee3ebeadd882a"}},"a93d2bfc9a5a48dc83fd8c0b1b289709":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"4918cfaeb1b742f382b37d71e2b7cb6e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8ea5c37d4af54a56b9e20fc0a5b0c9bf":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"7c872722b330486a9c4c12460ca8ba98":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"83136f24e1ee4bfc91830fe16e142323":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d626e65710cf4eb7a29ee3ebeadd882a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f0c50f2d98ef44fd8f47ad1ee216e9fb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_b1c0458bf30b476e90ff2e7540d96d03","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_8a4bdf94eca74bdb8030095bb4f9dd7a","IPY_MODEL_b0ef84a441f64fb88a0b4623ada96cb9","IPY_MODEL_0ab039ca418a481bb60382baef78cafa"]}},"b1c0458bf30b476e90ff2e7540d96d03":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8a4bdf94eca74bdb8030095bb4f9dd7a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e20dfddbfe8a4cf8910cae02fdd2a0bf","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_cf6f624783284fa1b980266c5059e647"}},"b0ef84a441f64fb88a0b4623ada96cb9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_34568dae32ed4211ac08df4d52019167","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":97,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":97,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_dbe53e01fadd4996a75a9806b1dd443b"}},"0ab039ca418a481bb60382baef78cafa":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f07a04b03afc49a8b23cc001d5d6ac9d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 97/97 [00:00&lt;00:00, 425.07ex/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2e6d5619c9124216b5908fe82c23245d"}},"e20dfddbfe8a4cf8910cae02fdd2a0bf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"cf6f624783284fa1b980266c5059e647":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"34568dae32ed4211ac08df4d52019167":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"dbe53e01fadd4996a75a9806b1dd443b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f07a04b03afc49a8b23cc001d5d6ac9d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"2e6d5619c9124216b5908fe82c23245d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bb7cec071edf4913954cef1118814cbb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_3cf855c95af548ca8f368b5fe0d685dc","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_c83d216e731b4f01885db4443b234855","IPY_MODEL_20b52327a99c461bafdc26c9230329b0","IPY_MODEL_6b92f1f88f5b43b18ce491c8f153ed9f"]}},"3cf855c95af548ca8f368b5fe0d685dc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c83d216e731b4f01885db4443b234855":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_3d30275a46a84f3db68daacfa835bab1","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_37399e206d9b4d7e9f9b5af66aa8315e"}},"20b52327a99c461bafdc26c9230329b0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_a451631eaa0c4ad9ae655b83047781bb","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":79,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":79,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b5de90aee859493f89362970c95595d8"}},"6b92f1f88f5b43b18ce491c8f153ed9f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_1bfc0f3589fd4188885e2a5b50ff94bd","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 79/79 [00:00&lt;00:00, 326.96ex/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_afb99fb454294229bec06fd37765b23d"}},"3d30275a46a84f3db68daacfa835bab1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"37399e206d9b4d7e9f9b5af66aa8315e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a451631eaa0c4ad9ae655b83047781bb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"b5de90aee859493f89362970c95595d8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1bfc0f3589fd4188885e2a5b50ff94bd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"afb99fb454294229bec06fd37765b23d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"786614b932884444b92ff2abf574e33a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_e1f0c94cb32c429a84c72ad4fa4061e9","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_24bbee5ef64943d8a13b79538de4b52d","IPY_MODEL_66ad0c517fef4084b24bb73015d55285","IPY_MODEL_1a4b4341b8284e49a9bc38487b16d263"]}},"e1f0c94cb32c429a84c72ad4fa4061e9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"24bbee5ef64943d8a13b79538de4b52d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_eb8394b396284c1b8462c5dc12ecd07d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_91ba6c58a9ad45bcbab3f6d5ad41e37a"}},"66ad0c517fef4084b24bb73015d55285":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_7549fc5e95524d4397678b11370cb812","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1057,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1057,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f9e9985ceaf44fcabe04938b23663194"}},"1a4b4341b8284e49a9bc38487b16d263":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_991fd23e01b54b1784251afd899ed3ba","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1057/1057 [00:01&lt;00:00, 568.85ex/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6941bbc9b59f43369ad6f11763fb9195"}},"eb8394b396284c1b8462c5dc12ecd07d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"91ba6c58a9ad45bcbab3f6d5ad41e37a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7549fc5e95524d4397678b11370cb812":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"f9e9985ceaf44fcabe04938b23663194":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"991fd23e01b54b1784251afd899ed3ba":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"6941bbc9b59f43369ad6f11763fb9195":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"248dfd465f7741c5b23d458d588739fd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_11d0801b94ca47688ab328b9d893f897","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_9c426f6ad0c0451bb013a85edf70d1b0","IPY_MODEL_30f4657943d9443b86a28c3174b67e80","IPY_MODEL_08acde948b8549a986a40e895c45cad1"]}},"11d0801b94ca47688ab328b9d893f897":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9c426f6ad0c0451bb013a85edf70d1b0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_986e4fcf66774e0c9d630a85012c6991","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d2d5d284aeee4020a21e987871bb6fa0"}},"30f4657943d9443b86a28c3174b67e80":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_5676ca474a1442539e481e60583ecb3e","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":97,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":97,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_455f671cc12f4542b29c9932d47ec416"}},"08acde948b8549a986a40e895c45cad1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a9c36cc5d80b40d79da53950644ca3fe","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 97/97 [00:00&lt;00:00, 378.41ex/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_667bcb35ed57488187d19ccd4ba71126"}},"986e4fcf66774e0c9d630a85012c6991":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d2d5d284aeee4020a21e987871bb6fa0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5676ca474a1442539e481e60583ecb3e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"455f671cc12f4542b29c9932d47ec416":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a9c36cc5d80b40d79da53950644ca3fe":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"667bcb35ed57488187d19ccd4ba71126":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8a191f9febb9448db24ce8785a4fd568":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_3f4db3f005b940dba7d0d3605e339def","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_921fbc28a04044b88c832334e9f7d45d","IPY_MODEL_024b6715b69342d5afd9d63e5827bd26","IPY_MODEL_00b776207c024052b9b5c042ad005581"]}},"3f4db3f005b940dba7d0d3605e339def":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"921fbc28a04044b88c832334e9f7d45d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_c4a354cd6f474ea193fdb54e0050e9b6","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_aeabd7d3b85944ada45fd60a35c4e07e"}},"024b6715b69342d5afd9d63e5827bd26":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_568639a2cb3a4e47bc69a23f27cf6c8f","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":79,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":79,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_801a4a2dd1b648fa8e3011fd26f0642e"}},"00b776207c024052b9b5c042ad005581":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_2f1305dbbbfb44cc95c85644ca47e7d6","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 79/79 [00:00&lt;00:00, 427.89ex/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9bcbcca52c764319b2116ab7c7c3fb04"}},"c4a354cd6f474ea193fdb54e0050e9b6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"aeabd7d3b85944ada45fd60a35c4e07e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"568639a2cb3a4e47bc69a23f27cf6c8f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"801a4a2dd1b648fa8e3011fd26f0642e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2f1305dbbbfb44cc95c85644ca47e7d6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"9bcbcca52c764319b2116ab7c7c3fb04":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d91d0c2485b44ff89640196049c0eb8f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_656979f70c49405eb300f3e678dacea5","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_fd24744743694db5a704e8d7544a8961","IPY_MODEL_f8ba7f62eed4434ca8a958e708289679","IPY_MODEL_f427a198b4f345dd952f415ac65cb636"]}},"656979f70c49405eb300f3e678dacea5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fd24744743694db5a704e8d7544a8961":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f5b60c454ee54baca18caba39e85914c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: ","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_349f8b69b5e24849852a77bbb66ad420"}},"f8ba7f62eed4434ca8a958e708289679":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_3e1cca387fa44100af1a5860e96e21dc","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":2603,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":2603,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_095729e3eeae48bf921ae67b3063475e"}},"f427a198b4f345dd952f415ac65cb636":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ea7ee4c779db4089808534e3f857f114","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 9.52k/? [00:00&lt;00:00, 262kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0eba576651f04c8e8f3dfadfb2dcb331"}},"f5b60c454ee54baca18caba39e85914c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"349f8b69b5e24849852a77bbb66ad420":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3e1cca387fa44100af1a5860e96e21dc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"095729e3eeae48bf921ae67b3063475e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ea7ee4c779db4089808534e3f857f114":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"0eba576651f04c8e8f3dfadfb2dcb331":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"72da9a1718334039916cc85c53ce99c0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_21985842bd2a4064b3eaf44ffabfa7d9","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_b9567fe90bb44292a8702291d47d0c84","IPY_MODEL_ac6841bee5514b8ca51d81e1ba8a28a9","IPY_MODEL_393b50ea8323421fb8ad6db78b2e003b"]}},"21985842bd2a4064b3eaf44ffabfa7d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b9567fe90bb44292a8702291d47d0c84":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_485b66cae2b641a7b0e1fd7ac3396d9e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: ","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e83c9ff0257447219d4fdf899cab87b4"}},"ac6841bee5514b8ca51d81e1ba8a28a9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_019b14c73bcf46efbef4ae3de09d4a68","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1781,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1781,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_327c1d2a4b384725abda45e6dfa2bbe3"}},"393b50ea8323421fb8ad6db78b2e003b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_0744d50224654d39b0a8520ce01128d7","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 4.18k/? [00:00&lt;00:00, 96.4kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_20fe145e8c744525bcb9766c3b9ff050"}},"485b66cae2b641a7b0e1fd7ac3396d9e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e83c9ff0257447219d4fdf899cab87b4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"019b14c73bcf46efbef4ae3de09d4a68":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"327c1d2a4b384725abda45e6dfa2bbe3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0744d50224654d39b0a8520ce01128d7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"20fe145e8c744525bcb9766c3b9ff050":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"294c7eb15a874dfaa57c31223f5c0a51":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_5285d23f92dc4e36abf1d7e46995ad73","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_887ef6e7b2944dc8b1c8fa6f056e6a4f","IPY_MODEL_060542ef3f0941acb768c08f9ef6de02","IPY_MODEL_a5feeb841b9f48a4aca6c56a58b3237a"]}},"5285d23f92dc4e36abf1d7e46995ad73":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"887ef6e7b2944dc8b1c8fa6f056e6a4f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b05731da36bf413b83cbfb780b60673c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: ","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4b8f51a61fc14694824723c1f14fbe01"}},"060542ef3f0941acb768c08f9ef6de02":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_c1c9e0f1fa384171a7876405ba76fd14","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":649539,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":649539,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_57797ec82161461da0b3fe3137f9d8fe"}},"a5feeb841b9f48a4aca6c56a58b3237a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_89b399fa432144e3ba7a026222bcaccd","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 3.28M/? [00:00&lt;00:00, 25.6MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9003f28d56f3422ca43ba8d390b3a76c"}},"b05731da36bf413b83cbfb780b60673c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"4b8f51a61fc14694824723c1f14fbe01":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c1c9e0f1fa384171a7876405ba76fd14":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"57797ec82161461da0b3fe3137f9d8fe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"89b399fa432144e3ba7a026222bcaccd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"9003f28d56f3422ca43ba8d390b3a76c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"63064fef852948c78bc2b01b8233d119":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_05cb37c123814f91b2cdb42f6bce833e","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_ec701dc7bb6f41ffb0e8657e766e535c","IPY_MODEL_29d0ae708c98480e800021c329cb7585","IPY_MODEL_c9cc509fef4d4b85b97edcab1191e88a"]}},"05cb37c123814f91b2cdb42f6bce833e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ec701dc7bb6f41ffb0e8657e766e535c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_c731024c38e3402f9a00b4a5f4de8a8e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: ","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9587a6c349234e7d9873f77d475f5248"}},"29d0ae708c98480e800021c329cb7585":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_720d4861b1984f8397eadb12abb4c29b","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":162714,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":162714,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_519ad735190b4361bf6d2d3762b4e77d"}},"c9cc509fef4d4b85b97edcab1191e88a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ba394871df534be69eaf9fa3228881f0","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 827k/? [00:00&lt;00:00, 12.3MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_602d6e617a234d74b50dc6eaafb3aaa5"}},"c731024c38e3402f9a00b4a5f4de8a8e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"9587a6c349234e7d9873f77d475f5248":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"720d4861b1984f8397eadb12abb4c29b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"519ad735190b4361bf6d2d3762b4e77d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ba394871df534be69eaf9fa3228881f0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"602d6e617a234d74b50dc6eaafb3aaa5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1f19d2b6d6eb46978ac822072b9b5a02":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_06177686049c4d7fbc531b086e788bc0","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_fed4e6d4ceee4b1589faf45165b72ae8","IPY_MODEL_2cd8e668001b4baeb60ea4d581b496db","IPY_MODEL_bab4907c1c2a449e96eea3003d308cb3"]}},"06177686049c4d7fbc531b086e788bc0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fed4e6d4ceee4b1589faf45165b72ae8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_bbb5349a16d2424ea0757a286756f14a","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: ","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7cf14d6c1b154288a099741cb3ac7afa"}},"2cd8e668001b4baeb60ea4d581b496db":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_11c906426b884c34953b74fe7c18e7ab","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":145897,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":145897,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1d8ed71c3f24455580efe2be742ca5e3"}},"bab4907c1c2a449e96eea3003d308cb3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_c5ecdcd1cb9240f48c81d1c84e724dbd","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 748k/? [00:00&lt;00:00, 11.1MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ff01f09b89cc42e082580ce8256f1d98"}},"bbb5349a16d2424ea0757a286756f14a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"7cf14d6c1b154288a099741cb3ac7afa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"11c906426b884c34953b74fe7c18e7ab":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"1d8ed71c3f24455580efe2be742ca5e3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c5ecdcd1cb9240f48c81d1c84e724dbd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"ff01f09b89cc42e082580ce8256f1d98":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d2a3cfa7e6b946fba5e2597d47b977b7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_da03ab78025449eea007d202e720825c","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_4490951fea0b49a5be7ea319460046b1","IPY_MODEL_59abb0c5445b4d98b23fd401b0f82cd2","IPY_MODEL_f5d49bba992542a0a389202a97f453b3"]}},"da03ab78025449eea007d202e720825c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4490951fea0b49a5be7ea319460046b1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_34622185c7f84566bc3babbc63ee71eb","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_bc9442b3b25c4a4e9faaed99290c7243"}},"59abb0c5445b4d98b23fd401b0f82cd2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_8b110514ba054675bddb4defd1254e2e","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c461b6d0e6dc415bbb9c28a1e3df54b6"}},"f5d49bba992542a0a389202a97f453b3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_fd5f0366560041038aba2e4665b3e1c0","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 13873/0 [00:02&lt;00:00, 4916.66 examples/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e6190a07bf11461cbe5f87339b3b8756"}},"34622185c7f84566bc3babbc63ee71eb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"bc9442b3b25c4a4e9faaed99290c7243":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8b110514ba054675bddb4defd1254e2e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"c461b6d0e6dc415bbb9c28a1e3df54b6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":"20px","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fd5f0366560041038aba2e4665b3e1c0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e6190a07bf11461cbe5f87339b3b8756":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"821b7d4ef03c47f4907438086f7a21e0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_63b8cc3014c94b75974af76b09a72285","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_5fa00e0e7fc7493aa2af029ff3de90f7","IPY_MODEL_67329e1a1fe346d8bfc40463ec33c046","IPY_MODEL_cd66e250cb004073bd1687d98fde64d1"]}},"63b8cc3014c94b75974af76b09a72285":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5fa00e0e7fc7493aa2af029ff3de90f7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_86de8f811bb5414d9ffcad01bc190fb9","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_58670e46904e409d8a5b2da30767c8bc"}},"67329e1a1fe346d8bfc40463ec33c046":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_4be71ee8468c4fb0a47247fdfa31ddc9","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_cf325b678c4c47339fd292284cc42279"}},"cd66e250cb004073bd1687d98fde64d1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ef6751e39d09438eb0da732af1cd8ada","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 3250/0 [00:00&lt;00:00, 3849.76 examples/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_87d264e2a49543c2a25e069c20d33c71"}},"86de8f811bb5414d9ffcad01bc190fb9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"58670e46904e409d8a5b2da30767c8bc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4be71ee8468c4fb0a47247fdfa31ddc9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"cf325b678c4c47339fd292284cc42279":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":"20px","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ef6751e39d09438eb0da732af1cd8ada":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"87d264e2a49543c2a25e069c20d33c71":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0d9bf8d94f4946fda0afddcc2801e876":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_c33b2da511fb451ab580f4a57e86e8e2","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_41dd81e5558241e3b12bc2fe4a2a8d70","IPY_MODEL_7356d63ec9a246808412b1185132fe26","IPY_MODEL_fd9e7991d0ac498e8611719452d83836"]}},"c33b2da511fb451ab580f4a57e86e8e2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"41dd81e5558241e3b12bc2fe4a2a8d70":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_c52d3dbdff0f4a14acab2c409adb8aef","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_86b85ee96a7f4bc59f994e39e66fbd35"}},"7356d63ec9a246808412b1185132fe26":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_693ca78a770c49dab03c1ef024bcb65c","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"info","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3e8cc1872d15415bab7fdaee7da1d2f7"}},"fd9e7991d0ac498e8611719452d83836":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_27dc599456d44401b0a29a8f3031529d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 3176/0 [00:00&lt;00:00, 5867.17 examples/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_21f461b9e17b4033a0e05a0637db4758"}},"c52d3dbdff0f4a14acab2c409adb8aef":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"86b85ee96a7f4bc59f994e39e66fbd35":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"693ca78a770c49dab03c1ef024bcb65c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"3e8cc1872d15415bab7fdaee7da1d2f7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":"20px","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"27dc599456d44401b0a29a8f3031529d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"21f461b9e17b4033a0e05a0637db4758":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a9a813020aba4146adcb255e49ab8c0e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_b3c6199422a04d48b2677d31f3cce937","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_b22e173830c04973bd790152375cb82b","IPY_MODEL_29d13c0fb2144352ac9c871b57d738fa","IPY_MODEL_16d0a5d52ac64b43bc875f038d918dc2"]}},"b3c6199422a04d48b2677d31f3cce937":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b22e173830c04973bd790152375cb82b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_75daa41cd912419ca73c6790024ac1c1","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_46e91dc92cdc42f5addddb2320975e1a"}},"29d13c0fb2144352ac9c871b57d738fa":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_60fea8d061ee4f4ba800be7b387df98e","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":14041,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":14041,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0719e23f8e8049268638d8462842c3c9"}},"16d0a5d52ac64b43bc875f038d918dc2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a46207e015a140a5b21e6ba1606e3ff5","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 14041/14041 [00:02&lt;00:00, 5525.66ex/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7d6f01762b764f919b97f0e7c46ac5df"}},"75daa41cd912419ca73c6790024ac1c1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"46e91dc92cdc42f5addddb2320975e1a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"60fea8d061ee4f4ba800be7b387df98e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"0719e23f8e8049268638d8462842c3c9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a46207e015a140a5b21e6ba1606e3ff5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"7d6f01762b764f919b97f0e7c46ac5df":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"69a241273b73402d953e9f70428f737f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_050c92fe2bdf42c4a512a52debfb4107","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_7d42bb8c10754deab2e8f43b56514485","IPY_MODEL_2c4cef4d44cf4bee814fdcf6fd443c22","IPY_MODEL_8150f61e3c66459887e62b93321d9aa8"]}},"050c92fe2bdf42c4a512a52debfb4107":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7d42bb8c10754deab2e8f43b56514485":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b0d4653b79b54fe19b15718851be4676","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5e6c9479cf95452e8a54e07038f5406c"}},"2c4cef4d44cf4bee814fdcf6fd443c22":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_5dbc4ebf6c784e10b677a288216ceb49","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":3250,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":3250,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ec910867ba3144c4ab43086afd7e0283"}},"8150f61e3c66459887e62b93321d9aa8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_0ddf4b87615741bebfe2d008ef0e900b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 3250/3250 [00:00&lt;00:00, 5214.28ex/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6cd5c95cae4544b39860e6d86c441658"}},"b0d4653b79b54fe19b15718851be4676":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"5e6c9479cf95452e8a54e07038f5406c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5dbc4ebf6c784e10b677a288216ceb49":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"ec910867ba3144c4ab43086afd7e0283":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0ddf4b87615741bebfe2d008ef0e900b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"6cd5c95cae4544b39860e6d86c441658":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8caa1ee05d9a41a6b29b9bf4f158f392":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_ee3c7dd2d96e4504893680e514910279","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_6a6969a5523e4387881465b810d7ef5c","IPY_MODEL_c3d2988930db4d139afb4c0c812ef57d","IPY_MODEL_0f4ab175408844a58b37e23c2c2ff6d2"]}},"ee3c7dd2d96e4504893680e514910279":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6a6969a5523e4387881465b810d7ef5c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_0dd92c2dddf34788816de2704a495416","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9d13b2e865b34e5197ca27dc017a6cc5"}},"c3d2988930db4d139afb4c0c812ef57d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_b34ddc02ef314f4d88055523ca56ea47","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":3453,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":3453,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_574e51a5b117401faa260fdd5a0bdeed"}},"0f4ab175408844a58b37e23c2c2ff6d2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_de273dfcb060438e99c70f113d885b0f","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 3453/3453 [00:00&lt;00:00, 5516.95ex/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_20c791434a894b8d8fbc7c7b366f541a"}},"0dd92c2dddf34788816de2704a495416":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"9d13b2e865b34e5197ca27dc017a6cc5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b34ddc02ef314f4d88055523ca56ea47":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"574e51a5b117401faa260fdd5a0bdeed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"de273dfcb060438e99c70f113d885b0f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"20c791434a894b8d8fbc7c7b366f541a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bcc0334547704a8b93fd16c712dd9fec":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_ae85a2d5ea9f402ba0021e48842e72d3","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_812063e969d54a4ca11a3140b5a0a4cf","IPY_MODEL_76afb4a3000d4685b4f9c5c6a22606f1","IPY_MODEL_9a8785e65d1e4eb0aa5c020b58231282"]}},"ae85a2d5ea9f402ba0021e48842e72d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"812063e969d54a4ca11a3140b5a0a4cf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_41872043cdb645a7bdb3abad59e8f470","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b86952164f5841319c2eedaf6c7b3dcd"}},"76afb4a3000d4685b4f9c5c6a22606f1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_586dba559f624b29932af8c9810385fe","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1057,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1057,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a2c18290416f4fcda20c54b26e4158ed"}},"9a8785e65d1e4eb0aa5c020b58231282":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e48a7c0acb6847a194f3117b3552523d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1057/1057 [00:01&lt;00:00, 665.12ex/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_540e0fa5354a40c389f56b5f2697c814"}},"41872043cdb645a7bdb3abad59e8f470":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"b86952164f5841319c2eedaf6c7b3dcd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"586dba559f624b29932af8c9810385fe":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"a2c18290416f4fcda20c54b26e4158ed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e48a7c0acb6847a194f3117b3552523d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"540e0fa5354a40c389f56b5f2697c814":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a26b312ac6174c4dadd3db55974a7e38":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_df773a3b16724a36bc9e80e842dbbb8c","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_608ee24288c2464abece2bd59f88d457","IPY_MODEL_565df88bb4cd49c98e9d94ee8c69ea72","IPY_MODEL_0b2fa1f8e0ba47e2bc2bfc4701970a99"]}},"df773a3b16724a36bc9e80e842dbbb8c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"608ee24288c2464abece2bd59f88d457":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b03c4c2c226f494db1ff192082db4424","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_572f3dae58db4109b0750ac824da06ea"}},"565df88bb4cd49c98e9d94ee8c69ea72":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_e3ca63b79327496eb53ddecffec19f95","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":266,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":266,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_21c93b51e6d1455e8637203377e5d7a2"}},"0b2fa1f8e0ba47e2bc2bfc4701970a99":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_dca6a6c2ac6240aa86c37d08ad1e2a5a","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 266/266 [00:00&lt;00:00, 667.91ex/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_82320c694fe044ce83d6c4fb6ec7c328"}},"b03c4c2c226f494db1ff192082db4424":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"572f3dae58db4109b0750ac824da06ea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e3ca63b79327496eb53ddecffec19f95":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"21c93b51e6d1455e8637203377e5d7a2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"dca6a6c2ac6240aa86c37d08ad1e2a5a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"82320c694fe044ce83d6c4fb6ec7c328":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f0a346f5440a4b0d86e0fca88da246de":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_69ee0dd06974427a939d871133b2c4bc","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_7b1405f49b014efdb01e9d14d3707552","IPY_MODEL_e111590e5ed44a3d9a94808ea4ec874a","IPY_MODEL_a31deeff91334da2b39972c1edbc321b"]}},"69ee0dd06974427a939d871133b2c4bc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7b1405f49b014efdb01e9d14d3707552":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_34766e5cac6f4c0f8e94afc116af5889","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_05417dbafbc54add87217c76479a93c7"}},"e111590e5ed44a3d9a94808ea4ec874a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_43490c2870d3444aa5b0daab264f2c0b","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":243,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":243,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_63ddc3816d9c4c638f4838d7cbf1cb34"}},"a31deeff91334da2b39972c1edbc321b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_6e40518a230f4a34a21f153b1421b4c8","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 243/243 [00:00&lt;00:00, 667.36ex/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_96c749b0559b4765bfd3b3de7f8da526"}},"34766e5cac6f4c0f8e94afc116af5889":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"05417dbafbc54add87217c76479a93c7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"43490c2870d3444aa5b0daab264f2c0b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"63ddc3816d9c4c638f4838d7cbf1cb34":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"6e40518a230f4a34a21f153b1421b4c8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"96c749b0559b4765bfd3b3de7f8da526":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4493fdff8b3f405d95c41c9c26d22241":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_79f8beaa7a504068a38bb3db446c1863","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_113c163eb5b6494db7be2f0863c26ef3","IPY_MODEL_f7f6cd04fa0845858e365a9e5e57c798","IPY_MODEL_2f86a9952b8e4aa985c16b2f917324f4"]}},"79f8beaa7a504068a38bb3db446c1863":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"113c163eb5b6494db7be2f0863c26ef3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b1db05b46239464bb43c1d914deccc09","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_650cc1502312456daa4ec4a6a968148a"}},"f7f6cd04fa0845858e365a9e5e57c798":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_ee2a0327dcb54ea0b883c8e197b5a035","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1057,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1057,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_56aea1c87fa74454a0463cb56c192ca1"}},"2f86a9952b8e4aa985c16b2f917324f4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a7ebd5dcebe84772ae90de92c67c47de","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1057/1057 [00:01&lt;00:00, 673.15ex/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_02634723850e430f85373624c7bd46fc"}},"b1db05b46239464bb43c1d914deccc09":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"650cc1502312456daa4ec4a6a968148a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ee2a0327dcb54ea0b883c8e197b5a035":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"56aea1c87fa74454a0463cb56c192ca1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a7ebd5dcebe84772ae90de92c67c47de":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"02634723850e430f85373624c7bd46fc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1a1671d3c45e47778d5f1d96c31b1de7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_1c27e5ebe104420880c0bd5b420de29e","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_8ac4da8ec8e24592980a13985227f94a","IPY_MODEL_5e48ffa6af8349539fd580f9f95d2591","IPY_MODEL_ac47f949cc67488f9dfcdb30bb80d205"]}},"1c27e5ebe104420880c0bd5b420de29e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8ac4da8ec8e24592980a13985227f94a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ed69e631d062420f8870206431ee83a2","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_fe2fec34247e43aca326e778418e98a4"}},"5e48ffa6af8349539fd580f9f95d2591":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_78855c0584f14da583f5c33004e97748","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":266,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":266,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_06fda07e012a4bdf8577f920d5dbacf6"}},"ac47f949cc67488f9dfcdb30bb80d205":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_289f4a1576dc4e3f8896675a4f7ea72a","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 266/266 [00:00&lt;00:00, 800.88ex/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_13d7002607cc4a6c8b68ad5ceb3d104f"}},"ed69e631d062420f8870206431ee83a2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"fe2fec34247e43aca326e778418e98a4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"78855c0584f14da583f5c33004e97748":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"06fda07e012a4bdf8577f920d5dbacf6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"289f4a1576dc4e3f8896675a4f7ea72a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"13d7002607cc4a6c8b68ad5ceb3d104f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ace09768d30848578ee3b4861763bd7d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_01b07fc033d049a0b1b4e6587ee1b529","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_b128a4731c3743a18eab5639d43f98ec","IPY_MODEL_bd84992aa29141578156f2be46f5615c","IPY_MODEL_833cb6e4211549d883aa56c445a3a532"]}},"01b07fc033d049a0b1b4e6587ee1b529":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b128a4731c3743a18eab5639d43f98ec":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_1a446fa20c544566a8eaca9add5343ec","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_89edef893ecf4ac898efa8eb40084667"}},"bd84992aa29141578156f2be46f5615c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_c026101635a04ea8be776263717384df","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":243,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":243,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_006d7976408a406386ed2000e3e1d24d"}},"833cb6e4211549d883aa56c445a3a532":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b56405b46401459ba710a4ba92505c71","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 243/243 [00:00&lt;00:00, 769.74ex/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_47452effc7e746f197b081e7fae99790"}},"1a446fa20c544566a8eaca9add5343ec":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"89edef893ecf4ac898efa8eb40084667":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c026101635a04ea8be776263717384df":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"006d7976408a406386ed2000e3e1d24d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b56405b46401459ba710a4ba92505c71":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"47452effc7e746f197b081e7fae99790":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7c0d59c49e6e4dd988b4fd0a74eebe9d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_84fe35b4965c46ec98adf0dbb1c9a3a1","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_2451496173624943b9e3e43098fec181","IPY_MODEL_a20b0aea4aeb46a5928ee7c0fed0008e","IPY_MODEL_4a80d0a4df214a5792b99234a87deea1"]}},"84fe35b4965c46ec98adf0dbb1c9a3a1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2451496173624943b9e3e43098fec181":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_0404c9ab46514c6e83b1d67efaa0f695","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_84e79342550043429626855655f67afd"}},"a20b0aea4aeb46a5928ee7c0fed0008e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_c6f2117ea9444ab9aa105ea382e336a9","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7ed8173a4c054e8da431900386ae5112"}},"4a80d0a4df214a5792b99234a87deea1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ea171165bf4f46ddbdebbb9bf5c5cbfa","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1/1 [00:00&lt;00:00,  1.71ba/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b0e24827c1c442578a074d07c448068b"}},"0404c9ab46514c6e83b1d67efaa0f695":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"84e79342550043429626855655f67afd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c6f2117ea9444ab9aa105ea382e336a9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"7ed8173a4c054e8da431900386ae5112":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ea171165bf4f46ddbdebbb9bf5c5cbfa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"b0e24827c1c442578a074d07c448068b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2c1625c7e85e4643aa17b9a71ccce271":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_bb3489a0e67049c988c67405e24d130f","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_d84c293ce1984a599ead00f3be40a6cb","IPY_MODEL_38e0b55e3cbf425e8fd40b49be3280d0","IPY_MODEL_b89ca3ccb27045539d2c10dd258290cc"]}},"bb3489a0e67049c988c67405e24d130f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d84c293ce1984a599ead00f3be40a6cb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_fc6f2f700fb94c88988e87ebd501bb03","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1f0e3c0a73e6428c9b2059a7bdd6776a"}},"38e0b55e3cbf425e8fd40b49be3280d0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_152a112f9a1942e19cd6be544b3cb766","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_65270b5cf62e4c689556dbc92c70e160"}},"b89ca3ccb27045539d2c10dd258290cc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_8e0bdef7b20446c8b865e7c97da7c917","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1/1 [00:00&lt;00:00,  5.16ba/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9812cc0027664d6bb3c0fd9d3684893e"}},"fc6f2f700fb94c88988e87ebd501bb03":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"1f0e3c0a73e6428c9b2059a7bdd6776a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"152a112f9a1942e19cd6be544b3cb766":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"65270b5cf62e4c689556dbc92c70e160":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8e0bdef7b20446c8b865e7c97da7c917":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"9812cc0027664d6bb3c0fd9d3684893e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4ab75620e0064166b7f4311cc9f033ef":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_b622410dd9d04a5d97035d68c77fe56a","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_9cb2e875012c4014a7b3d215a2c190bf","IPY_MODEL_ca5481ea42094931965c82cd6267675d","IPY_MODEL_44e03193e3ad4f97a80e4bddf0c94edb"]}},"b622410dd9d04a5d97035d68c77fe56a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9cb2e875012c4014a7b3d215a2c190bf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_69b369dfed6f4a29a1e429eea31f5518","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_79de2d9f7a6c45ff919cd76546181f34"}},"ca5481ea42094931965c82cd6267675d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_e0f23b1dd2ca4f0db0c842405906e77b","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e62fb23f7c53411698bf1e46ff8e444e"}},"44e03193e3ad4f97a80e4bddf0c94edb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_2c4201704a524b178f8537ae6e0c543c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1/1 [00:00&lt;00:00,  5.98ba/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e9a737fb8d9c4b6ab7d4f5ba13998d6e"}},"69b369dfed6f4a29a1e429eea31f5518":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"79de2d9f7a6c45ff919cd76546181f34":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e0f23b1dd2ca4f0db0c842405906e77b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"e62fb23f7c53411698bf1e46ff8e444e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2c4201704a524b178f8537ae6e0c543c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e9a737fb8d9c4b6ab7d4f5ba13998d6e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3fc714c87be34fbea12e74ca3a35dcf0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_4c1593ea48744cdfa3bb8efbc38af4d5","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_5fd391d72b784204ac8b4c94f68aab7a","IPY_MODEL_5e71bb9c11764e9a8848f8628c3ce643","IPY_MODEL_23297aac257c4dfcb9bbde6b14b92f72"]}},"4c1593ea48744cdfa3bb8efbc38af4d5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5fd391d72b784204ac8b4c94f68aab7a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b56603cac1fc4980bb83b66e34db96dd","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7c83a794e67c4ddfa405950eac65ccbe"}},"5e71bb9c11764e9a8848f8628c3ce643":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_a13f9a732da04d43b5e6eca41257c073","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":2114,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":2114,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_fceca30b50cb488292daa9e536fe3889"}},"23297aac257c4dfcb9bbde6b14b92f72":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_70fd900faa2c4f8487861571a05ed091","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 2114/2114 [00:01&lt;00:00, 1390.20ex/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_17b9a8c9026a40c7af67b64c5538b57a"}},"b56603cac1fc4980bb83b66e34db96dd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"7c83a794e67c4ddfa405950eac65ccbe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a13f9a732da04d43b5e6eca41257c073":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"fceca30b50cb488292daa9e536fe3889":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"70fd900faa2c4f8487861571a05ed091":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"17b9a8c9026a40c7af67b64c5538b57a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9945d72500a64bb884a58b252043ae0b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_a78269dfa1e64ce49f9c9dc0b7077679","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_928c5496558149c5aca8d62e168fab50","IPY_MODEL_ade1bc87911046bab7b81f2f564d19cc","IPY_MODEL_434f2f544c0c480996df505d36761b7a"]}},"a78269dfa1e64ce49f9c9dc0b7077679":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"928c5496558149c5aca8d62e168fab50":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_0fa60878cbbd4c1590a89ffb24f21239","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a7aa0a1a48df4f58be30dfccef7b9df6"}},"ade1bc87911046bab7b81f2f564d19cc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_3dc7421efec5403fbbd226e41f9ed269","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":340,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":340,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a5ffe75c9f2546bbb19b0a3e71ca43b0"}},"434f2f544c0c480996df505d36761b7a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_9d016484ff3f49dd9fefaadd9e1583c7","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 340/340 [00:00&lt;00:00, 1075.25ex/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_551a9fe010eb467c91fb9bec8167fb41"}},"0fa60878cbbd4c1590a89ffb24f21239":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a7aa0a1a48df4f58be30dfccef7b9df6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3dc7421efec5403fbbd226e41f9ed269":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"a5ffe75c9f2546bbb19b0a3e71ca43b0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9d016484ff3f49dd9fefaadd9e1583c7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"551a9fe010eb467c91fb9bec8167fb41":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"07ff33393cbc4b4bba8a36157f3711c7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_731ceac6f8d941dfa1a7b98e45ca003c","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_c83b934cad704967bfa05d3fce74d1ad","IPY_MODEL_4a8fdde976704c63ab94e9c818b7081c","IPY_MODEL_bdb75a67942549dcbe6b1e46fed75308"]}},"731ceac6f8d941dfa1a7b98e45ca003c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c83b934cad704967bfa05d3fce74d1ad":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ea9ffd82ca8844df87d081e719396313","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f3e858d520a74b7ca524da2f3297cbcd"}},"4a8fdde976704c63ab94e9c818b7081c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_efadae02a6d0406193fa50efed786ae8","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":345,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":345,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f0e5799cd847424291f4d7ee10e190cd"}},"bdb75a67942549dcbe6b1e46fed75308":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_0b1c8c6ca9554e108ba1d6965c3b2038","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 345/345 [00:00&lt;00:00, 1165.21ex/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_301258b2e40041328037ecb480d3ae55"}},"ea9ffd82ca8844df87d081e719396313":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f3e858d520a74b7ca524da2f3297cbcd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"efadae02a6d0406193fa50efed786ae8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"f0e5799cd847424291f4d7ee10e190cd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0b1c8c6ca9554e108ba1d6965c3b2038":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"301258b2e40041328037ecb480d3ae55":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b85d3840c3fa4c1fbead2cccc677ded9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_a7bde24fe28a4e389a2b3c0fb5ea8faf","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_869db1042eca408abe7ecc78125b76e8","IPY_MODEL_e44dd9d060bd4bf9b1f48c55c3fa76b1","IPY_MODEL_1a43abbc44924d3c93304cb46a583216"]}},"a7bde24fe28a4e389a2b3c0fb5ea8faf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"869db1042eca408abe7ecc78125b76e8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_92fbb19c2fa44c0ea6510427d5ce2115","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"Downloading: 100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_53a6bab40aff4cf8a66937bba286f006"}},"e44dd9d060bd4bf9b1f48c55c3fa76b1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_4b2e7745ce60413d8493998b0c330782","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":331070498,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":331070498,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_84798573c8ab47ac916a3cf3d1b86750"}},"1a43abbc44924d3c93304cb46a583216":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_e40ea17efe89401bb458135254b0b947","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 331M/331M [00:06&lt;00:00, 46.5MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_24c097b174434153978f3146d9934b37"}},"92fbb19c2fa44c0ea6510427d5ce2115":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"53a6bab40aff4cf8a66937bba286f006":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4b2e7745ce60413d8493998b0c330782":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"84798573c8ab47ac916a3cf3d1b86750":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e40ea17efe89401bb458135254b0b947":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"24c097b174434153978f3146d9934b37":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0uBcPooxRbiw","executionInfo":{"status":"ok","timestamp":1630828848309,"user_tz":-60,"elapsed":10598,"user":{"displayName":"Cameron Stronge","photoUrl":"","userId":"13361440774782721572"}},"outputId":"7db465b0-b676-4356-dc15-f75f3496303a"},"source":["! pip install transformers\n","! pip install datasets"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.10.0-py3-none-any.whl (2.8 MB)\n","\u001b[K     |████████████████████████████████| 2.8 MB 4.2 MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 67.3 MB/s \n","\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n","  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n","\u001b[K     |████████████████████████████████| 3.3 MB 64.8 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n","\u001b[K     |████████████████████████████████| 636 kB 71.1 MB/s \n","\u001b[?25hCollecting huggingface-hub>=0.0.12\n","  Downloading huggingface_hub-0.0.16-py3-none-any.whl (50 kB)\n","\u001b[K     |████████████████████████████████| 50 kB 8.5 MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.12->transformers) (3.7.4.3)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Installing collected packages: tokenizers, sacremoses, pyyaml, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.0.16 pyyaml-5.4.1 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.10.0\n","Collecting datasets\n","  Downloading datasets-1.11.0-py3-none-any.whl (264 kB)\n","\u001b[K     |████████████████████████████████| 264 kB 4.1 MB/s \n","\u001b[?25hRequirement already satisfied: pyarrow!=4.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n","Requirement already satisfied: tqdm>=4.42 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.62.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.19.5)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.6.4)\n","Collecting xxhash\n","  Downloading xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243 kB)\n","\u001b[K     |████████████████████████████████| 243 kB 50.1 MB/s \n","\u001b[?25hRequirement already satisfied: huggingface-hub<0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.0.16)\n","Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n","Collecting fsspec>=2021.05.0\n","  Downloading fsspec-2021.8.1-py3-none-any.whl (119 kB)\n","\u001b[K     |████████████████████████████████| 119 kB 74.4 MB/s \n","\u001b[?25hRequirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets) (3.0.12)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<0.1.0->datasets) (3.7.4.3)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (2.4.7)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.5.30)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.5.0)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n","Installing collected packages: xxhash, fsspec, datasets\n","Successfully installed datasets-1.11.0 fsspec-2021.8.1 xxhash-2.0.2\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IQuSZyOpRyQ3","executionInfo":{"status":"ok","timestamp":1630828848736,"user_tz":-60,"elapsed":465,"user":{"displayName":"Cameron Stronge","photoUrl":"","userId":"13361440774782721572"}},"outputId":"a54c7057-5718-4649-f998-f7ab34981265"},"source":["cd '/content/drive/MyDrive/CAMemBERT2'"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/CAMemBERT2\n"]}]},{"cell_type":"code","metadata":{"id":"cMALxkWlRwi7","executionInfo":{"status":"ok","timestamp":1630828856863,"user_tz":-60,"elapsed":8143,"user":{"displayName":"Cameron Stronge","photoUrl":"","userId":"13361440774782721572"}}},"source":["from transformers import TrainingArguments,Trainer,AutoModelForSequenceClassification,AutoModel\n","import numpy as np\n","from math import floor\n","import torch\n","from torch.cuda import is_available\n","from collections import defaultdict\n","from scipy.stats import spearmanr\n","from sklearn.metrics import cohen_kappa_score,classification_report,fbeta_score\n","from models_f import MultiTaskModel\n","from trainer_f import MultiTaskModelTrainer\n","from trainer_utils import (training_args,training_kwargs,get_dataset,\n","                           freeze_layers,normalise_scores,create_params_grid)"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["40b35177a66d443a9436f53adb6ba85d","d2692e4031fa4baab1c3dc2c744aa84b","5d602471fdbe426f9ffff0afc1a9d94e","cdc26a4f3b7c4cfeadd91d9d0d4073cf","d1b5c8ee535b494baadcd2cc823c81a9","dcf1159663c1490391f8f70d7e814d37","c592d10f5f114c3b8956bdf16e8618d0","b0206816dca04698b821bb5fa33d5888","828018f93c5a45d49aaa57b425fc0152","0ce244702c654c4dbcd56dce691902be","65d110011f8e4fa289e8f328a409ccd7","5865448e12f342428f1db5cffea4e802","78088dd0a245458d8f757259593ffd31","47a94615cd4245fd8fe30b7239c15a1f","791d6a2528924273a359ca0b440e7b4c","e8fee998920745b5bad1a51fa8efc89b","94895c0297f44cb8b85eab505a8d56f2","692f2b7bd8d441488a879cf749fbb63d","dfbec7d114f54f41ab966f0d086a5999","09f4d86992ad4e00b11ee540d1ded979","87bd9c16125f433d847961194de9a514","29929e23961e40b0b69de20915dc16e1","9fa399f436ee4f699c525c82956b5877","5b980274f44544d9977a898a77b99409","32b65c13765540fb8902c0c2323c77b9","3b8afbfcc8004dab922f5f4855acfb2a","d8321b9cad2144d48af6f3d350709470","3ab87334e1c843af81388699092f90d4","2125a571ae6f456fa91ca15c9a041cf0","a52a4a0043504b51a195c9bb1a45e854","74de4fac18b54f78924715fec3c5fb2c","fb7b00a3de354ba7b97780bcc4f6c6af","ba9ff7eb2cc3449ab0a68e2bdf4964f3","ce85f3ec51f94affb5a7ab691b8c879e","5db334475c324668b99f6dd84be824f0","97dab9355cc54bf09e0aba318c5b78b8","e472009d71d84021b685fc3891e675ea","58b9e95fc6504889afc3a4f6122dbd5a","ec659763b5f547eeaa003884eb929139","ad4a8df5e088411683f524c79b5fa869","64b1e57c597f4ba19c210c22fd7312eb","0708bc82af814b32a93597178b4256f8","37cba868b4ac4731b77377f563e45155","46843e008f824c1e882e8dc2b3262a1c","b8cd72d96c9b4900b42cbcb612bd1d9a","15200f54de1c452a9d3c3ec17aeaab48","93d5402880064b338cc7268e20d12e16","4fa2657f2e264c83861e2e74bc26b211","785f6c2ece1f421ebc938dd915b4b5a5","a93d2bfc9a5a48dc83fd8c0b1b289709","4918cfaeb1b742f382b37d71e2b7cb6e","8ea5c37d4af54a56b9e20fc0a5b0c9bf","7c872722b330486a9c4c12460ca8ba98","83136f24e1ee4bfc91830fe16e142323","d626e65710cf4eb7a29ee3ebeadd882a","f0c50f2d98ef44fd8f47ad1ee216e9fb","b1c0458bf30b476e90ff2e7540d96d03","8a4bdf94eca74bdb8030095bb4f9dd7a","b0ef84a441f64fb88a0b4623ada96cb9","0ab039ca418a481bb60382baef78cafa","e20dfddbfe8a4cf8910cae02fdd2a0bf","cf6f624783284fa1b980266c5059e647","34568dae32ed4211ac08df4d52019167","dbe53e01fadd4996a75a9806b1dd443b","f07a04b03afc49a8b23cc001d5d6ac9d","2e6d5619c9124216b5908fe82c23245d","bb7cec071edf4913954cef1118814cbb","3cf855c95af548ca8f368b5fe0d685dc","c83d216e731b4f01885db4443b234855","20b52327a99c461bafdc26c9230329b0","6b92f1f88f5b43b18ce491c8f153ed9f","3d30275a46a84f3db68daacfa835bab1","37399e206d9b4d7e9f9b5af66aa8315e","a451631eaa0c4ad9ae655b83047781bb","b5de90aee859493f89362970c95595d8","1bfc0f3589fd4188885e2a5b50ff94bd","afb99fb454294229bec06fd37765b23d","786614b932884444b92ff2abf574e33a","e1f0c94cb32c429a84c72ad4fa4061e9","24bbee5ef64943d8a13b79538de4b52d","66ad0c517fef4084b24bb73015d55285","1a4b4341b8284e49a9bc38487b16d263","eb8394b396284c1b8462c5dc12ecd07d","91ba6c58a9ad45bcbab3f6d5ad41e37a","7549fc5e95524d4397678b11370cb812","f9e9985ceaf44fcabe04938b23663194","991fd23e01b54b1784251afd899ed3ba","6941bbc9b59f43369ad6f11763fb9195","248dfd465f7741c5b23d458d588739fd","11d0801b94ca47688ab328b9d893f897","9c426f6ad0c0451bb013a85edf70d1b0","30f4657943d9443b86a28c3174b67e80","08acde948b8549a986a40e895c45cad1","986e4fcf66774e0c9d630a85012c6991","d2d5d284aeee4020a21e987871bb6fa0","5676ca474a1442539e481e60583ecb3e","455f671cc12f4542b29c9932d47ec416","a9c36cc5d80b40d79da53950644ca3fe","667bcb35ed57488187d19ccd4ba71126","8a191f9febb9448db24ce8785a4fd568","3f4db3f005b940dba7d0d3605e339def","921fbc28a04044b88c832334e9f7d45d","024b6715b69342d5afd9d63e5827bd26","00b776207c024052b9b5c042ad005581","c4a354cd6f474ea193fdb54e0050e9b6","aeabd7d3b85944ada45fd60a35c4e07e","568639a2cb3a4e47bc69a23f27cf6c8f","801a4a2dd1b648fa8e3011fd26f0642e","2f1305dbbbfb44cc95c85644ca47e7d6","9bcbcca52c764319b2116ab7c7c3fb04","d91d0c2485b44ff89640196049c0eb8f","656979f70c49405eb300f3e678dacea5","fd24744743694db5a704e8d7544a8961","f8ba7f62eed4434ca8a958e708289679","f427a198b4f345dd952f415ac65cb636","f5b60c454ee54baca18caba39e85914c","349f8b69b5e24849852a77bbb66ad420","3e1cca387fa44100af1a5860e96e21dc","095729e3eeae48bf921ae67b3063475e","ea7ee4c779db4089808534e3f857f114","0eba576651f04c8e8f3dfadfb2dcb331","72da9a1718334039916cc85c53ce99c0","21985842bd2a4064b3eaf44ffabfa7d9","b9567fe90bb44292a8702291d47d0c84","ac6841bee5514b8ca51d81e1ba8a28a9","393b50ea8323421fb8ad6db78b2e003b","485b66cae2b641a7b0e1fd7ac3396d9e","e83c9ff0257447219d4fdf899cab87b4","019b14c73bcf46efbef4ae3de09d4a68","327c1d2a4b384725abda45e6dfa2bbe3","0744d50224654d39b0a8520ce01128d7","20fe145e8c744525bcb9766c3b9ff050","294c7eb15a874dfaa57c31223f5c0a51","5285d23f92dc4e36abf1d7e46995ad73","887ef6e7b2944dc8b1c8fa6f056e6a4f","060542ef3f0941acb768c08f9ef6de02","a5feeb841b9f48a4aca6c56a58b3237a","b05731da36bf413b83cbfb780b60673c","4b8f51a61fc14694824723c1f14fbe01","c1c9e0f1fa384171a7876405ba76fd14","57797ec82161461da0b3fe3137f9d8fe","89b399fa432144e3ba7a026222bcaccd","9003f28d56f3422ca43ba8d390b3a76c","63064fef852948c78bc2b01b8233d119","05cb37c123814f91b2cdb42f6bce833e","ec701dc7bb6f41ffb0e8657e766e535c","29d0ae708c98480e800021c329cb7585","c9cc509fef4d4b85b97edcab1191e88a","c731024c38e3402f9a00b4a5f4de8a8e","9587a6c349234e7d9873f77d475f5248","720d4861b1984f8397eadb12abb4c29b","519ad735190b4361bf6d2d3762b4e77d","ba394871df534be69eaf9fa3228881f0","602d6e617a234d74b50dc6eaafb3aaa5","1f19d2b6d6eb46978ac822072b9b5a02","06177686049c4d7fbc531b086e788bc0","fed4e6d4ceee4b1589faf45165b72ae8","2cd8e668001b4baeb60ea4d581b496db","bab4907c1c2a449e96eea3003d308cb3","bbb5349a16d2424ea0757a286756f14a","7cf14d6c1b154288a099741cb3ac7afa","11c906426b884c34953b74fe7c18e7ab","1d8ed71c3f24455580efe2be742ca5e3","c5ecdcd1cb9240f48c81d1c84e724dbd","ff01f09b89cc42e082580ce8256f1d98","d2a3cfa7e6b946fba5e2597d47b977b7","da03ab78025449eea007d202e720825c","4490951fea0b49a5be7ea319460046b1","59abb0c5445b4d98b23fd401b0f82cd2","f5d49bba992542a0a389202a97f453b3","34622185c7f84566bc3babbc63ee71eb","bc9442b3b25c4a4e9faaed99290c7243","8b110514ba054675bddb4defd1254e2e","c461b6d0e6dc415bbb9c28a1e3df54b6","fd5f0366560041038aba2e4665b3e1c0","e6190a07bf11461cbe5f87339b3b8756","821b7d4ef03c47f4907438086f7a21e0","63b8cc3014c94b75974af76b09a72285","5fa00e0e7fc7493aa2af029ff3de90f7","67329e1a1fe346d8bfc40463ec33c046","cd66e250cb004073bd1687d98fde64d1","86de8f811bb5414d9ffcad01bc190fb9","58670e46904e409d8a5b2da30767c8bc","4be71ee8468c4fb0a47247fdfa31ddc9","cf325b678c4c47339fd292284cc42279","ef6751e39d09438eb0da732af1cd8ada","87d264e2a49543c2a25e069c20d33c71","0d9bf8d94f4946fda0afddcc2801e876","c33b2da511fb451ab580f4a57e86e8e2","41dd81e5558241e3b12bc2fe4a2a8d70","7356d63ec9a246808412b1185132fe26","fd9e7991d0ac498e8611719452d83836","c52d3dbdff0f4a14acab2c409adb8aef","86b85ee96a7f4bc59f994e39e66fbd35","693ca78a770c49dab03c1ef024bcb65c","3e8cc1872d15415bab7fdaee7da1d2f7","27dc599456d44401b0a29a8f3031529d","21f461b9e17b4033a0e05a0637db4758","a9a813020aba4146adcb255e49ab8c0e","b3c6199422a04d48b2677d31f3cce937","b22e173830c04973bd790152375cb82b","29d13c0fb2144352ac9c871b57d738fa","16d0a5d52ac64b43bc875f038d918dc2","75daa41cd912419ca73c6790024ac1c1","46e91dc92cdc42f5addddb2320975e1a","60fea8d061ee4f4ba800be7b387df98e","0719e23f8e8049268638d8462842c3c9","a46207e015a140a5b21e6ba1606e3ff5","7d6f01762b764f919b97f0e7c46ac5df","69a241273b73402d953e9f70428f737f","050c92fe2bdf42c4a512a52debfb4107","7d42bb8c10754deab2e8f43b56514485","2c4cef4d44cf4bee814fdcf6fd443c22","8150f61e3c66459887e62b93321d9aa8","b0d4653b79b54fe19b15718851be4676","5e6c9479cf95452e8a54e07038f5406c","5dbc4ebf6c784e10b677a288216ceb49","ec910867ba3144c4ab43086afd7e0283","0ddf4b87615741bebfe2d008ef0e900b","6cd5c95cae4544b39860e6d86c441658","8caa1ee05d9a41a6b29b9bf4f158f392","ee3c7dd2d96e4504893680e514910279","6a6969a5523e4387881465b810d7ef5c","c3d2988930db4d139afb4c0c812ef57d","0f4ab175408844a58b37e23c2c2ff6d2","0dd92c2dddf34788816de2704a495416","9d13b2e865b34e5197ca27dc017a6cc5","b34ddc02ef314f4d88055523ca56ea47","574e51a5b117401faa260fdd5a0bdeed","de273dfcb060438e99c70f113d885b0f","20c791434a894b8d8fbc7c7b366f541a","bcc0334547704a8b93fd16c712dd9fec","ae85a2d5ea9f402ba0021e48842e72d3","812063e969d54a4ca11a3140b5a0a4cf","76afb4a3000d4685b4f9c5c6a22606f1","9a8785e65d1e4eb0aa5c020b58231282","41872043cdb645a7bdb3abad59e8f470","b86952164f5841319c2eedaf6c7b3dcd","586dba559f624b29932af8c9810385fe","a2c18290416f4fcda20c54b26e4158ed","e48a7c0acb6847a194f3117b3552523d","540e0fa5354a40c389f56b5f2697c814","a26b312ac6174c4dadd3db55974a7e38","df773a3b16724a36bc9e80e842dbbb8c","608ee24288c2464abece2bd59f88d457","565df88bb4cd49c98e9d94ee8c69ea72","0b2fa1f8e0ba47e2bc2bfc4701970a99","b03c4c2c226f494db1ff192082db4424","572f3dae58db4109b0750ac824da06ea","e3ca63b79327496eb53ddecffec19f95","21c93b51e6d1455e8637203377e5d7a2","dca6a6c2ac6240aa86c37d08ad1e2a5a","82320c694fe044ce83d6c4fb6ec7c328","f0a346f5440a4b0d86e0fca88da246de","69ee0dd06974427a939d871133b2c4bc","7b1405f49b014efdb01e9d14d3707552","e111590e5ed44a3d9a94808ea4ec874a","a31deeff91334da2b39972c1edbc321b","34766e5cac6f4c0f8e94afc116af5889","05417dbafbc54add87217c76479a93c7","43490c2870d3444aa5b0daab264f2c0b","63ddc3816d9c4c638f4838d7cbf1cb34","6e40518a230f4a34a21f153b1421b4c8","96c749b0559b4765bfd3b3de7f8da526","4493fdff8b3f405d95c41c9c26d22241","79f8beaa7a504068a38bb3db446c1863","113c163eb5b6494db7be2f0863c26ef3","f7f6cd04fa0845858e365a9e5e57c798","2f86a9952b8e4aa985c16b2f917324f4","b1db05b46239464bb43c1d914deccc09","650cc1502312456daa4ec4a6a968148a","ee2a0327dcb54ea0b883c8e197b5a035","56aea1c87fa74454a0463cb56c192ca1","a7ebd5dcebe84772ae90de92c67c47de","02634723850e430f85373624c7bd46fc","1a1671d3c45e47778d5f1d96c31b1de7","1c27e5ebe104420880c0bd5b420de29e","8ac4da8ec8e24592980a13985227f94a","5e48ffa6af8349539fd580f9f95d2591","ac47f949cc67488f9dfcdb30bb80d205","ed69e631d062420f8870206431ee83a2","fe2fec34247e43aca326e778418e98a4","78855c0584f14da583f5c33004e97748","06fda07e012a4bdf8577f920d5dbacf6","289f4a1576dc4e3f8896675a4f7ea72a","13d7002607cc4a6c8b68ad5ceb3d104f","ace09768d30848578ee3b4861763bd7d","01b07fc033d049a0b1b4e6587ee1b529","b128a4731c3743a18eab5639d43f98ec","bd84992aa29141578156f2be46f5615c","833cb6e4211549d883aa56c445a3a532","1a446fa20c544566a8eaca9add5343ec","89edef893ecf4ac898efa8eb40084667","c026101635a04ea8be776263717384df","006d7976408a406386ed2000e3e1d24d","b56405b46401459ba710a4ba92505c71","47452effc7e746f197b081e7fae99790","7c0d59c49e6e4dd988b4fd0a74eebe9d","84fe35b4965c46ec98adf0dbb1c9a3a1","2451496173624943b9e3e43098fec181","a20b0aea4aeb46a5928ee7c0fed0008e","4a80d0a4df214a5792b99234a87deea1","0404c9ab46514c6e83b1d67efaa0f695","84e79342550043429626855655f67afd","c6f2117ea9444ab9aa105ea382e336a9","7ed8173a4c054e8da431900386ae5112","ea171165bf4f46ddbdebbb9bf5c5cbfa","b0e24827c1c442578a074d07c448068b","2c1625c7e85e4643aa17b9a71ccce271","bb3489a0e67049c988c67405e24d130f","d84c293ce1984a599ead00f3be40a6cb","38e0b55e3cbf425e8fd40b49be3280d0","b89ca3ccb27045539d2c10dd258290cc","fc6f2f700fb94c88988e87ebd501bb03","1f0e3c0a73e6428c9b2059a7bdd6776a","152a112f9a1942e19cd6be544b3cb766","65270b5cf62e4c689556dbc92c70e160","8e0bdef7b20446c8b865e7c97da7c917","9812cc0027664d6bb3c0fd9d3684893e","4ab75620e0064166b7f4311cc9f033ef","b622410dd9d04a5d97035d68c77fe56a","9cb2e875012c4014a7b3d215a2c190bf","ca5481ea42094931965c82cd6267675d","44e03193e3ad4f97a80e4bddf0c94edb","69b369dfed6f4a29a1e429eea31f5518","79de2d9f7a6c45ff919cd76546181f34","e0f23b1dd2ca4f0db0c842405906e77b","e62fb23f7c53411698bf1e46ff8e444e","2c4201704a524b178f8537ae6e0c543c","e9a737fb8d9c4b6ab7d4f5ba13998d6e","3fc714c87be34fbea12e74ca3a35dcf0","4c1593ea48744cdfa3bb8efbc38af4d5","5fd391d72b784204ac8b4c94f68aab7a","5e71bb9c11764e9a8848f8628c3ce643","23297aac257c4dfcb9bbde6b14b92f72","b56603cac1fc4980bb83b66e34db96dd","7c83a794e67c4ddfa405950eac65ccbe","a13f9a732da04d43b5e6eca41257c073","fceca30b50cb488292daa9e536fe3889","70fd900faa2c4f8487861571a05ed091","17b9a8c9026a40c7af67b64c5538b57a","9945d72500a64bb884a58b252043ae0b","a78269dfa1e64ce49f9c9dc0b7077679","928c5496558149c5aca8d62e168fab50","ade1bc87911046bab7b81f2f564d19cc","434f2f544c0c480996df505d36761b7a","0fa60878cbbd4c1590a89ffb24f21239","a7aa0a1a48df4f58be30dfccef7b9df6","3dc7421efec5403fbbd226e41f9ed269","a5ffe75c9f2546bbb19b0a3e71ca43b0","9d016484ff3f49dd9fefaadd9e1583c7","551a9fe010eb467c91fb9bec8167fb41","07ff33393cbc4b4bba8a36157f3711c7","731ceac6f8d941dfa1a7b98e45ca003c","c83b934cad704967bfa05d3fce74d1ad","4a8fdde976704c63ab94e9c818b7081c","bdb75a67942549dcbe6b1e46fed75308","ea9ffd82ca8844df87d081e719396313","f3e858d520a74b7ca524da2f3297cbcd","efadae02a6d0406193fa50efed786ae8","f0e5799cd847424291f4d7ee10e190cd","0b1c8c6ca9554e108ba1d6965c3b2038","301258b2e40041328037ecb480d3ae55","b85d3840c3fa4c1fbead2cccc677ded9","a7bde24fe28a4e389a2b3c0fb5ea8faf","869db1042eca408abe7ecc78125b76e8","e44dd9d060bd4bf9b1f48c55c3fa76b1","1a43abbc44924d3c93304cb46a583216","92fbb19c2fa44c0ea6510427d5ce2115","53a6bab40aff4cf8a66937bba286f006","4b2e7745ce60413d8493998b0c330782","84798573c8ab47ac916a3cf3d1b86750","e40ea17efe89401bb458135254b0b947","24c097b174434153978f3146d9934b37"]},"id":"WEgWTVNYR9Cl","executionInfo":{"status":"error","timestamp":1630832511159,"user_tz":-60,"elapsed":185906,"user":{"displayName":"Cameron Stronge","photoUrl":"","userId":"13361440774782721572"}},"outputId":"b6c560af-fc5e-494b-f89c-1531ab68575c"},"source":["for pretrained_model_name in ['distilroberta-base']:\n","    model_type = 'roberta' if 'roberta' in pretrained_model_name else 'bert'\n","    model_n_layers = 6 if 'roberta' in pretrained_model_name else 12\n","    params_grid = create_params_grid({'tasks':[['aes','ged','ner']],\n","                                      'lr':[4e-5],\n","                                      'shared_encoder_n_layers':[0,1,2],\n","                                      'frozen_layers':[None],\n","                                      'output_layer':[2,4,-1]}\n","                                      )\n","\n","    prev_task = None\n","    for i,params in enumerate(params_grid):\n","        print(params)\n","        if params['tasks']!=prev_task:\n","            dataset_obj,dataset_dict = get_dataset(params['tasks'],pretrained_model=pretrained_model_name,max_length=512)\n","            dataset_dict = dataset_dict.map(normalise_scores)\n","\n","        trainer_kwargs,model_kwargs = training_kwargs(\n","            tasks=params['tasks'],\n","            class_weights={'aes':None,'ged':dataset_obj.get_weights(),'ner':None},\n","            early_stopping_patience=2,\n","            shared_encoder_n_layers=params['shared_encoder_n_layers'],\n","            output_layer = {'aes':-1,\n","                            'ged':params['output_layer'],\n","                            'ner':params['output_layer']},\n","            early_stopping_metric='los',\n","            normalised_values=[40,0],\n","            frozen_layers=params['frozen_layers'],\n","            save_results=True)\n","\n","        args = training_args(lr=params['lr'],epochs=8)\n","        model = MultiTaskModel(kwargs_dict = model_kwargs,pretrained_model=pretrained_model_name)\n","        model = freeze_layers(model,frozen_layers=params['frozen_layers'],model_type=model_type)\n","        dev_set = 'dev' if params['tasks']!='ner' else 'validation'\n","        trainer = MultiTaskModelTrainer(\n","            model,\n","            args,\n","            train_dataset=dataset_dict['train'],\n","            eval_dataset=dataset_dict[dev_set],\n","        )\n","        trainer.kwargs_dict = trainer_kwargs\n","        trainer.test_dataset = dataset_dict['test']\n","        trainer.train()\n","        prev_task=params['tasks']"],"execution_count":4,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["{'frozen_layers': None, 'lr': 4e-05, 'output_layer': 2, 'shared_encoder_n_layers': 0, 'tasks': ['aes', 'ged', 'ner']}\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"40b35177a66d443a9436f53adb6ba85d","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/480 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5865448e12f342428f1db5cffea4e802","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/899k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9fa399f436ee4f699c525c82956b5877","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ce85f3ec51f94affb5a7ab691b8c879e","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/content/drive/My Drive/CAMemBERT2/preprocessing_f.py:53: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n","  ged = pd.DataFrame(pd.read_csv(f'data/fce-public.{self.set_type}.original.tsv',sep='  ',names=['word']).word.str.split('\\t',1).tolist(),columns = ['word','labels'])\n","/content/drive/My Drive/CAMemBERT2/preprocessing_f.py:53: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n","  ged = pd.DataFrame(pd.read_csv(f'data/fce-public.{self.set_type}.original.tsv',sep='  ',names=['word']).word.str.split('\\t',1).tolist(),columns = ['word','labels'])\n","/content/drive/My Drive/CAMemBERT2/preprocessing_f.py:53: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n","  ged = pd.DataFrame(pd.read_csv(f'data/fce-public.{self.set_type}.original.tsv',sep='  ',names=['word']).word.str.split('\\t',1).tolist(),columns = ['word','labels'])\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b8cd72d96c9b4900b42cbcb612bd1d9a","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1057 [00:00<?, ?ex/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f0c50f2d98ef44fd8f47ad1ee216e9fb","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/97 [00:00<?, ?ex/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bb7cec071edf4913954cef1118814cbb","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/79 [00:00<?, ?ex/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"786614b932884444b92ff2abf574e33a","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1057 [00:00<?, ?ex/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"248dfd465f7741c5b23d458d588739fd","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/97 [00:00<?, ?ex/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8a191f9febb9448db24ce8785a4fd568","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/79 [00:00<?, ?ex/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d91d0c2485b44ff89640196049c0eb8f","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/2.60k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"72da9a1718334039916cc85c53ce99c0","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/1.78k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Downloading and preparing dataset conll2003/conll2003 (download: 4.63 MiB, generated: 9.78 MiB, post-processed: Unknown size, total: 14.41 MiB) to /root/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/40e7cb6bcc374f7c349c83acd1e9352a4f09474eb691f64f364ee62eb65d0ca6...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"294c7eb15a874dfaa57c31223f5c0a51","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/650k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"63064fef852948c78bc2b01b8233d119","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/163k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1f19d2b6d6eb46978ac822072b9b5a02","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/146k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d2a3cfa7e6b946fba5e2597d47b977b7","version_major":2,"version_minor":0},"text/plain":["0 examples [00:00, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"821b7d4ef03c47f4907438086f7a21e0","version_major":2,"version_minor":0},"text/plain":["0 examples [00:00, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0d9bf8d94f4946fda0afddcc2801e876","version_major":2,"version_minor":0},"text/plain":["0 examples [00:00, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Dataset conll2003 downloaded and prepared to /root/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/40e7cb6bcc374f7c349c83acd1e9352a4f09474eb691f64f364ee62eb65d0ca6. Subsequent calls will reuse this data.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a9a813020aba4146adcb255e49ab8c0e","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/14041 [00:00<?, ?ex/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"69a241273b73402d953e9f70428f737f","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/3250 [00:00<?, ?ex/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8caa1ee05d9a41a6b29b9bf4f158f392","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/3453 [00:00<?, ?ex/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bcc0334547704a8b93fd16c712dd9fec","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1057 [00:00<?, ?ex/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a26b312ac6174c4dadd3db55974a7e38","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/266 [00:00<?, ?ex/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f0a346f5440a4b0d86e0fca88da246de","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/243 [00:00<?, ?ex/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4493fdff8b3f405d95c41c9c26d22241","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1057 [00:00<?, ?ex/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1a1671d3c45e47778d5f1d96c31b1de7","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/266 [00:00<?, ?ex/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ace09768d30848578ee3b4861763bd7d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/243 [00:00<?, ?ex/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7c0d59c49e6e4dd988b4fd0a74eebe9d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2c1625c7e85e4643aa17b9a71ccce271","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4ab75620e0064166b7f4311cc9f033ef","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3fc714c87be34fbea12e74ca3a35dcf0","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2114 [00:00<?, ?ex/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9945d72500a64bb884a58b252043ae0b","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/340 [00:00<?, ?ex/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"07ff33393cbc4b4bba8a36157f3711c7","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/345 [00:00<?, ?ex/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b85d3840c3fa4c1fbead2cccc677ded9","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/331M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight']\n","- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","***** Running training *****\n","  Num examples = 2114\n","  Num Epochs = 8\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 2120\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1060' max='2120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1060/2120 03:44 < 03:44, 4.71 it/s, Epoch 4/8]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>0.449900</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.308600</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["aes_weight_coef : 1.0\n","ged_weight_coef : 1.0\n","ner_weight_coef : 1.0\n","\n","losses {'aes': 0.006459073997427558, 'ged': 0.12047770411469215, 'ner': 0.08649276993995489, 'total_loss': 0.2134295480520746}\n","\n","aes_metrics {'rmse_aes': 7.110243002567181, 'pearson_aes': 0.11696545272260048, 'spearman_aes': 0.07349404923694604, 'kappa_aes': 0.00748639465178591}\n","\n","ged               precision    recall  f1-score   support\n","\n","           0       0.93      0.68      0.79     25174\n","           1       0.25      0.69      0.37      3917\n","\n","    accuracy                           0.68     29091\n","   macro avg       0.59      0.69      0.58     29091\n","weighted avg       0.84      0.68      0.73     29091\n","\n","ged_metrics {'accuracy_ged': 0.6799010003093741, 'f1_score_macro_ged': 0.5768715696493052, 'f1_score_weighted_ged': 0.7294383831317909, 'f_0_5_ged': 0.5119492581266281}\n","\n","ner               precision    recall  f1-score   support\n","\n","           0  0.991734768 0.996187937 0.993956364     42759\n","           1  0.912841671 0.960912052 0.936260249      1842\n","           2  0.959214502 0.971690895 0.965412391      1307\n","           3  0.754098361 0.823266219 0.787165775      1341\n","           4  0.725063939 0.754993342 0.739726027       751\n","           5  0.889128095 0.899292324 0.894181326      1837\n","           6  0.759358289 0.552529183 0.639639640       257\n","           7  0.854137447 0.660520607 0.744954128       922\n","           8  0.895833333 0.372832370 0.526530612       346\n","\n","    accuracy                      0.970347728     51362\n","   macro avg  0.860156712 0.776913881 0.803091835     51362\n","weighted avg  0.970025700 0.970347728 0.969084438     51362\n","\n","ner_metrics {'accuracy_ner': 0.970347727892216, 'f1_score_macro_ner': 0.8030918347846596, 'f1_score_weighted_ner': 0.9690844378089}\n","\n","epochs since best performance 0\n","\n","aes_weight_coef : 1.0\n","ged_weight_coef : 1.0\n","ner_weight_coef : 1.0\n","\n","losses {'aes': 0.005094617605209351, 'ged': 0.1147329335988954, 'ner': 0.05854859501989775, 'total_loss': 0.1783761462240025}\n","\n","aes_metrics {'rmse_aes': 6.232753983771718, 'pearson_aes': nan, 'spearman_aes': nan, 'kappa_aes': 0.0}\n","\n","ged               precision    recall  f1-score   support\n","\n","           0       0.94      0.71      0.81     25174\n","           1       0.28      0.72      0.40      3917\n","\n","    accuracy                           0.71     29091\n","   macro avg       0.61      0.71      0.60     29091\n","weighted avg       0.85      0.71      0.75     29091\n","\n","ged_metrics {'accuracy_ged': 0.7098759066377918, 'f1_score_macro_ged': 0.6040987223939817, 'f1_score_weighted_ged': 0.753630251653187, 'f_0_5_ged': 0.5438868436349545}\n","\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2559: RuntimeWarning: invalid value encountered in true_divide\n","  c /= stddev[:, None]\n","/usr/local/lib/python3.7/dist-packages/numpy/lib/function_base.py:2560: RuntimeWarning: invalid value encountered in true_divide\n","  c /= stddev[None, :]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["ner               precision    recall  f1-score   support\n","\n","           0  0.995022434 0.995790360 0.995406249     42759\n","           1  0.931877275 0.972855592 0.951925631      1842\n","           2  0.974693252 0.972456006 0.973573344      1307\n","           3  0.855895197 0.876957494 0.866298343      1341\n","           4  0.811842105 0.821571238 0.816677697       751\n","           5  0.921205711 0.948285248 0.934549356      1837\n","           6  0.872641509 0.719844358 0.788912580       257\n","           7  0.892512077 0.801518438 0.844571429       922\n","           8  0.838129496 0.673410405 0.746794872       346\n","\n","    accuracy                      0.979985203     51362\n","   macro avg  0.899313229 0.864743238 0.879856611     51362\n","weighted avg  0.979780146 0.979985203 0.979714921     51362\n","\n","ner_metrics {'accuracy_ner': 0.9799852030684163, 'f1_score_macro_ner': 0.8798566110265038, 'f1_score_weighted_ner': 0.9797149211437942}\n","\n","epochs since best performance 0\n","\n","aes_weight_coef : 1.0\n","ged_weight_coef : 1.0\n","ner_weight_coef : 1.0\n","\n","losses {'aes': 0.006452161862060081, 'ged': 0.1121221572853798, 'ner': 0.04785943979960541, 'total_loss': 0.1664337589470453}\n","\n","aes_metrics {'rmse_aes': 7.030686705831483, 'pearson_aes': 0.3218322972510986, 'spearman_aes': 0.3064080261206843, 'kappa_aes': 0.08347636136682779}\n","\n","ged               precision    recall  f1-score   support\n","\n","           0       0.94      0.76      0.84     25174\n","           1       0.31      0.69      0.42      3917\n","\n","    accuracy                           0.75     29091\n","   macro avg       0.62      0.72      0.63     29091\n","weighted avg       0.85      0.75      0.78     29091\n","\n","ged_metrics {'accuracy_ged': 0.7497507820288062, 'f1_score_macro_ged': 0.6325189153892778, 'f1_score_weighted_ged': 0.7841833173828541, 'f_0_5_ged': 0.5509811150710745}\n","\n","ner               precision    recall  f1-score   support\n","\n","           0  0.994542274 0.997240347 0.995889483     42759\n","           1  0.946701847 0.973941368 0.960128445      1842\n","           2  0.979922780 0.970925784 0.975403536      1307\n","           3  0.902735562 0.885906040 0.894241626      1341\n","           4  0.863448276 0.833555260 0.848238482       751\n","           5  0.937834941 0.952640174 0.945179584      1837\n","           6  0.907894737 0.805447471 0.853608247       257\n","           7  0.896551724 0.845986985 0.870535714       922\n","           8  0.856164384 0.722543353 0.783699060       346\n","\n","    accuracy                      0.983314513     51362\n","   macro avg  0.920644058 0.887576309 0.902991575     51362\n","weighted avg  0.982987818 0.983314513 0.983067610     51362\n","\n","ner_metrics {'accuracy_ner': 0.9833145126747401, 'f1_score_macro_ner': 0.9029915753152343, 'f1_score_weighted_ner': 0.9830676096488472}\n","\n","epochs since best performance 1\n","\n","aes_weight_coef : 1.0\n","ged_weight_coef : 1.0\n","ner_weight_coef : 1.0\n","\n","losses {'aes': 0.004579329754897329, 'ged': 0.11050274205762287, 'ner': 0.044397449813956436, 'total_loss': 0.15947952162647663}\n","\n","aes_metrics {'rmse_aes': 5.860650324172414, 'pearson_aes': 0.48913122081697186, 'spearman_aes': 0.4998553218471761, 'kappa_aes': 0.3988164483334177}\n","\n","ged               precision    recall  f1-score   support\n","\n","           0       0.95      0.73      0.82     25174\n","           1       0.30      0.73      0.42      3917\n","\n","    accuracy                           0.73     29091\n","   macro avg       0.62      0.73      0.62     29091\n","weighted avg       0.86      0.73      0.77     29091\n","\n","ged_metrics {'accuracy_ged': 0.7309133408958097, 'f1_score_macro_ged': 0.6237968137698549, 'f1_score_weighted_ged': 0.770480832137208, 'f_0_5_ged': 0.5667680398119989}\n","\n","ner               precision    recall  f1-score   support\n","\n","           0  0.995515067 0.996702449 0.996108404     42759\n","           1  0.945378151 0.977198697 0.961025093      1842\n","           2  0.980000000 0.974751339 0.977368623      1307\n","           3  0.897608371 0.895600298 0.896603210      1341\n","           4  0.885200553 0.852197071 0.868385346       751\n","           5  0.946370531 0.951007077 0.948683139      1837\n","           6  0.935897436 0.852140078 0.892057026       257\n","           7  0.898876404 0.867678959 0.883002208       922\n","           8  0.829652997 0.760115607 0.793363499       346\n","\n","    accuracy                      0.984424283     51362\n","   macro avg  0.923833279 0.903043508 0.912955172     51362\n","weighted avg  0.984244890 0.984424283 0.984294847     51362\n","\n","ner_metrics {'accuracy_ner': 0.9844242825435147, 'f1_score_macro_ner': 0.9129551720266057, 'f1_score_weighted_ner': 0.984294847073456}\n","\n","epochs since best performance 2\n","\n","\n","test results {'rmse_aes': 4.590524661372235, 'pearson_aes': 0.6835414600086788, 'spearman_aes': 0.7124320988452189, 'kappa_aes': 0.5832684093168202, 'accuracy_ged': 0.690126920507682, 'f1_score_macro_ged': 0.6032855436094893, 'f1_score_weighted_ged': 0.73265489348895, 'f_0_5_ged': 0.5631685849695328, 'accuracy_ner': 0.9747604177883062, 'f1_score_macro_ner': 0.8585360051726817, 'f1_score_weighted_ner': 0.9751089961085173, 'aes': 0.0037238171900666897, 'ged': 0.1584168459687914, 'ner': 0.0676949532436473, 'total_loss': 0.2298356164025054, 'aes_weight_coef': 1.0, 'ged_weight_coef': 1.0, 'ner_weight_coef': 1.0}\n","some model info : ['aes', 'ged', 'ner']_distilroberta-base_lr4e-05\n","        bs8_freNone_share0\n","        outs{'aes': -1, 'ged': 2, 'ner': 2}_norm[40, 0]\n","        pri{'primary_task': 'aes', 'secondary_task': 'ged', 'aux_task': 'ner'}_optfixed\n","        scoscript_eslos\n","model saved to results/raw_results/ 1630829177\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["{'frozen_layers': None, 'lr': 4e-05, 'output_layer': 2, 'shared_encoder_n_layers': 1, 'tasks': ['aes', 'ged', 'ner']}\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["loading configuration file https://huggingface.co/distilroberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/42d6b7c87cbac84fcdf35aa69504a5ccfca878fcee2a1a9b9ff7a3d1297f9094.aa95727ac70adfa1aaf5c88bea30a4f5e50869c68e68bce96ef1ec41b5facf46\n","Model config RobertaConfig {\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"LABEL_0\": 0\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 6,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.10.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading weights file https://huggingface.co/distilroberta-base/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/7a0115a4c463f49bc7ab011872fc4a4b81be681a0434075955d29ac3388e225b.a6127d76576e81475313180aceb31a8688f7a649b80e380d26b5d30302dc83c1\n","Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight']\n","- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","loading configuration file https://huggingface.co/distilroberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/42d6b7c87cbac84fcdf35aa69504a5ccfca878fcee2a1a9b9ff7a3d1297f9094.aa95727ac70adfa1aaf5c88bea30a4f5e50869c68e68bce96ef1ec41b5facf46\n","Model config RobertaConfig {\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 1,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.10.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading weights file https://huggingface.co/distilroberta-base/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/7a0115a4c463f49bc7ab011872fc4a4b81be681a0434075955d29ac3388e225b.a6127d76576e81475313180aceb31a8688f7a649b80e380d26b5d30302dc83c1\n","Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaModel: ['roberta.encoder.layer.4.attention.output.dense.weight', 'roberta.encoder.layer.1.output.LayerNorm.bias', 'roberta.encoder.layer.1.attention.self.query.bias', 'roberta.encoder.layer.5.attention.self.key.bias', 'roberta.encoder.layer.2.attention.self.query.bias', 'lm_head.layer_norm.bias', 'roberta.encoder.layer.4.intermediate.dense.bias', 'lm_head.dense.weight', 'roberta.encoder.layer.5.attention.self.value.weight', 'roberta.encoder.layer.1.intermediate.dense.weight', 'roberta.encoder.layer.1.output.LayerNorm.weight', 'roberta.encoder.layer.5.attention.self.key.weight', 'roberta.encoder.layer.3.attention.self.key.bias', 'roberta.encoder.layer.1.output.dense.weight', 'roberta.encoder.layer.2.attention.self.key.bias', 'roberta.encoder.layer.4.intermediate.dense.weight', 'roberta.encoder.layer.3.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.output.dense.bias', 'roberta.encoder.layer.5.attention.self.query.weight', 'roberta.encoder.layer.3.attention.output.LayerNorm.bias', 'roberta.encoder.layer.3.attention.self.value.bias', 'roberta.encoder.layer.5.attention.output.LayerNorm.weight', 'roberta.encoder.layer.2.output.dense.weight', 'roberta.encoder.layer.4.attention.self.key.weight', 'roberta.encoder.layer.3.attention.output.dense.weight', 'roberta.encoder.layer.2.attention.self.value.bias', 'roberta.encoder.layer.5.attention.self.value.bias', 'roberta.encoder.layer.2.attention.self.query.weight', 'roberta.encoder.layer.3.attention.self.query.bias', 'roberta.encoder.layer.5.intermediate.dense.bias', 'roberta.encoder.layer.1.attention.self.key.weight', 'roberta.encoder.layer.3.attention.self.key.weight', 'lm_head.bias', 'roberta.encoder.layer.3.attention.output.dense.bias', 'roberta.encoder.layer.4.output.LayerNorm.bias', 'roberta.encoder.layer.5.intermediate.dense.weight', 'roberta.encoder.layer.1.attention.output.dense.weight', 'roberta.encoder.layer.1.attention.output.dense.bias', 'roberta.encoder.layer.1.attention.output.LayerNorm.bias', 'roberta.encoder.layer.4.attention.self.value.weight', 'roberta.encoder.layer.2.output.LayerNorm.bias', 'roberta.encoder.layer.1.attention.self.value.weight', 'roberta.encoder.layer.5.output.LayerNorm.bias', 'roberta.encoder.layer.3.output.dense.bias', 'roberta.encoder.layer.4.attention.output.LayerNorm.bias', 'roberta.encoder.layer.4.output.dense.weight', 'roberta.encoder.layer.4.attention.self.query.weight', 'roberta.encoder.layer.4.attention.self.key.bias', 'roberta.encoder.layer.3.output.LayerNorm.bias', 'roberta.encoder.layer.4.output.dense.bias', 'roberta.encoder.layer.3.attention.self.query.weight', 'roberta.encoder.layer.3.output.dense.weight', 'roberta.encoder.layer.1.attention.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.output.LayerNorm.weight', 'roberta.encoder.layer.5.output.dense.weight', 'roberta.encoder.layer.2.output.LayerNorm.weight', 'roberta.encoder.layer.5.attention.output.dense.weight', 'roberta.encoder.layer.1.attention.self.key.bias', 'roberta.encoder.layer.3.intermediate.dense.weight', 'roberta.encoder.layer.2.attention.self.key.weight', 'roberta.encoder.layer.5.attention.output.LayerNorm.bias', 'roberta.encoder.layer.3.attention.output.LayerNorm.weight', 'roberta.encoder.layer.5.attention.self.query.bias', 'lm_head.decoder.weight', 'roberta.encoder.layer.2.intermediate.dense.bias', 'roberta.encoder.layer.5.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.self.value.bias', 'roberta.encoder.layer.2.attention.output.LayerNorm.weight', 'roberta.encoder.layer.2.attention.output.dense.weight', 'lm_head.dense.bias', 'roberta.encoder.layer.2.attention.output.LayerNorm.bias', 'roberta.encoder.layer.3.attention.self.value.weight', 'roberta.encoder.layer.2.attention.self.value.weight', 'roberta.encoder.layer.1.attention.self.value.bias', 'roberta.encoder.layer.5.attention.output.dense.bias', 'lm_head.layer_norm.weight', 'roberta.encoder.layer.2.attention.output.dense.bias', 'roberta.encoder.layer.4.attention.self.query.bias', 'roberta.encoder.layer.2.output.dense.bias', 'roberta.encoder.layer.2.intermediate.dense.weight', 'roberta.encoder.layer.5.output.dense.bias', 'roberta.encoder.layer.4.output.LayerNorm.weight', 'roberta.encoder.layer.1.attention.self.query.weight', 'roberta.encoder.layer.3.intermediate.dense.bias', 'roberta.encoder.layer.1.intermediate.dense.bias', 'roberta.encoder.layer.1.output.dense.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of RobertaModel were initialized from the model checkpoint at distilroberta-base.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaModel for predictions without further training.\n","loading configuration file https://huggingface.co/distilroberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/42d6b7c87cbac84fcdf35aa69504a5ccfca878fcee2a1a9b9ff7a3d1297f9094.aa95727ac70adfa1aaf5c88bea30a4f5e50869c68e68bce96ef1ec41b5facf46\n","Model config RobertaConfig {\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 6,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.10.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading configuration file https://huggingface.co/distilroberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/42d6b7c87cbac84fcdf35aa69504a5ccfca878fcee2a1a9b9ff7a3d1297f9094.aa95727ac70adfa1aaf5c88bea30a4f5e50869c68e68bce96ef1ec41b5facf46\n","Model config RobertaConfig {\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\",\n","    \"3\": \"LABEL_3\",\n","    \"4\": \"LABEL_4\",\n","    \"5\": \"LABEL_5\",\n","    \"6\": \"LABEL_6\",\n","    \"7\": \"LABEL_7\",\n","    \"8\": \"LABEL_8\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2,\n","    \"LABEL_3\": 3,\n","    \"LABEL_4\": 4,\n","    \"LABEL_5\": 5,\n","    \"LABEL_6\": 6,\n","    \"LABEL_7\": 7,\n","    \"LABEL_8\": 8\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 6,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.10.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","***** Running training *****\n","  Num examples = 2114\n","  Num Epochs = 8\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 2120\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1325' max='2120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1325/2120 05:30 < 03:18, 4.00 it/s, Epoch 5/8]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>0.436300</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.303400</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["aes_weight_coef : 1.0\n","ged_weight_coef : 1.0\n","ner_weight_coef : 1.0\n","\n","losses {'aes': 0.005108574232043222, 'ged': 0.12332790396934332, 'ner': 0.09223165233121362, 'total_loss': 0.22066813053260015}\n","\n","aes_metrics {'rmse_aes': 6.258327785172862, 'pearson_aes': 0.5221177025573297, 'spearman_aes': 0.5134023399632817, 'kappa_aes': 0.1837279093031009}\n","\n","ged               precision    recall  f1-score   support\n","\n","           0       0.92      0.77      0.84     25174\n","           1       0.29      0.58      0.38      3917\n","\n","    accuracy                           0.75     29091\n","   macro avg       0.60      0.68      0.61     29091\n","weighted avg       0.84      0.75      0.78     29091\n","\n","ged_metrics {'accuracy_ged': 0.7483414114330893, 'f1_score_macro_ged': 0.6132795921390506, 'f1_score_weighted_ged': 0.7802763983706339, 'f_0_5_ged': 0.48393234672304436}\n","\n","ner               precision    recall  f1-score   support\n","\n","           0  0.991783054 0.996445193 0.994108657     42759\n","           1  0.911145352 0.963083605 0.936394827      1842\n","           2  0.956456456 0.974751339 0.965517241      1307\n","           3  0.653556969 0.842654735 0.736156352      1341\n","           4  0.738441215 0.744340879 0.741379310       751\n","           5  0.867750678 0.871529668 0.869636067      1837\n","           6  0.736585366 0.587548638 0.653679654       257\n","           7  0.828693790 0.419739696 0.557235421       922\n","           8  0.858333333 0.297687861 0.442060086       346\n","\n","    accuracy                      0.965421907     51362\n","   macro avg  0.838082913 0.744197957 0.766240846     51362\n","weighted avg  0.965917578 0.965421907 0.963164692     51362\n","\n","ner_metrics {'accuracy_ner': 0.9654219072466026, 'f1_score_macro_ner': 0.7662408462268427, 'f1_score_weighted_ner': 0.96316469161163}\n","\n","epochs since best performance 0\n","\n","aes_weight_coef : 1.0\n","ged_weight_coef : 1.0\n","ner_weight_coef : 1.0\n","\n","losses {'aes': 0.003147578614135814, 'ged': 0.11531320976656537, 'ner': 0.05989114506993183, 'total_loss': 0.17835193345063302}\n","\n","aes_metrics {'rmse_aes': 4.908892158341047, 'pearson_aes': 0.5693814237809437, 'spearman_aes': 0.5766560889253095, 'kappa_aes': 0.42887884656767805}\n","\n","ged               precision    recall  f1-score   support\n","\n","           0       0.94      0.75      0.83     25174\n","           1       0.30      0.68      0.41      3917\n","\n","    accuracy                           0.74     29091\n","   macro avg       0.62      0.71      0.62     29091\n","weighted avg       0.85      0.74      0.78     29091\n","\n","ged_metrics {'accuracy_ged': 0.7401258121068371, 'f1_score_macro_ged': 0.6231654603303202, 'f1_score_weighted_ged': 0.7765699273947629, 'f_0_5_ged': 0.5402882078343819}\n","\n","ner               precision    recall  f1-score   support\n","\n","           0  0.994725665 0.996819383 0.995771423     42759\n","           1  0.917300863 0.981541802 0.948334645      1842\n","           2  0.974045802 0.976281561 0.975162400      1307\n","           3  0.826086957 0.892617450 0.858064516      1341\n","           4  0.876811594 0.805592543 0.839694656       751\n","           5  0.933444260 0.916167665 0.924725275      1837\n","           6  0.852140078 0.852140078 0.852140078       257\n","           7  0.896640827 0.752711497 0.818396226       922\n","           8  0.833976834 0.624277457 0.714049587       346\n","\n","    accuracy                      0.979732098     51362\n","   macro avg  0.900574764 0.866461048 0.880704312     51362\n","weighted avg  0.979546840 0.979732098 0.979326700     51362\n","\n","ner_metrics {'accuracy_ner': 0.9797320976597484, 'f1_score_macro_ner': 0.8807043117687079, 'f1_score_weighted_ner': 0.9793267000579757}\n","\n","epochs since best performance 0\n","\n","aes_weight_coef : 1.0\n","ged_weight_coef : 1.0\n","ner_weight_coef : 1.0\n","\n","losses {'aes': 0.0032405879153588482, 'ged': 0.11516598629397015, 'ner': 0.04969240504122058, 'total_loss': 0.1680989792505496}\n","\n","aes_metrics {'rmse_aes': 4.935697631653616, 'pearson_aes': 0.6541938941367454, 'spearman_aes': 0.6674551468105947, 'kappa_aes': 0.5419337841398085}\n","\n","ged               precision    recall  f1-score   support\n","\n","           0       0.93      0.83      0.88     25174\n","           1       0.36      0.61      0.45      3917\n","\n","    accuracy                           0.80     29091\n","   macro avg       0.64      0.72      0.66     29091\n","weighted avg       0.85      0.80      0.82     29091\n","\n","ged_metrics {'accuracy_ged': 0.799663126052731, 'f1_score_macro_ged': 0.6640004891406557, 'f1_score_weighted_ged': 0.8200070172899652, 'f_0_5_ged': 0.5342845641186206}\n","\n","ner               precision    recall  f1-score   support\n","\n","           0  0.995535506 0.996071003 0.995803182     42759\n","           1  0.952127660 0.971769815 0.961848469      1842\n","           2  0.986760125 0.969395562 0.978000772      1307\n","           3  0.861777151 0.911260254 0.885828199      1341\n","           4  0.876190476 0.857523302 0.866756393       751\n","           5  0.941752858 0.941752858 0.941752858      1837\n","           6  0.892720307 0.906614786 0.899613900       257\n","           7  0.885057471 0.835140998 0.859375000       922\n","           8  0.864406780 0.736994220 0.795631825       346\n","\n","    accuracy                      0.983256104     51362\n","   macro avg  0.917369815 0.902946978 0.909401177     51362\n","weighted avg  0.983213589 0.983256104 0.983162317     51362\n","\n","ner_metrics {'accuracy_ner': 0.9832561037342783, 'f1_score_macro_ner': 0.9094011774443675, 'f1_score_weighted_ner': 0.9831623174841763}\n","\n","epochs since best performance 0\n","\n","aes_weight_coef : 1.0\n","ged_weight_coef : 1.0\n","ner_weight_coef : 1.0\n","\n","losses {'aes': 0.006151691815534303, 'ged': 0.10983344981836718, 'ner': 0.04607718043722386, 'total_loss': 0.16206232207112534}\n","\n","aes_metrics {'rmse_aes': 6.855654600401044, 'pearson_aes': 0.6383278325840966, 'spearman_aes': 0.6583135863566156, 'kappa_aes': 0.3151687345420353}\n","\n","ged               precision    recall  f1-score   support\n","\n","           0       0.95      0.74      0.83     25174\n","           1       0.31      0.73      0.43      3917\n","\n","    accuracy                           0.74     29091\n","   macro avg       0.63      0.74      0.63     29091\n","weighted avg       0.86      0.74      0.78     29091\n","\n","ged_metrics {'accuracy_ged': 0.7421195558763879, 'f1_score_macro_ged': 0.6335409410999233, 'f1_score_weighted_ged': 0.779297531835844, 'f_0_5_ged': 0.5752389330987323}\n","\n","ner               precision    recall  f1-score   support\n","\n","           0  0.996050202 0.996702449 0.996376219     42759\n","           1  0.957424162 0.976655809 0.966944370      1842\n","           2  0.989843750 0.969395562 0.979512949      1307\n","           3  0.869747899 0.926174497 0.897074756      1341\n","           4  0.882591093 0.870838881 0.876675603       751\n","           5  0.959798995 0.935764834 0.947629548      1837\n","           6  0.899224806 0.902723735 0.900970874       257\n","           7  0.892013498 0.860086768 0.875759249       922\n","           8  0.854368932 0.763005780 0.806106870       346\n","\n","    accuracy                      0.984930493     51362\n","   macro avg  0.922340371 0.911260924 0.916338938     51362\n","weighted avg  0.984947415 0.984930493 0.984880930     51362\n","\n","ner_metrics {'accuracy_ner': 0.9849304933608505, 'f1_score_macro_ner': 0.9163389375837904, 'f1_score_weighted_ner': 0.9848809297127994}\n","\n","epochs since best performance 1\n","\n","aes_weight_coef : 1.0\n","ged_weight_coef : 1.0\n","ner_weight_coef : 1.0\n","\n","losses {'aes': 0.004496620913837538, 'ged': 0.1100624300712763, 'ner': 0.044899858685946745, 'total_loss': 0.15945890967106058}\n","\n","aes_metrics {'rmse_aes': 5.851163227180653, 'pearson_aes': 0.6526153698759183, 'spearman_aes': 0.669423070933278, 'kappa_aes': 0.4663721601153984}\n","\n","ged               precision    recall  f1-score   support\n","\n","           0       0.94      0.78      0.85     25174\n","           1       0.33      0.70      0.45      3917\n","\n","    accuracy                           0.77     29091\n","   macro avg       0.64      0.74      0.65     29091\n","weighted avg       0.86      0.77      0.80     29091\n","\n","ged_metrics {'accuracy_ged': 0.7687257227321165, 'f1_score_macro_ged': 0.6513970091666704, 'f1_score_weighted_ged': 0.7991754333096276, 'f_0_5_ged': 0.5722929271854786}\n","\n","ner               precision    recall  f1-score   support\n","\n","           0  0.996189185 0.996515353 0.996352242     42759\n","           1  0.963440860 0.972855592 0.968125338      1842\n","           2  0.988299532 0.969395562 0.978756277      1307\n","           3  0.905856190 0.911260254 0.908550186      1341\n","           4  0.895460798 0.866844208 0.880920162       751\n","           5  0.940106952 0.956995101 0.948475856      1837\n","           6  0.904580153 0.922178988 0.913294798       257\n","           7  0.871212121 0.873101952 0.872156013       922\n","           8  0.844444444 0.768786127 0.804841150       346\n","\n","    accuracy                      0.985319886     51362\n","   macro avg  0.923287804 0.915325904 0.919052447     51362\n","weighted avg  0.985252756 0.985319886 0.985264466     51362\n","\n","ner_metrics {'accuracy_ner': 0.9853198862972625, 'f1_score_macro_ner': 0.9190524468722779, 'f1_score_weighted_ner': 0.9852644658328781}\n","\n","epochs since best performance 2\n","\n","\n","test results {'rmse_aes': 5.300353761778547, 'pearson_aes': 0.7537072761342802, 'spearman_aes': 0.7575463671049684, 'kappa_aes': 0.5541538787173246, 'accuracy_ged': 0.7396392785571142, 'f1_score_macro_ged': 0.6365613538282816, 'f1_score_weighted_ged': 0.7714661587327821, 'f_0_5_ged': 0.5615290980755855, 'accuracy_ner': 0.9750403790244427, 'f1_score_macro_ner': 0.8636449541112912, 'f1_score_weighted_ner': 0.975523388671625, 'aes': 0.004999477105836074, 'ged': 0.15826472640037537, 'ner': 0.07421224608662583, 'total_loss': 0.23747644959283726, 'aes_weight_coef': 1.0, 'ged_weight_coef': 1.0, 'ner_weight_coef': 1.0}\n","some model info : ['aes', 'ged', 'ner']_distilroberta-base_lr4e-05\n","        bs8_freNone_share1\n","        outs{'aes': -1, 'ged': 2, 'ner': 2}_norm[40, 0]\n","        pri{'primary_task': 'aes', 'secondary_task': 'ged', 'aux_task': 'ner'}_optfixed\n","        scoscript_eslos\n","model saved to results/raw_results/ 1630829515\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["{'frozen_layers': None, 'lr': 4e-05, 'output_layer': 2, 'shared_encoder_n_layers': 2, 'tasks': ['aes', 'ged', 'ner']}\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["loading configuration file https://huggingface.co/distilroberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/42d6b7c87cbac84fcdf35aa69504a5ccfca878fcee2a1a9b9ff7a3d1297f9094.aa95727ac70adfa1aaf5c88bea30a4f5e50869c68e68bce96ef1ec41b5facf46\n","Model config RobertaConfig {\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"LABEL_0\": 0\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 6,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.10.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading weights file https://huggingface.co/distilroberta-base/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/7a0115a4c463f49bc7ab011872fc4a4b81be681a0434075955d29ac3388e225b.a6127d76576e81475313180aceb31a8688f7a649b80e380d26b5d30302dc83c1\n","Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight']\n","- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","loading configuration file https://huggingface.co/distilroberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/42d6b7c87cbac84fcdf35aa69504a5ccfca878fcee2a1a9b9ff7a3d1297f9094.aa95727ac70adfa1aaf5c88bea30a4f5e50869c68e68bce96ef1ec41b5facf46\n","Model config RobertaConfig {\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 2,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.10.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading weights file https://huggingface.co/distilroberta-base/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/7a0115a4c463f49bc7ab011872fc4a4b81be681a0434075955d29ac3388e225b.a6127d76576e81475313180aceb31a8688f7a649b80e380d26b5d30302dc83c1\n","Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaModel: ['roberta.encoder.layer.5.output.LayerNorm.bias', 'roberta.encoder.layer.4.attention.output.LayerNorm.bias', 'roberta.encoder.layer.4.output.dense.weight', 'roberta.encoder.layer.4.attention.self.query.weight', 'roberta.encoder.layer.4.attention.output.dense.weight', 'roberta.encoder.layer.4.attention.self.key.bias', 'roberta.encoder.layer.3.output.LayerNorm.bias', 'roberta.encoder.layer.4.output.dense.bias', 'roberta.encoder.layer.5.attention.self.key.bias', 'roberta.encoder.layer.3.attention.self.query.weight', 'roberta.encoder.layer.2.attention.self.query.bias', 'lm_head.layer_norm.bias', 'roberta.encoder.layer.3.output.dense.weight', 'roberta.encoder.layer.4.attention.output.LayerNorm.weight', 'roberta.encoder.layer.5.output.dense.weight', 'roberta.encoder.layer.2.output.LayerNorm.weight', 'roberta.encoder.layer.4.intermediate.dense.bias', 'roberta.encoder.layer.5.attention.output.dense.weight', 'lm_head.dense.weight', 'roberta.encoder.layer.5.attention.self.value.weight', 'roberta.encoder.layer.3.intermediate.dense.weight', 'roberta.encoder.layer.2.attention.self.key.weight', 'roberta.encoder.layer.5.attention.output.LayerNorm.bias', 'roberta.encoder.layer.3.attention.output.LayerNorm.weight', 'roberta.encoder.layer.5.attention.self.query.bias', 'lm_head.decoder.weight', 'roberta.encoder.layer.5.attention.self.key.weight', 'roberta.encoder.layer.3.attention.self.key.bias', 'roberta.encoder.layer.2.intermediate.dense.bias', 'roberta.encoder.layer.2.attention.self.key.bias', 'roberta.encoder.layer.4.intermediate.dense.weight', 'roberta.encoder.layer.5.output.LayerNorm.weight', 'roberta.encoder.layer.3.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.self.value.bias', 'roberta.encoder.layer.2.attention.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.output.dense.bias', 'roberta.encoder.layer.5.attention.self.query.weight', 'roberta.encoder.layer.3.attention.output.LayerNorm.bias', 'roberta.encoder.layer.2.attention.output.dense.weight', 'lm_head.dense.bias', 'roberta.encoder.layer.2.attention.output.LayerNorm.bias', 'roberta.encoder.layer.3.attention.self.value.weight', 'roberta.encoder.layer.3.attention.self.value.bias', 'roberta.encoder.layer.2.output.dense.weight', 'roberta.encoder.layer.2.attention.self.value.weight', 'roberta.encoder.layer.4.attention.self.key.weight', 'roberta.encoder.layer.3.attention.output.dense.weight', 'roberta.encoder.layer.5.attention.output.dense.bias', 'roberta.encoder.layer.2.attention.self.value.bias', 'roberta.encoder.layer.5.attention.self.value.bias', 'roberta.encoder.layer.2.attention.self.query.weight', 'lm_head.layer_norm.weight', 'roberta.encoder.layer.2.attention.output.dense.bias', 'roberta.encoder.layer.3.attention.self.query.bias', 'roberta.encoder.layer.2.output.dense.bias', 'roberta.encoder.layer.4.attention.self.query.bias', 'roberta.encoder.layer.3.attention.self.key.weight', 'lm_head.bias', 'roberta.encoder.layer.2.intermediate.dense.weight', 'roberta.encoder.layer.3.attention.output.dense.bias', 'roberta.encoder.layer.5.output.dense.bias', 'roberta.encoder.layer.4.output.LayerNorm.bias', 'roberta.encoder.layer.4.output.LayerNorm.weight', 'roberta.encoder.layer.5.intermediate.dense.weight', 'roberta.encoder.layer.3.intermediate.dense.bias', 'roberta.encoder.layer.5.intermediate.dense.bias', 'roberta.encoder.layer.5.attention.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.self.value.weight', 'roberta.encoder.layer.2.output.LayerNorm.bias', 'roberta.encoder.layer.3.output.dense.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of RobertaModel were initialized from the model checkpoint at distilroberta-base.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaModel for predictions without further training.\n","loading configuration file https://huggingface.co/distilroberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/42d6b7c87cbac84fcdf35aa69504a5ccfca878fcee2a1a9b9ff7a3d1297f9094.aa95727ac70adfa1aaf5c88bea30a4f5e50869c68e68bce96ef1ec41b5facf46\n","Model config RobertaConfig {\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 6,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.10.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading configuration file https://huggingface.co/distilroberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/42d6b7c87cbac84fcdf35aa69504a5ccfca878fcee2a1a9b9ff7a3d1297f9094.aa95727ac70adfa1aaf5c88bea30a4f5e50869c68e68bce96ef1ec41b5facf46\n","Model config RobertaConfig {\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\",\n","    \"3\": \"LABEL_3\",\n","    \"4\": \"LABEL_4\",\n","    \"5\": \"LABEL_5\",\n","    \"6\": \"LABEL_6\",\n","    \"7\": \"LABEL_7\",\n","    \"8\": \"LABEL_8\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2,\n","    \"LABEL_3\": 3,\n","    \"LABEL_4\": 4,\n","    \"LABEL_5\": 5,\n","    \"LABEL_6\": 6,\n","    \"LABEL_7\": 7,\n","    \"LABEL_8\": 8\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 6,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.10.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","***** Running training *****\n","  Num examples = 2114\n","  Num Epochs = 8\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 2120\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='2120' max='2120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2120/2120 10:08, Epoch 8/8]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>0.437800</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.299900</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.264700</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>0.246400</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["aes_weight_coef : 1.0\n","ged_weight_coef : 1.0\n","ner_weight_coef : 1.0\n","\n","losses {'aes': 0.003727530324181845, 'ged': 0.12784839092298997, 'ner': 0.07639353237179823, 'total_loss': 0.20796945361897004}\n","\n","aes_metrics {'rmse_aes': 5.326818938165629, 'pearson_aes': 0.5232752997382277, 'spearman_aes': 0.49750120267943576, 'kappa_aes': 0.23367976615784358}\n","\n","ged               precision    recall  f1-score   support\n","\n","           0       0.94      0.49      0.65     25174\n","           1       0.20      0.80      0.32      3917\n","\n","    accuracy                           0.54     29091\n","   macro avg       0.57      0.65      0.48     29091\n","weighted avg       0.84      0.54      0.60     29091\n","\n","ged_metrics {'accuracy_ged': 0.5362826991165652, 'f1_score_macro_ged': 0.483407743048856, 'f1_score_weighted_ged': 0.6041730746413451, 'f_0_5_ged': 0.49896939908038684}\n","\n","ner               precision    recall  f1-score   support\n","\n","           0  0.994924333 0.994784724 0.994854523     42759\n","           1  0.940021231 0.961454940 0.950617284      1842\n","           2  0.982087227 0.964804897 0.973369355      1307\n","           3  0.714625446 0.896346010 0.795236520      1341\n","           4  0.763546798 0.825565912 0.793346129       751\n","           5  0.911648846 0.881872618 0.896513558      1837\n","           6  0.756972112 0.739299611 0.748031496       257\n","           7  0.834048641 0.632321041 0.719309068       922\n","           8  0.790909091 0.502890173 0.614840989       346\n","\n","    accuracy                      0.972645146     51362\n","   macro avg  0.854309303 0.822148881 0.831790992     51362\n","weighted avg  0.973495993 0.972645146 0.972304581     51362\n","\n","ner_metrics {'accuracy_ner': 0.9726451462170477, 'f1_score_macro_ner': 0.8317909915920061, 'f1_score_weighted_ner': 0.9723045813889217}\n","\n","epochs since best performance 0\n","\n","aes_weight_coef : 1.0\n","ged_weight_coef : 1.0\n","ner_weight_coef : 1.0\n","\n","losses {'aes': 0.0035146392427038314, 'ged': 0.11542911446371744, 'ner': 0.052073870980462365, 'total_loss': 0.17101762468688364}\n","\n","aes_metrics {'rmse_aes': 5.139714648369758, 'pearson_aes': 0.6263527047672074, 'spearman_aes': 0.6281573764615832, 'kappa_aes': 0.42137430356238403}\n","\n","ged               precision    recall  f1-score   support\n","\n","           0       0.94      0.70      0.80     25174\n","           1       0.27      0.72      0.39      3917\n","\n","    accuracy                           0.70     29091\n","   macro avg       0.61      0.71      0.60     29091\n","weighted avg       0.85      0.70      0.75     29091\n","\n","ged_metrics {'accuracy_ged': 0.7040665497920319, 'f1_score_macro_ged': 0.5995498545853891, 'f1_score_weighted_ged': 0.7490392496875022, 'f_0_5_ged': 0.5408006158583525}\n","\n","ner               precision    recall  f1-score   support\n","\n","           0  0.995352965 0.996842770 0.996097310     42759\n","           1  0.937565036 0.978284473 0.957492030      1842\n","           2  0.982225657 0.972456006 0.977316417      1307\n","           3  0.851123596 0.903803132 0.876672694      1341\n","           4  0.867486339 0.845539281 0.856372218       751\n","           5  0.928800857 0.944474687 0.936572200      1837\n","           6  0.873076923 0.883268482 0.878143133       257\n","           7  0.932203390 0.775488069 0.846654825       922\n","           8  0.893382353 0.702312139 0.786407767       346\n","\n","    accuracy                      0.982516257     51362\n","   macro avg  0.917913013 0.889163227 0.901303177     51362\n","weighted avg  0.982498538 0.982516257 0.982259455     51362\n","\n","ner_metrics {'accuracy_ner': 0.9825162571550952, 'f1_score_macro_ner': 0.9013031772326434, 'f1_score_weighted_ner': 0.9822594551107353}\n","\n","epochs since best performance 0\n","\n","aes_weight_coef : 1.0\n","ged_weight_coef : 1.0\n","ner_weight_coef : 1.0\n","\n","losses {'aes': 0.0051860730488633, 'ged': 0.11119465495264808, 'ner': 0.043676673542968066, 'total_loss': 0.16005740154447945}\n","\n","aes_metrics {'rmse_aes': 6.268306523030496, 'pearson_aes': 0.6335187808219277, 'spearman_aes': 0.619526532758653, 'kappa_aes': 0.34998588766581984}\n","\n","ged               precision    recall  f1-score   support\n","\n","           0       0.94      0.75      0.84     25174\n","           1       0.31      0.70      0.43      3917\n","\n","    accuracy                           0.75     29091\n","   macro avg       0.62      0.73      0.63     29091\n","weighted avg       0.86      0.75      0.78     29091\n","\n","ged_metrics {'accuracy_ged': 0.7469320408373724, 'f1_score_macro_ged': 0.6326675053300685, 'f1_score_weighted_ged': 0.7823698924658934, 'f_0_5_ged': 0.5589633180322542}\n","\n","ner               precision    recall  f1-score   support\n","\n","           0  0.995517370 0.997216960 0.996366440     42759\n","           1  0.962162162 0.966340934 0.964247021      1842\n","           2  0.987460815 0.964039786 0.975609756      1307\n","           3  0.875177305 0.920208799 0.897128317      1341\n","           4  0.882352941 0.858854860 0.870445344       751\n","           5  0.937901499 0.953728906 0.945748988      1837\n","           6  0.914634146 0.875486381 0.894632207       257\n","           7  0.923627685 0.839479393 0.879545455       922\n","           8  0.848874598 0.763005780 0.803652968       346\n","\n","    accuracy                      0.984657918     51362\n","   macro avg  0.925300947 0.904262422 0.914152944     51362\n","weighted avg  0.984575803 0.984657918 0.984539491     51362\n","\n","ner_metrics {'accuracy_ner': 0.984657918305362, 'f1_score_macro_ner': 0.9141529439311399, 'f1_score_weighted_ner': 0.9845394906433803}\n","\n","epochs since best performance 0\n","\n","aes_weight_coef : 1.0\n","ged_weight_coef : 1.0\n","ner_weight_coef : 1.0\n","\n","losses {'aes': 0.0026080043401655764, 'ged': 0.11305957062299861, 'ner': 0.04084379388409298, 'total_loss': 0.15651136884725717}\n","\n","aes_metrics {'rmse_aes': 4.4643650786596245, 'pearson_aes': 0.6508456114806236, 'spearman_aes': 0.6551877834299128, 'kappa_aes': 0.5948699929725931}\n","\n","ged               precision    recall  f1-score   support\n","\n","           0       0.93      0.85      0.89     25174\n","           1       0.38      0.60      0.47      3917\n","\n","    accuracy                           0.82     29091\n","   macro avg       0.66      0.73      0.68     29091\n","weighted avg       0.86      0.82      0.83     29091\n","\n","ged_metrics {'accuracy_ged': 0.8167818225568045, 'f1_score_macro_ged': 0.6794573008802907, 'f1_score_weighted_ged': 0.8327637111149241, 'f_0_5_ged': 0.5412595752488418}\n","\n","ner               precision    recall  f1-score   support\n","\n","           0  0.996330661 0.996983091 0.996656769     42759\n","           1  0.963322546 0.969598263 0.966450216      1842\n","           2  0.990573449 0.964804897 0.977519380      1307\n","           3  0.888569375 0.921700224 0.904831625      1341\n","           4  0.897680764 0.876165113 0.886792453       751\n","           5  0.940482574 0.954817637 0.947595894      1837\n","           6  0.915708812 0.929961089 0.922779923       257\n","           7  0.908059024 0.867678959 0.887409872       922\n","           8  0.854889590 0.783236994 0.817496229       346\n","\n","    accuracy                      0.985845567     51362\n","   macro avg  0.928401866 0.918327363 0.923059151     51362\n","weighted avg  0.985806200 0.985845567 0.985790272     51362\n","\n","ner_metrics {'accuracy_ner': 0.985845566761419, 'f1_score_macro_ner': 0.9230591513725257, 'f1_score_weighted_ner': 0.9857902723838291}\n","\n","epochs since best performance 0\n","\n","aes_weight_coef : 1.0\n","ged_weight_coef : 1.0\n","ner_weight_coef : 1.0\n","\n","losses {'aes': 0.0032747398173913014, 'ged': 0.10856105976326522, 'ner': 0.039369681676806406, 'total_loss': 0.15120548125746291}\n","\n","aes_metrics {'rmse_aes': 5.063485843654437, 'pearson_aes': 0.6656337989174406, 'spearman_aes': 0.6794992694240728, 'kappa_aes': 0.5932970374036626}\n","\n","ged               precision    recall  f1-score   support\n","\n","           0       0.94      0.80      0.87     25174\n","           1       0.35      0.68      0.46      3917\n","\n","    accuracy                           0.79     29091\n","   macro avg       0.65      0.74      0.67     29091\n","weighted avg       0.86      0.79      0.81     29091\n","\n","ged_metrics {'accuracy_ged': 0.7879069127908975, 'f1_score_macro_ged': 0.6653025915022663, 'f1_score_weighted_ged': 0.8133232683712635, 'f_0_5_ged': 0.5717667312244459}\n","\n","ner               precision    recall  f1-score   support\n","\n","           0  0.996377404 0.997029865 0.996703528     42759\n","           1  0.959871589 0.973941368 0.966855295      1842\n","           2  0.989036805 0.966335119 0.977554180      1307\n","           3  0.926149209 0.916480239 0.921289355      1341\n","           4  0.917366947 0.872170439 0.894197952       751\n","           5  0.949435180 0.960805661 0.955086580      1837\n","           6  0.896678967 0.945525292 0.920454545       257\n","           7  0.888888889 0.885032538 0.886956522       922\n","           8  0.814705882 0.800578035 0.807580175       346\n","\n","    accuracy                      0.986604883     51362\n","   macro avg  0.926501208 0.924210951 0.925186459     51362\n","weighted avg  0.986561415 0.986604883 0.986563921     51362\n","\n","ner_metrics {'accuracy_ner': 0.9866048829874227, 'f1_score_macro_ner': 0.925186459145546, 'f1_score_weighted_ner': 0.9865639212606893}\n","\n","epochs since best performance 0\n","\n","aes_weight_coef : 1.0\n","ged_weight_coef : 1.0\n","ner_weight_coef : 1.0\n","\n","losses {'aes': 0.0043860946478712, 'ged': 0.11092640424883643, 'ner': 0.039541797463370616, 'total_loss': 0.15485429636007825}\n","\n","aes_metrics {'rmse_aes': 5.807083796728115, 'pearson_aes': 0.684317887329344, 'spearman_aes': 0.7103935939424025, 'kappa_aes': 0.4978375917600866}\n","\n","ged               precision    recall  f1-score   support\n","\n","           0       0.94      0.84      0.89     25174\n","           1       0.38      0.63      0.48      3917\n","\n","    accuracy                           0.81     29091\n","   macro avg       0.66      0.74      0.68     29091\n","weighted avg       0.86      0.81      0.83     29091\n","\n","ged_metrics {'accuracy_ged': 0.8136880822247431, 'f1_score_macro_ged': 0.6820849283000521, 'f1_score_weighted_ged': 0.8315473551300546, 'f_0_5_ged': 0.559774011299435}\n","\n","ner               precision    recall  f1-score   support\n","\n","           0  0.996796146 0.996842770 0.996819457     42759\n","           1  0.957006369 0.978827362 0.967793881      1842\n","           2  0.984520124 0.973221117 0.978838015      1307\n","           3  0.935015291 0.912005966 0.923367308      1341\n","           4  0.915977961 0.885486019 0.900473934       751\n","           5  0.946438136 0.961894393 0.954103672      1837\n","           6  0.900369004 0.949416342 0.924242424       257\n","           7  0.892039258 0.887201735 0.889613921       922\n","           8  0.830357143 0.806358382 0.818181818       346\n","\n","    accuracy                      0.987013746     51362\n","   macro avg  0.928724381 0.927917121 0.928159381     51362\n","weighted avg  0.986976760 0.987013746 0.986975701     51362\n","\n","ner_metrics {'accuracy_ner': 0.9870137455706554, 'f1_score_macro_ner': 0.9281593810780352, 'f1_score_weighted_ner': 0.9869757013115007}\n","\n","epochs since best performance 0\n","\n","aes_weight_coef : 1.0\n","ged_weight_coef : 1.0\n","ner_weight_coef : 1.0\n","\n","losses {'aes': 0.005620304841634839, 'ged': 0.11701632377713225, 'ner': 0.03935073246789533, 'total_loss': 0.16198736108666242}\n","\n","aes_metrics {'rmse_aes': 6.56907739167212, 'pearson_aes': 0.668289102894506, 'spearman_aes': 0.6912032671000055, 'kappa_aes': 0.44939290234869445}\n","\n","ged               precision    recall  f1-score   support\n","\n","           0       0.93      0.87      0.90     25174\n","           1       0.42      0.59      0.49      3917\n","\n","    accuracy                           0.83     29091\n","   macro avg       0.68      0.73      0.70     29091\n","weighted avg       0.86      0.83      0.85     29091\n","\n","ged_metrics {'accuracy_ged': 0.8342098930940841, 'f1_score_macro_ged': 0.6956153999043986, 'f1_score_weighted_ged': 0.8456970678480127, 'f_0_5_ged': 0.5466245521402978}\n","\n","ner               precision    recall  f1-score   support\n","\n","           0  0.996610566 0.997100026 0.996855236     42759\n","           1  0.956983537 0.978284473 0.967516779      1842\n","           2  0.985259891 0.971690895 0.978428351      1307\n","           3  0.908296943 0.930648770 0.919337017      1341\n","           4  0.906882591 0.894806924 0.900804290       751\n","           5  0.965669989 0.949373979 0.957452649      1837\n","           6  0.919540230 0.933852140 0.926640927       257\n","           7  0.902113459 0.879609544 0.890719385       922\n","           8  0.835866261 0.794797688 0.814814815       346\n","\n","    accuracy                      0.987052685     51362\n","   macro avg  0.930802608 0.925573827 0.928063272     51362\n","weighted avg  0.987011419 0.987052685 0.987013671     51362\n","\n","ner_metrics {'accuracy_ner': 0.9870526848642965, 'f1_score_macro_ner': 0.9280632718778141, 'f1_score_weighted_ner': 0.9870136710984786}\n","\n","epochs since best performance 1\n","\n","aes_weight_coef : 1.0\n","ged_weight_coef : 1.0\n","ner_weight_coef : 1.0\n","\n","losses {'aes': 0.00413048678879128, 'ged': 0.12268955624380777, 'ner': 0.0390724744214568, 'total_loss': 0.16589251745405587}\n","\n","aes_metrics {'rmse_aes': 5.573997169396881, 'pearson_aes': 0.6727617609827476, 'spearman_aes': 0.6955657586274648, 'kappa_aes': 0.5522043040343441}\n","\n","ged               precision    recall  f1-score   support\n","\n","           0       0.93      0.89      0.91     25174\n","           1       0.45      0.56      0.50      3917\n","\n","    accuracy                           0.85     29091\n","   macro avg       0.69      0.72      0.70     29091\n","weighted avg       0.86      0.85      0.85     29091\n","\n","ged_metrics {'accuracy_ged': 0.8476161011996838, 'f1_score_macro_ged': 0.7029349823756524, 'f1_score_weighted_ged': 0.8544218577003708, 'f_0_5_ged': 0.5301850048685492}\n","\n","ner               precision    recall  f1-score   support\n","\n","           0  0.996704067 0.997193573 0.996948760     42759\n","           1  0.965609887 0.975570033 0.970564407      1842\n","           2  0.985271318 0.972456006 0.978821717      1307\n","           3  0.928089888 0.923937360 0.926008969      1341\n","           4  0.913161465 0.896138482 0.904569892       751\n","           5  0.953225806 0.965160588 0.959156072      1837\n","           6  0.897435897 0.953307393 0.924528302       257\n","           7  0.908379888 0.881778742 0.894881673       922\n","           8  0.833836858 0.797687861 0.815361891       346\n","\n","    accuracy                      0.987617305     51362\n","   macro avg  0.931301675 0.929247782 0.930093520     51362\n","weighted avg  0.987550634 0.987617305 0.987568850     51362\n","\n","ner_metrics {'accuracy_ner': 0.9876173046220942, 'f1_score_macro_ner': 0.9300935204512152, 'f1_score_weighted_ner': 0.9875688499750378}\n","\n","epochs since best performance 2\n","\n","\n","test results {'rmse_aes': 5.3967582862307255, 'pearson_aes': 0.7295458209266984, 'spearman_aes': 0.7472847587938891, 'kappa_aes': 0.5803878004443547, 'accuracy_ged': 0.8187040748162993, 'f1_score_macro_ged': 0.6843222505294717, 'f1_score_weighted_ged': 0.827878229173173, 'f_0_5_ged': 0.51820634973515, 'accuracy_ner': 0.9775815656293744, 'f1_score_macro_ner': 0.8725936192988123, 'f1_score_weighted_ner': 0.9780691005311836, 'aes': 0.005102505353057668, 'ged': 0.18024237524895442, 'ner': 0.07434884041902565, 'total_loss': 0.2596937210210377, 'aes_weight_coef': 1.0, 'ged_weight_coef': 1.0, 'ner_weight_coef': 1.0}\n","some model info : ['aes', 'ged', 'ner']_distilroberta-base_lr4e-05\n","        bs8_freNone_share2\n","        outs{'aes': -1, 'ged': 2, 'ner': 2}_norm[40, 0]\n","        pri{'primary_task': 'aes', 'secondary_task': 'ged', 'aux_task': 'ner'}_optfixed\n","        scoscript_eslos\n","model saved to results/raw_results/ 1630830129\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["{'frozen_layers': None, 'lr': 4e-05, 'output_layer': 4, 'shared_encoder_n_layers': 0, 'tasks': ['aes', 'ged', 'ner']}\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["loading configuration file https://huggingface.co/distilroberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/42d6b7c87cbac84fcdf35aa69504a5ccfca878fcee2a1a9b9ff7a3d1297f9094.aa95727ac70adfa1aaf5c88bea30a4f5e50869c68e68bce96ef1ec41b5facf46\n","Model config RobertaConfig {\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"LABEL_0\": 0\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 6,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.10.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading weights file https://huggingface.co/distilroberta-base/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/7a0115a4c463f49bc7ab011872fc4a4b81be681a0434075955d29ac3388e225b.a6127d76576e81475313180aceb31a8688f7a649b80e380d26b5d30302dc83c1\n","Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight']\n","- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","loading configuration file https://huggingface.co/distilroberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/42d6b7c87cbac84fcdf35aa69504a5ccfca878fcee2a1a9b9ff7a3d1297f9094.aa95727ac70adfa1aaf5c88bea30a4f5e50869c68e68bce96ef1ec41b5facf46\n","Model config RobertaConfig {\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 6,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.10.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading configuration file https://huggingface.co/distilroberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/42d6b7c87cbac84fcdf35aa69504a5ccfca878fcee2a1a9b9ff7a3d1297f9094.aa95727ac70adfa1aaf5c88bea30a4f5e50869c68e68bce96ef1ec41b5facf46\n","Model config RobertaConfig {\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\",\n","    \"3\": \"LABEL_3\",\n","    \"4\": \"LABEL_4\",\n","    \"5\": \"LABEL_5\",\n","    \"6\": \"LABEL_6\",\n","    \"7\": \"LABEL_7\",\n","    \"8\": \"LABEL_8\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2,\n","    \"LABEL_3\": 3,\n","    \"LABEL_4\": 4,\n","    \"LABEL_5\": 5,\n","    \"LABEL_6\": 6,\n","    \"LABEL_7\": 7,\n","    \"LABEL_8\": 8\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 6,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.10.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","***** Running training *****\n","  Num examples = 2114\n","  Num Epochs = 8\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 2120\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='2120' max='2120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2120/2120 08:12, Epoch 8/8]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>0.381900</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.255300</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.220700</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>0.200800</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["aes_weight_coef : 1.0\n","ged_weight_coef : 1.0\n","ner_weight_coef : 1.0\n","\n","losses {'aes': 0.0035030287473874037, 'ged': 0.10948793000953141, 'ner': 0.05017772789091565, 'total_loss': 0.16316868664783446}\n","\n","aes_metrics {'rmse_aes': 5.177408189003023, 'pearson_aes': 0.5835503445322373, 'spearman_aes': 0.5807762661799234, 'kappa_aes': 0.34355573974305853}\n","\n","ged               precision    recall  f1-score   support\n","\n","           0       0.95      0.73      0.82     25174\n","           1       0.30      0.75      0.43      3917\n","\n","    accuracy                           0.73     29091\n","   macro avg       0.62      0.74      0.63     29091\n","weighted avg       0.86      0.73      0.77     29091\n","\n","ged_metrics {'accuracy_ged': 0.7301227183665051, 'f1_score_macro_ged': 0.626066691561888, 'f1_score_weighted_ged': 0.770203206731036, 'f_0_5_ged': 0.577933793536241}\n","\n","ner               precision    recall  f1-score   support\n","\n","           0  0.995191410 0.997076639 0.996133132     42759\n","           1  0.969338354 0.978284473 0.973790867      1842\n","           2  0.984520124 0.973221117 0.978838015      1307\n","           3  0.811053985 0.941088740 0.871246117      1341\n","           4  0.825699746 0.864181092 0.844502277       751\n","           5  0.953151143 0.930321176 0.941597796      1837\n","           6  0.864197531 0.817120623 0.840000000       257\n","           7  0.905882353 0.751626898 0.821576763       922\n","           8  0.872807018 0.575144509 0.693379791       346\n","\n","    accuracy                      0.981854289     51362\n","   macro avg  0.909093518 0.869785030 0.884562751     51362\n","weighted avg  0.982120140 0.981854289 0.981509312     51362\n","\n","ner_metrics {'accuracy_ner': 0.9818542891631946, 'f1_score_macro_ner': 0.8845627509728652, 'f1_score_weighted_ner': 0.9815093115259705}\n","\n","epochs since best performance 0\n","\n","aes_weight_coef : 1.0\n","ged_weight_coef : 1.0\n","ner_weight_coef : 1.0\n","\n","losses {'aes': 0.0035586107067417266, 'ged': 0.10240438580513, 'ner': 0.03269747404251681, 'total_loss': 0.13866047055438854}\n","\n","aes_metrics {'rmse_aes': 5.174724898753341, 'pearson_aes': 0.6612765335592646, 'spearman_aes': 0.6574687069655992, 'kappa_aes': 0.4224066390041493}\n","\n","ged               precision    recall  f1-score   support\n","\n","           0       0.95      0.76      0.84     25174\n","           1       0.33      0.77      0.46      3917\n","\n","    accuracy                           0.76     29091\n","   macro avg       0.64      0.76      0.65     29091\n","weighted avg       0.87      0.76      0.79     29091\n","\n","ged_metrics {'accuracy_ged': 0.7567976350073906, 'f1_score_macro_ged': 0.6510208719348058, 'f1_score_weighted_ged': 0.7914115220742872, 'f_0_5_ged': 0.6042052686699428}\n","\n","ner               precision    recall  f1-score   support\n","\n","           0  0.996821167 0.997380668 0.997100839     42759\n","           1  0.982513661 0.976112921 0.979302832      1842\n","           2  0.989053948 0.967865340 0.978344934      1307\n","           3  0.902282454 0.943325876 0.922347794      1341\n","           4  0.898717949 0.933422104 0.915741346       751\n","           5  0.954765751 0.965160588 0.959935030      1837\n","           6  0.929133858 0.918287938 0.923679061       257\n","           7  0.920930233 0.859002169 0.888888889       922\n","           8  0.880126183 0.806358382 0.841628959       346\n","\n","    accuracy                      0.988201394     51362\n","   macro avg  0.939371689 0.929657332 0.934107743     51362\n","weighted avg  0.988216412 0.988201394 0.988157450     51362\n","\n","ner_metrics {'accuracy_ner': 0.9882013940267124, 'f1_score_macro_ner': 0.9341077427087756, 'f1_score_weighted_ner': 0.9881574495253351}\n","\n","epochs since best performance 0\n","\n","aes_weight_coef : 1.0\n","ged_weight_coef : 1.0\n","ner_weight_coef : 1.0\n","\n","losses {'aes': 0.006490529319921205, 'ged': 0.10058546828669171, 'ner': 0.029630115808009408, 'total_loss': 0.13670611341462233}\n","\n","aes_metrics {'rmse_aes': 7.074995092263708, 'pearson_aes': 0.6736218706010356, 'spearman_aes': 0.6587141133444414, 'kappa_aes': 0.3887083315033598}\n","\n","ged               precision    recall  f1-score   support\n","\n","           0       0.95      0.83      0.88     25174\n","           1       0.39      0.70      0.50      3917\n","\n","    accuracy                           0.81     29091\n","   macro avg       0.67      0.77      0.69     29091\n","weighted avg       0.87      0.81      0.83     29091\n","\n","ged_metrics {'accuracy_ged': 0.8106630916778385, 'f1_score_macro_ged': 0.6918676576732372, 'f1_score_weighted_ged': 0.8316691602273981, 'f_0_5_ged': 0.605821151060187}\n","\n","ner               precision    recall  f1-score   support\n","\n","           0  0.996404222 0.998012114 0.997207520     42759\n","           1  0.981521739 0.980456026 0.980988593      1842\n","           2  0.989938080 0.978576894 0.984224702      1307\n","           3  0.940196821 0.926174497 0.933132983      1341\n","           4  0.956896552 0.886817577 0.920525225       751\n","           5  0.956776948 0.976047904 0.966316357      1837\n","           6  0.917910448 0.957198444 0.937142857       257\n","           7  0.915836102 0.896963124 0.906301370       922\n","           8  0.855882353 0.841040462 0.848396501       346\n","\n","    accuracy                      0.989525330     51362\n","   macro avg  0.945707029 0.937920782 0.941581790     51362\n","weighted avg  0.989457807 0.989525330 0.989461639     51362\n","\n","ner_metrics {'accuracy_ner': 0.9895253300105136, 'f1_score_macro_ner': 0.9415817897067813, 'f1_score_weighted_ner': 0.9894616389963327}\n","\n","epochs since best performance 0\n","\n","aes_weight_coef : 1.0\n","ged_weight_coef : 1.0\n","ner_weight_coef : 1.0\n","\n","losses {'aes': 0.006455608751884726, 'ged': 0.10746823285901269, 'ner': 0.02731964706854765, 'total_loss': 0.14124348867944506}\n","\n","aes_metrics {'rmse_aes': 6.993052107469083, 'pearson_aes': 0.6818854038650568, 'spearman_aes': 0.673318976693694, 'kappa_aes': 0.41536877332990085}\n","\n","ged               precision    recall  f1-score   support\n","\n","           0       0.94      0.89      0.91     25174\n","           1       0.46      0.63      0.54      3917\n","\n","    accuracy                           0.85     29091\n","   macro avg       0.70      0.76      0.72     29091\n","weighted avg       0.88      0.85      0.86     29091\n","\n","ged_metrics {'accuracy_ged': 0.8524629610532467, 'f1_score_macro_ged': 0.7242882297577373, 'f1_score_weighted_ged': 0.86165199396992, 'f_0_5_ged': 0.5907554624648926}\n","\n","ner               precision    recall  f1-score   support\n","\n","           0  0.997731684 0.997825019 0.997778349     42759\n","           1  0.976856835 0.985342020 0.981081081      1842\n","           2  0.987701768 0.983167559 0.985429448      1307\n","           3  0.938745387 0.948545861 0.943620178      1341\n","           4  0.956521739 0.908122503 0.931693989       751\n","           5  0.966955580 0.971692978 0.969318490      1837\n","           6  0.942748092 0.961089494 0.951830443       257\n","           7  0.910367171 0.914316703 0.912337662       922\n","           8  0.866863905 0.846820809 0.856725146       346\n","\n","    accuracy                      0.990771387     51362\n","   macro avg  0.949388018 0.946324772 0.947757199     51362\n","weighted avg  0.990759473 0.990771387 0.990753274     51362\n","\n","ner_metrics {'accuracy_ner': 0.9907713874070324, 'f1_score_macro_ner': 0.9477571986149458, 'f1_score_weighted_ner': 0.9907532736943206}\n","\n","epochs since best performance 0\n","\n","aes_weight_coef : 1.0\n","ged_weight_coef : 1.0\n","ner_weight_coef : 1.0\n","\n","losses {'aes': 0.004047664088132077, 'ged': 0.10231282613998235, 'ner': 0.027423894073445955, 'total_loss': 0.1337843843015604}\n","\n","aes_metrics {'rmse_aes': 5.581467349880117, 'pearson_aes': 0.6857316430367545, 'spearman_aes': 0.6832298690246352, 'kappa_aes': 0.5359058660667936}\n","\n","ged               precision    recall  f1-score   support\n","\n","           0       0.95      0.86      0.90     25174\n","           1       0.43      0.68      0.53      3917\n","\n","    accuracy                           0.84     29091\n","   macro avg       0.69      0.77      0.71     29091\n","weighted avg       0.88      0.84      0.85     29091\n","\n","ged_metrics {'accuracy_ged': 0.835172390086281, 'f1_score_macro_ged': 0.7137672432206925, 'f1_score_weighted_ged': 0.8499811779257391, 'f_0_5_ged': 0.6108421629521374}\n","\n","ner               precision    recall  f1-score   support\n","\n","           0  0.997755489 0.998035501 0.997895475     42759\n","           1  0.978004292 0.989685125 0.983810038      1842\n","           2  0.988461538 0.983167559 0.985807442      1307\n","           3  0.947486872 0.941834452 0.944652206      1341\n","           4  0.964488636 0.904127830 0.933333333       751\n","           5  0.963519313 0.977681002 0.970548500      1837\n","           6  0.922222222 0.968871595 0.944971537       257\n","           7  0.905376344 0.913232104 0.909287257       922\n","           8  0.892638037 0.841040462 0.866071429       346\n","\n","    accuracy                      0.991063432     51362\n","   macro avg  0.951105860 0.946408403 0.948486357     51362\n","weighted avg  0.991042926 0.991063432 0.991027060     51362\n","\n","ner_metrics {'accuracy_ner': 0.9910634321093416, 'f1_score_macro_ner': 0.948486357479529, 'f1_score_weighted_ner': 0.9910270595079786}\n","\n","epochs since best performance 0\n","\n","aes_weight_coef : 1.0\n","ged_weight_coef : 1.0\n","ner_weight_coef : 1.0\n","\n","losses {'aes': 0.0029306163968041885, 'ged': 0.10857348802477815, 'ner': 0.02742049866897422, 'total_loss': 0.13892460309055654}\n","\n","aes_metrics {'rmse_aes': 4.814618941884763, 'pearson_aes': 0.6792279978106694, 'spearman_aes': 0.6644432470292287, 'kappa_aes': 0.6052860877142028}\n","\n","ged               precision    recall  f1-score   support\n","\n","           0       0.94      0.88      0.91     25174\n","           1       0.46      0.65      0.54      3917\n","\n","    accuracy                           0.85     29091\n","   macro avg       0.70      0.77      0.72     29091\n","weighted avg       0.88      0.85      0.86     29091\n","\n","ged_metrics {'accuracy_ged': 0.8491629713657145, 'f1_score_macro_ged': 0.7241715503395744, 'f1_score_weighted_ged': 0.8598475262754708, 'f_0_5_ged': 0.6020979349922386}\n","\n","ner               precision    recall  f1-score   support\n","\n","           0  0.997895524 0.998058888 0.997977200     42759\n","           1  0.972785486 0.989685125 0.981162540      1842\n","           2  0.985462892 0.985462892 0.985462892      1307\n","           3  0.937728938 0.954511559 0.946045824      1341\n","           4  0.962131837 0.913448735 0.937158470       751\n","           5  0.973784817 0.970604246 0.972191930      1837\n","           6  0.929104478 0.968871595 0.948571429       257\n","           7  0.915754923 0.907809111 0.911764706       922\n","           8  0.901234568 0.843930636 0.871641791       346\n","\n","    accuracy                      0.991277598     51362\n","   macro avg  0.952875940 0.948042532 0.950219642     51362\n","weighted avg  0.991252616 0.991277598 0.991242485     51362\n","\n","ner_metrics {'accuracy_ner': 0.9912775982243682, 'f1_score_macro_ner': 0.9502196424311425, 'f1_score_weighted_ner': 0.9912424845538278}\n","\n","epochs since best performance 1\n","\n","aes_weight_coef : 1.0\n","ged_weight_coef : 1.0\n","ner_weight_coef : 1.0\n","\n","losses {'aes': 0.004267916451533174, 'ged': 0.1228648590487103, 'ner': 0.027604026335486493, 'total_loss': 0.15473680183573}\n","\n","aes_metrics {'rmse_aes': 5.740934883216612, 'pearson_aes': 0.6918079886484864, 'spearman_aes': 0.6869711357490692, 'kappa_aes': 0.5339930462690559}\n","\n","ged               precision    recall  f1-score   support\n","\n","           0       0.93      0.91      0.92     25174\n","           1       0.51      0.58      0.54      3917\n","\n","    accuracy                           0.87     29091\n","   macro avg       0.72      0.75      0.73     29091\n","weighted avg       0.88      0.87      0.87     29091\n","\n","ged_metrics {'accuracy_ged': 0.8683441614244956, 'f1_score_macro_ged': 0.7335560902678535, 'f1_score_weighted_ged': 0.8720312740954471, 'f_0_5_ged': 0.5669693811721501}\n","\n","ner               precision    recall  f1-score   support\n","\n","           0  0.997848859 0.998058888 0.997953863     42759\n","           1  0.977491961 0.990228013 0.983818770      1842\n","           2  0.987730061 0.985462892 0.986595174      1307\n","           3  0.935766423 0.956002983 0.945776466      1341\n","           4  0.954230236 0.916111851 0.934782609       751\n","           5  0.971211298 0.973326075 0.972267537      1837\n","           6  0.932835821 0.972762646 0.952380952       257\n","           7  0.919691969 0.906724512 0.913162206       922\n","           8  0.911111111 0.829479769 0.868381241       346\n","\n","    accuracy                      0.991374946     51362\n","   macro avg  0.954213082 0.947573070 0.950568758     51362\n","weighted avg  0.991337308 0.991374946 0.991330246     51362\n","\n","ner_metrics {'accuracy_ner': 0.9913749464584712, 'f1_score_macro_ner': 0.9505687575590406, 'f1_score_weighted_ner': 0.9913302458776133}\n","\n","epochs since best performance 0\n","\n","aes_weight_coef : 1.0\n","ged_weight_coef : 1.0\n","ner_weight_coef : 1.0\n","\n","losses {'aes': 0.004158321183261483, 'ged': 0.12315744300221287, 'ner': 0.027549746574909793, 'total_loss': 0.15486551076038416}\n","\n","aes_metrics {'rmse_aes': 5.6408726669234825, 'pearson_aes': 0.6864634637328085, 'spearman_aes': 0.6810787559775876, 'kappa_aes': 0.5594327160339971}\n","\n","ged               precision    recall  f1-score   support\n","\n","           0       0.94      0.91      0.92     25174\n","           1       0.51      0.60      0.55      3917\n","\n","    accuracy                           0.87     29091\n","   macro avg       0.72      0.75      0.73     29091\n","weighted avg       0.88      0.87      0.87     29091\n","\n","ged_metrics {'accuracy_ged': 0.8670035406139356, 'f1_score_macro_ged': 0.7346373548498082, 'f1_score_weighted_ged': 0.8715841090008866, 'f_0_5_ged': 0.5759755616870319}\n","\n","ner               precision    recall  f1-score   support\n","\n","           0  0.997849060 0.998152436 0.998000725     42759\n","           1  0.979043525 0.989142237 0.984066973      1842\n","           2  0.989222479 0.983167559 0.986185725      1307\n","           3  0.945022288 0.948545861 0.946780796      1341\n","           4  0.960618847 0.909454061 0.934336525       751\n","           5  0.964535196 0.977136636 0.970795024      1837\n","           6  0.926199262 0.976653696 0.950757576       257\n","           7  0.917030568 0.911062907 0.914036997       922\n","           8  0.898461538 0.843930636 0.870342772       346\n","\n","    accuracy                      0.991394416     51362\n","   macro avg  0.953109196 0.948582892 0.950589235     51362\n","weighted avg  0.991361197 0.991394416 0.991355569     51362\n","\n","ner_metrics {'accuracy_ner': 0.9913944161052919, 'f1_score_macro_ner': 0.9505892348228235, 'f1_score_weighted_ner': 0.9913555692386806}\n","\n","epochs since best performance 1\n","\n","\n","test results {'rmse_aes': 5.271780217978237, 'pearson_aes': 0.7809887544294833, 'spearman_aes': 0.7860980564262474, 'kappa_aes': 0.6315233467145573, 'accuracy_ged': 0.8521309285237141, 'f1_score_macro_ged': 0.7234480796056958, 'f1_score_weighted_ged': 0.854933531994215, 'f_0_5_ged': 0.5502317857884177, 'accuracy_ner': 0.9816087003338, 'f1_score_macro_ner': 0.8907771455479726, 'f1_score_weighted_ner': 0.9820488994668192, 'aes': 0.004915995922471795, 'ged': 0.18916051444553195, 'ner': 0.07134176781844526, 'total_loss': 0.265418278186449, 'aes_weight_coef': 1.0, 'ged_weight_coef': 1.0, 'ner_weight_coef': 1.0}\n","some model info : ['aes', 'ged', 'ner']_distilroberta-base_lr4e-05\n","        bs8_freNone_share0\n","        outs{'aes': -1, 'ged': 4, 'ner': 4}_norm[40, 0]\n","        pri{'primary_task': 'aes', 'secondary_task': 'ged', 'aux_task': 'ner'}_optfixed\n","        scoscript_eslos\n","model saved to results/raw_results/ 1630830626\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["{'frozen_layers': None, 'lr': 4e-05, 'output_layer': 4, 'shared_encoder_n_layers': 1, 'tasks': ['aes', 'ged', 'ner']}\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["loading configuration file https://huggingface.co/distilroberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/42d6b7c87cbac84fcdf35aa69504a5ccfca878fcee2a1a9b9ff7a3d1297f9094.aa95727ac70adfa1aaf5c88bea30a4f5e50869c68e68bce96ef1ec41b5facf46\n","Model config RobertaConfig {\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"LABEL_0\": 0\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 6,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.10.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading weights file https://huggingface.co/distilroberta-base/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/7a0115a4c463f49bc7ab011872fc4a4b81be681a0434075955d29ac3388e225b.a6127d76576e81475313180aceb31a8688f7a649b80e380d26b5d30302dc83c1\n","Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight']\n","- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","loading configuration file https://huggingface.co/distilroberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/42d6b7c87cbac84fcdf35aa69504a5ccfca878fcee2a1a9b9ff7a3d1297f9094.aa95727ac70adfa1aaf5c88bea30a4f5e50869c68e68bce96ef1ec41b5facf46\n","Model config RobertaConfig {\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 1,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.10.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading weights file https://huggingface.co/distilroberta-base/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/7a0115a4c463f49bc7ab011872fc4a4b81be681a0434075955d29ac3388e225b.a6127d76576e81475313180aceb31a8688f7a649b80e380d26b5d30302dc83c1\n","Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaModel: ['roberta.encoder.layer.4.attention.output.dense.weight', 'roberta.encoder.layer.1.output.LayerNorm.bias', 'roberta.encoder.layer.1.attention.self.query.bias', 'roberta.encoder.layer.5.attention.self.key.bias', 'roberta.encoder.layer.2.attention.self.query.bias', 'lm_head.layer_norm.bias', 'roberta.encoder.layer.4.intermediate.dense.bias', 'lm_head.dense.weight', 'roberta.encoder.layer.5.attention.self.value.weight', 'roberta.encoder.layer.1.intermediate.dense.weight', 'roberta.encoder.layer.1.output.LayerNorm.weight', 'roberta.encoder.layer.5.attention.self.key.weight', 'roberta.encoder.layer.3.attention.self.key.bias', 'roberta.encoder.layer.1.output.dense.weight', 'roberta.encoder.layer.2.attention.self.key.bias', 'roberta.encoder.layer.4.intermediate.dense.weight', 'roberta.encoder.layer.3.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.output.dense.bias', 'roberta.encoder.layer.5.attention.self.query.weight', 'roberta.encoder.layer.3.attention.output.LayerNorm.bias', 'roberta.encoder.layer.3.attention.self.value.bias', 'roberta.encoder.layer.5.attention.output.LayerNorm.weight', 'roberta.encoder.layer.2.output.dense.weight', 'roberta.encoder.layer.4.attention.self.key.weight', 'roberta.encoder.layer.3.attention.output.dense.weight', 'roberta.encoder.layer.2.attention.self.value.bias', 'roberta.encoder.layer.5.attention.self.value.bias', 'roberta.encoder.layer.2.attention.self.query.weight', 'roberta.encoder.layer.3.attention.self.query.bias', 'roberta.encoder.layer.5.intermediate.dense.bias', 'roberta.encoder.layer.1.attention.self.key.weight', 'roberta.encoder.layer.3.attention.self.key.weight', 'lm_head.bias', 'roberta.encoder.layer.3.attention.output.dense.bias', 'roberta.encoder.layer.4.output.LayerNorm.bias', 'roberta.encoder.layer.5.intermediate.dense.weight', 'roberta.encoder.layer.1.attention.output.dense.weight', 'roberta.encoder.layer.1.attention.output.dense.bias', 'roberta.encoder.layer.1.attention.output.LayerNorm.bias', 'roberta.encoder.layer.4.attention.self.value.weight', 'roberta.encoder.layer.2.output.LayerNorm.bias', 'roberta.encoder.layer.1.attention.self.value.weight', 'roberta.encoder.layer.5.output.LayerNorm.bias', 'roberta.encoder.layer.3.output.dense.bias', 'roberta.encoder.layer.4.attention.output.LayerNorm.bias', 'roberta.encoder.layer.4.output.dense.weight', 'roberta.encoder.layer.4.attention.self.query.weight', 'roberta.encoder.layer.4.attention.self.key.bias', 'roberta.encoder.layer.3.output.LayerNorm.bias', 'roberta.encoder.layer.4.output.dense.bias', 'roberta.encoder.layer.3.attention.self.query.weight', 'roberta.encoder.layer.3.output.dense.weight', 'roberta.encoder.layer.1.attention.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.output.LayerNorm.weight', 'roberta.encoder.layer.5.output.dense.weight', 'roberta.encoder.layer.2.output.LayerNorm.weight', 'roberta.encoder.layer.5.attention.output.dense.weight', 'roberta.encoder.layer.1.attention.self.key.bias', 'roberta.encoder.layer.3.intermediate.dense.weight', 'roberta.encoder.layer.2.attention.self.key.weight', 'roberta.encoder.layer.5.attention.output.LayerNorm.bias', 'roberta.encoder.layer.3.attention.output.LayerNorm.weight', 'roberta.encoder.layer.5.attention.self.query.bias', 'lm_head.decoder.weight', 'roberta.encoder.layer.2.intermediate.dense.bias', 'roberta.encoder.layer.5.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.self.value.bias', 'roberta.encoder.layer.2.attention.output.LayerNorm.weight', 'roberta.encoder.layer.2.attention.output.dense.weight', 'lm_head.dense.bias', 'roberta.encoder.layer.2.attention.output.LayerNorm.bias', 'roberta.encoder.layer.3.attention.self.value.weight', 'roberta.encoder.layer.2.attention.self.value.weight', 'roberta.encoder.layer.1.attention.self.value.bias', 'roberta.encoder.layer.5.attention.output.dense.bias', 'lm_head.layer_norm.weight', 'roberta.encoder.layer.2.attention.output.dense.bias', 'roberta.encoder.layer.4.attention.self.query.bias', 'roberta.encoder.layer.2.output.dense.bias', 'roberta.encoder.layer.2.intermediate.dense.weight', 'roberta.encoder.layer.5.output.dense.bias', 'roberta.encoder.layer.4.output.LayerNorm.weight', 'roberta.encoder.layer.1.attention.self.query.weight', 'roberta.encoder.layer.3.intermediate.dense.bias', 'roberta.encoder.layer.1.intermediate.dense.bias', 'roberta.encoder.layer.1.output.dense.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of RobertaModel were initialized from the model checkpoint at distilroberta-base.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaModel for predictions without further training.\n","loading configuration file https://huggingface.co/distilroberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/42d6b7c87cbac84fcdf35aa69504a5ccfca878fcee2a1a9b9ff7a3d1297f9094.aa95727ac70adfa1aaf5c88bea30a4f5e50869c68e68bce96ef1ec41b5facf46\n","Model config RobertaConfig {\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 6,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.10.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading configuration file https://huggingface.co/distilroberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/42d6b7c87cbac84fcdf35aa69504a5ccfca878fcee2a1a9b9ff7a3d1297f9094.aa95727ac70adfa1aaf5c88bea30a4f5e50869c68e68bce96ef1ec41b5facf46\n","Model config RobertaConfig {\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\",\n","    \"3\": \"LABEL_3\",\n","    \"4\": \"LABEL_4\",\n","    \"5\": \"LABEL_5\",\n","    \"6\": \"LABEL_6\",\n","    \"7\": \"LABEL_7\",\n","    \"8\": \"LABEL_8\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2,\n","    \"LABEL_3\": 3,\n","    \"LABEL_4\": 4,\n","    \"LABEL_5\": 5,\n","    \"LABEL_6\": 6,\n","    \"LABEL_7\": 7,\n","    \"LABEL_8\": 8\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 6,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.10.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","***** Running training *****\n","  Num examples = 2114\n","  Num Epochs = 8\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 2120\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1590' max='2120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1590/2120 07:12 < 02:24, 3.67 it/s, Epoch 6/8]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>0.389700</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.257700</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.223500</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["aes_weight_coef : 1.0\n","ged_weight_coef : 1.0\n","ner_weight_coef : 1.0\n","\n","losses {'aes': 0.003502201722111813, 'ged': 0.11027931127437325, 'ner': 0.06240327270744845, 'total_loss': 0.1761847857039335}\n","\n","aes_metrics {'rmse_aes': 5.189465825646755, 'pearson_aes': 0.5787957957229423, 'spearman_aes': 0.5642335790034257, 'kappa_aes': 0.29752317277009566}\n","\n","ged               precision    recall  f1-score   support\n","\n","           0       0.94      0.77      0.85     25174\n","           1       0.32      0.70      0.44      3917\n","\n","    accuracy                           0.76     29091\n","   macro avg       0.63      0.74      0.65     29091\n","weighted avg       0.86      0.76      0.79     29091\n","\n","ged_metrics {'accuracy_ged': 0.763019490564092, 'f1_score_macro_ged': 0.6463500087110533, 'f1_score_weighted_ged': 0.7947755982586051, 'f_0_5_ged': 0.5685161397256868}\n","\n","ner               precision    recall  f1-score   support\n","\n","           0  0.994983434 0.997287121 0.996133945     42759\n","           1  0.961558996 0.977741585 0.969582773      1842\n","           2  0.985384615 0.980107116 0.982738780      1307\n","           3  0.746286393 0.936614467 0.830687831      1341\n","           4  0.793060719 0.852197071 0.821566110       751\n","           5  0.957998765 0.844311377 0.897569444      1837\n","           6  0.857777778 0.750972763 0.800829876       257\n","           7  0.835946924 0.751626898 0.791547687       922\n","           8  0.892857143 0.433526012 0.583657588       346\n","\n","    accuracy                      0.977532028     51362\n","   macro avg  0.891761641 0.836042712 0.852701559     51362\n","weighted avg  0.978542676 0.977532028 0.977015143     51362\n","\n","ner_metrics {'accuracy_ner': 0.9775320275690199, 'f1_score_macro_ner': 0.8527015593050783, 'f1_score_weighted_ner': 0.9770151433455451}\n","\n","epochs since best performance 0\n","\n","aes_weight_coef : 1.0\n","ged_weight_coef : 1.0\n","ner_weight_coef : 1.0\n","\n","losses {'aes': 0.004558811873890633, 'ged': 0.1029927765214166, 'ner': 0.03781600272672814, 'total_loss': 0.14536759112203537}\n","\n","aes_metrics {'rmse_aes': 5.951190357119041, 'pearson_aes': 0.6051494012031887, 'spearman_aes': 0.5980789783560826, 'kappa_aes': 0.39297646447397727}\n","\n","ged               precision    recall  f1-score   support\n","\n","           0       0.95      0.79      0.86     25174\n","           1       0.35      0.73      0.48      3917\n","\n","    accuracy                           0.78     29091\n","   macro avg       0.65      0.76      0.67     29091\n","weighted avg       0.87      0.78      0.81     29091\n","\n","ged_metrics {'accuracy_ged': 0.7840912997146884, 'f1_score_macro_ged': 0.6698202612251702, 'f1_score_weighted_ged': 0.8117543190241469, 'f_0_5_ged': 0.6001348617666892}\n","\n","ner               precision    recall  f1-score   support\n","\n","           0  0.996448598 0.997404055 0.996926098     42759\n","           1  0.975067751 0.976655809 0.975861134      1842\n","           2  0.984579800 0.977046672 0.980798771      1307\n","           3  0.908230153 0.929903057 0.918938836      1341\n","           4  0.907734057 0.890812250 0.899193548       751\n","           5  0.936880543 0.977681002 0.956846031      1837\n","           6  0.864963504 0.922178988 0.892655367       257\n","           7  0.921875000 0.831887202 0.874572406       922\n","           8  0.909407666 0.754335260 0.824644550       346\n","\n","    accuracy                      0.987130563     51362\n","   macro avg  0.933909674 0.917544922 0.924492971     51362\n","weighted avg  0.987065926 0.987130563 0.986982904     51362\n","\n","ner_metrics {'accuracy_ner': 0.987130563451579, 'f1_score_macro_ner': 0.9244929711659151, 'f1_score_weighted_ner': 0.986982903922081}\n","\n","epochs since best performance 0\n","\n","aes_weight_coef : 1.0\n","ged_weight_coef : 1.0\n","ner_weight_coef : 1.0\n","\n","losses {'aes': 0.003959470547649057, 'ged': 0.10371516887531725, 'ner': 0.031805599519852984, 'total_loss': 0.13948023894281927}\n","\n","aes_metrics {'rmse_aes': 5.49621081594705, 'pearson_aes': 0.6591256710260491, 'spearman_aes': 0.6466477699451081, 'kappa_aes': 0.4787780206374218}\n","\n","ged               precision    recall  f1-score   support\n","\n","           0       0.94      0.85      0.90     25174\n","           1       0.42      0.67      0.52      3917\n","\n","    accuracy                           0.83     29091\n","   macro avg       0.68      0.76      0.71     29091\n","weighted avg       0.87      0.83      0.84     29091\n","\n","ged_metrics {'accuracy_ged': 0.8291224089924719, 'f1_score_macro_ged': 0.7057251898354306, 'f1_score_weighted_ged': 0.8449679272609124, 'f_0_5_ged': 0.6001181603344847}\n","\n","ner               precision    recall  f1-score   support\n","\n","           0  0.997101178 0.997497603 0.997299351     42759\n","           1  0.985197368 0.975570033 0.980360065      1842\n","           2  0.991412959 0.971690895 0.981452859      1307\n","           3  0.923636364 0.947054437 0.935198822      1341\n","           4  0.930362117 0.889480692 0.909462219       751\n","           5  0.973713034 0.967882417 0.970788971      1837\n","           6  0.912878788 0.937743191 0.925143954       257\n","           7  0.902702703 0.905639913 0.904168923       922\n","           8  0.793565684 0.855491329 0.823365786       346\n","\n","    accuracy                      0.989194346     51362\n","   macro avg  0.934507799 0.938672279 0.936360106     51362\n","weighted avg  0.989312024 0.989194346 0.989230218     51362\n","\n","ner_metrics {'accuracy_ner': 0.9891943460145632, 'f1_score_macro_ner': 0.9363601055631214, 'f1_score_weighted_ner': 0.9892302183312656}\n","\n","epochs since best performance 0\n","\n","aes_weight_coef : 1.0\n","ged_weight_coef : 1.0\n","ner_weight_coef : 1.0\n","\n","losses {'aes': 0.00306759272203889, 'ged': 0.09852370966312497, 'ner': 0.032317137659722286, 'total_loss': 0.13390844004488614}\n","\n","aes_metrics {'rmse_aes': 4.829021064816806, 'pearson_aes': 0.6784970172359053, 'spearman_aes': 0.6669987177437431, 'kappa_aes': 0.5626051151191789}\n","\n","ged               precision    recall  f1-score   support\n","\n","           0       0.95      0.82      0.88     25174\n","           1       0.39      0.73      0.51      3917\n","\n","    accuracy                           0.81     29091\n","   macro avg       0.67      0.78      0.69     29091\n","weighted avg       0.88      0.81      0.83     29091\n","\n","ged_metrics {'accuracy_ged': 0.8078443504864047, 'f1_score_macro_ged': 0.693448665075246, 'f1_score_weighted_ged': 0.8302844697449325, 'f_0_5_ged': 0.6209093667374626}\n","\n","ner               precision    recall  f1-score   support\n","\n","           0  0.997264374 0.997497603 0.997380975     42759\n","           1  0.981481481 0.978284473 0.979880370      1842\n","           2  0.986892830 0.979342005 0.983102919      1307\n","           3  0.959658650 0.922445936 0.940684411      1341\n","           4  0.943422914 0.888149134 0.914951989       751\n","           5  0.960385439 0.976592270 0.968421053      1837\n","           6  0.885304659 0.961089494 0.921641791       257\n","           7  0.894456290 0.909978308 0.902150538       922\n","           8  0.791556728 0.867052023 0.827586207       346\n","\n","    accuracy                      0.989408512     51362\n","   macro avg  0.933380374 0.942270139 0.937311139     51362\n","weighted avg  0.989554860 0.989408512 0.989436432     51362\n","\n","ner_metrics {'accuracy_ner': 0.98940851212959, 'f1_score_macro_ner': 0.9373111389871455, 'f1_score_weighted_ner': 0.9894364321197033}\n","\n","epochs since best performance 0\n","\n","aes_weight_coef : 1.0\n","ged_weight_coef : 1.0\n","ner_weight_coef : 1.0\n","\n","losses {'aes': 0.006474021064160868, 'ged': 0.10604984053345613, 'ner': 0.03182636018365968, 'total_loss': 0.14435022178127668}\n","\n","aes_metrics {'rmse_aes': 7.009913614937696, 'pearson_aes': 0.6616096488282494, 'spearman_aes': 0.6702407533594122, 'kappa_aes': 0.37625610767954265}\n","\n","ged               precision    recall  f1-score   support\n","\n","           0       0.94      0.87      0.91     25174\n","           1       0.45      0.66      0.53      3917\n","\n","    accuracy                           0.84     29091\n","   macro avg       0.69      0.77      0.72     29091\n","weighted avg       0.88      0.84      0.86     29091\n","\n","ged_metrics {'accuracy_ged': 0.8434911140902684, 'f1_score_macro_ged': 0.7194857942385592, 'f1_score_weighted_ged': 0.855768551145176, 'f_0_5_ged': 0.6041860465116279}\n","\n","ner               precision    recall  f1-score   support\n","\n","           0  0.997497076 0.997287121 0.997392087     42759\n","           1  0.978366685 0.982084691 0.980222162      1842\n","           2  0.985462892 0.985462892 0.985462892      1307\n","           3  0.948042169 0.938851603 0.943424504      1341\n","           4  0.953521127 0.901464714 0.926762491       751\n","           5  0.970254191 0.976592270 0.973412914      1837\n","           6  0.905454545 0.968871595 0.936090226       257\n","           7  0.905016009 0.919739696 0.912318451       922\n","           8  0.829131653 0.855491329 0.842105263       346\n","\n","    accuracy                      0.990284646     51362\n","   macro avg  0.941416261 0.947316212 0.944132332     51362\n","weighted avg  0.990341320 0.990284646 0.990293390     51362\n","\n","ner_metrics {'accuracy_ner': 0.9902846462365172, 'f1_score_macro_ner': 0.9441323321945223, 'f1_score_weighted_ner': 0.9902933904507858}\n","\n","epochs since best performance 1\n","\n","aes_weight_coef : 1.0\n","ged_weight_coef : 1.0\n","ner_weight_coef : 1.0\n","\n","losses {'aes': 0.005663166353262441, 'ged': 0.10825369524401288, 'ner': 0.03198452568937873, 'total_loss': 0.14590138728665406}\n","\n","aes_metrics {'rmse_aes': 6.581750864659376, 'pearson_aes': 0.6703441787502796, 'spearman_aes': 0.6846689836847507, 'kappa_aes': 0.42618629173989453}\n","\n","ged               precision    recall  f1-score   support\n","\n","           0       0.94      0.87      0.91     25174\n","           1       0.45      0.66      0.54      3917\n","\n","    accuracy                           0.85     29091\n","   macro avg       0.70      0.77      0.72     29091\n","weighted avg       0.88      0.85      0.86     29091\n","\n","ged_metrics {'accuracy_ged': 0.8453817331820838, 'f1_score_macro_ged': 0.7216182151223921, 'f1_score_weighted_ged': 0.8572495551953346, 'f_0_5_ged': 0.6057356027045931}\n","\n","ner               precision    recall  f1-score   support\n","\n","           0  0.997218066 0.997614537 0.997416262     42759\n","           1  0.976781857 0.982084691 0.979426096      1842\n","           2  0.986923077 0.981637337 0.984273111      1307\n","           3  0.936811168 0.950782998 0.943745374      1341\n","           4  0.928859060 0.921438083 0.925133690       751\n","           5  0.975877193 0.968971149 0.972411909      1837\n","           6  0.913533835 0.945525292 0.929254302       257\n","           7  0.915477497 0.904555315 0.909983633       922\n","           8  0.886850153 0.838150289 0.861812779       346\n","\n","    accuracy                      0.990284646     51362\n","   macro avg  0.946481323 0.943417743 0.944828573     51362\n","weighted avg  0.990253687 0.990284646 0.990260093     51362\n","\n","ner_metrics {'accuracy_ner': 0.9902846462365172, 'f1_score_macro_ner': 0.9448285729580215, 'f1_score_weighted_ner': 0.9902600930442575}\n","\n","epochs since best performance 2\n","\n","\n","test results {'rmse_aes': 5.757241816471958, 'pearson_aes': 0.7733948858169419, 'spearman_aes': 0.7790383101659661, 'kappa_aes': 0.5510475557033587, 'accuracy_ged': 0.8269071476285905, 'f1_score_macro_ged': 0.7118793209459039, 'f1_score_weighted_ged': 0.8387664888326498, 'f_0_5_ged': 0.5927634143172664, 'accuracy_ner': 0.979907397437278, 'f1_score_macro_ner': 0.885481631302254, 'f1_score_weighted_ner': 0.9803800006093747, 'aes': 0.005821889332894768, 'ged': 0.1626164090065729, 'ner': 0.07320635513003383, 'total_loss': 0.2416446534695015, 'aes_weight_coef': 1.0, 'ged_weight_coef': 1.0, 'ner_weight_coef': 1.0}\n","some model info : ['aes', 'ged', 'ner']_distilroberta-base_lr4e-05\n","        bs8_freNone_share1\n","        outs{'aes': -1, 'ged': 4, 'ner': 4}_norm[40, 0]\n","        pri{'primary_task': 'aes', 'secondary_task': 'ged', 'aux_task': 'ner'}_optfixed\n","        scoscript_eslos\n","model saved to results/raw_results/ 1630831064\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["{'frozen_layers': None, 'lr': 4e-05, 'output_layer': 4, 'shared_encoder_n_layers': 2, 'tasks': ['aes', 'ged', 'ner']}\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["loading configuration file https://huggingface.co/distilroberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/42d6b7c87cbac84fcdf35aa69504a5ccfca878fcee2a1a9b9ff7a3d1297f9094.aa95727ac70adfa1aaf5c88bea30a4f5e50869c68e68bce96ef1ec41b5facf46\n","Model config RobertaConfig {\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"LABEL_0\": 0\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 6,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.10.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading weights file https://huggingface.co/distilroberta-base/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/7a0115a4c463f49bc7ab011872fc4a4b81be681a0434075955d29ac3388e225b.a6127d76576e81475313180aceb31a8688f7a649b80e380d26b5d30302dc83c1\n","Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight']\n","- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","loading configuration file https://huggingface.co/distilroberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/42d6b7c87cbac84fcdf35aa69504a5ccfca878fcee2a1a9b9ff7a3d1297f9094.aa95727ac70adfa1aaf5c88bea30a4f5e50869c68e68bce96ef1ec41b5facf46\n","Model config RobertaConfig {\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 2,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.10.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading weights file https://huggingface.co/distilroberta-base/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/7a0115a4c463f49bc7ab011872fc4a4b81be681a0434075955d29ac3388e225b.a6127d76576e81475313180aceb31a8688f7a649b80e380d26b5d30302dc83c1\n","Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaModel: ['roberta.encoder.layer.5.output.LayerNorm.bias', 'roberta.encoder.layer.4.attention.output.LayerNorm.bias', 'roberta.encoder.layer.4.output.dense.weight', 'roberta.encoder.layer.4.attention.self.query.weight', 'roberta.encoder.layer.4.attention.output.dense.weight', 'roberta.encoder.layer.4.attention.self.key.bias', 'roberta.encoder.layer.3.output.LayerNorm.bias', 'roberta.encoder.layer.4.output.dense.bias', 'roberta.encoder.layer.5.attention.self.key.bias', 'roberta.encoder.layer.3.attention.self.query.weight', 'roberta.encoder.layer.2.attention.self.query.bias', 'lm_head.layer_norm.bias', 'roberta.encoder.layer.3.output.dense.weight', 'roberta.encoder.layer.4.attention.output.LayerNorm.weight', 'roberta.encoder.layer.5.output.dense.weight', 'roberta.encoder.layer.2.output.LayerNorm.weight', 'roberta.encoder.layer.4.intermediate.dense.bias', 'roberta.encoder.layer.5.attention.output.dense.weight', 'lm_head.dense.weight', 'roberta.encoder.layer.5.attention.self.value.weight', 'roberta.encoder.layer.3.intermediate.dense.weight', 'roberta.encoder.layer.2.attention.self.key.weight', 'roberta.encoder.layer.5.attention.output.LayerNorm.bias', 'roberta.encoder.layer.3.attention.output.LayerNorm.weight', 'roberta.encoder.layer.5.attention.self.query.bias', 'lm_head.decoder.weight', 'roberta.encoder.layer.5.attention.self.key.weight', 'roberta.encoder.layer.3.attention.self.key.bias', 'roberta.encoder.layer.2.intermediate.dense.bias', 'roberta.encoder.layer.2.attention.self.key.bias', 'roberta.encoder.layer.4.intermediate.dense.weight', 'roberta.encoder.layer.5.output.LayerNorm.weight', 'roberta.encoder.layer.3.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.self.value.bias', 'roberta.encoder.layer.2.attention.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.output.dense.bias', 'roberta.encoder.layer.5.attention.self.query.weight', 'roberta.encoder.layer.3.attention.output.LayerNorm.bias', 'roberta.encoder.layer.2.attention.output.dense.weight', 'lm_head.dense.bias', 'roberta.encoder.layer.2.attention.output.LayerNorm.bias', 'roberta.encoder.layer.3.attention.self.value.weight', 'roberta.encoder.layer.3.attention.self.value.bias', 'roberta.encoder.layer.2.output.dense.weight', 'roberta.encoder.layer.2.attention.self.value.weight', 'roberta.encoder.layer.4.attention.self.key.weight', 'roberta.encoder.layer.3.attention.output.dense.weight', 'roberta.encoder.layer.5.attention.output.dense.bias', 'roberta.encoder.layer.2.attention.self.value.bias', 'roberta.encoder.layer.5.attention.self.value.bias', 'roberta.encoder.layer.2.attention.self.query.weight', 'lm_head.layer_norm.weight', 'roberta.encoder.layer.2.attention.output.dense.bias', 'roberta.encoder.layer.3.attention.self.query.bias', 'roberta.encoder.layer.2.output.dense.bias', 'roberta.encoder.layer.4.attention.self.query.bias', 'roberta.encoder.layer.3.attention.self.key.weight', 'lm_head.bias', 'roberta.encoder.layer.2.intermediate.dense.weight', 'roberta.encoder.layer.3.attention.output.dense.bias', 'roberta.encoder.layer.5.output.dense.bias', 'roberta.encoder.layer.4.output.LayerNorm.bias', 'roberta.encoder.layer.4.output.LayerNorm.weight', 'roberta.encoder.layer.5.intermediate.dense.weight', 'roberta.encoder.layer.3.intermediate.dense.bias', 'roberta.encoder.layer.5.intermediate.dense.bias', 'roberta.encoder.layer.5.attention.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.self.value.weight', 'roberta.encoder.layer.2.output.LayerNorm.bias', 'roberta.encoder.layer.3.output.dense.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of RobertaModel were initialized from the model checkpoint at distilroberta-base.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaModel for predictions without further training.\n","loading configuration file https://huggingface.co/distilroberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/42d6b7c87cbac84fcdf35aa69504a5ccfca878fcee2a1a9b9ff7a3d1297f9094.aa95727ac70adfa1aaf5c88bea30a4f5e50869c68e68bce96ef1ec41b5facf46\n","Model config RobertaConfig {\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 6,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.10.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading configuration file https://huggingface.co/distilroberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/42d6b7c87cbac84fcdf35aa69504a5ccfca878fcee2a1a9b9ff7a3d1297f9094.aa95727ac70adfa1aaf5c88bea30a4f5e50869c68e68bce96ef1ec41b5facf46\n","Model config RobertaConfig {\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\",\n","    \"3\": \"LABEL_3\",\n","    \"4\": \"LABEL_4\",\n","    \"5\": \"LABEL_5\",\n","    \"6\": \"LABEL_6\",\n","    \"7\": \"LABEL_7\",\n","    \"8\": \"LABEL_8\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2,\n","    \"LABEL_3\": 3,\n","    \"LABEL_4\": 4,\n","    \"LABEL_5\": 5,\n","    \"LABEL_6\": 6,\n","    \"LABEL_7\": 7,\n","    \"LABEL_8\": 8\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 6,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.10.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","***** Running training *****\n","  Num examples = 2114\n","  Num Epochs = 8\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 2120\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1325' max='2120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1325/2120 06:52 < 04:07, 3.21 it/s, Epoch 5/8]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>0.403400</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.259900</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["aes_weight_coef : 1.0\n","ged_weight_coef : 1.0\n","ner_weight_coef : 1.0\n","\n","losses {'aes': 0.0047645261402913305, 'ged': 0.112123544826064, 'ner': 0.06314476024965908, 'total_loss': 0.1800328312160144}\n","\n","aes_metrics {'rmse_aes': 6.096447052723961, 'pearson_aes': 0.5964670151106171, 'spearman_aes': 0.6021456419751331, 'kappa_aes': 0.31253526803708187}\n","\n","ged               precision    recall  f1-score   support\n","\n","           0       0.94      0.83      0.88     25174\n","           1       0.37      0.63      0.46      3917\n","\n","    accuracy                           0.80     29091\n","   macro avg       0.65      0.73      0.67     29091\n","weighted avg       0.86      0.80      0.82     29091\n","\n","ged_metrics {'accuracy_ged': 0.8036506135918325, 'f1_score_macro_ged': 0.6715057489333531, 'f1_score_weighted_ged': 0.8237470035019563, 'f_0_5_ged': 0.5502210709660131}\n","\n","ner               precision    recall  f1-score   support\n","\n","           0  0.996351560 0.996328258 0.996339909     42759\n","           1  0.956567797 0.980456026 0.968364611      1842\n","           2  0.968349661 0.983167559 0.975702354      1307\n","           3  0.745823389 0.932140194 0.828637720      1341\n","           4  0.811250000 0.864181092 0.836879433       751\n","           5  0.946859903 0.853565596 0.897795591      1837\n","           6  0.808695652 0.723735409 0.763860370       257\n","           7  0.861809045 0.744034707 0.798603027       922\n","           8  0.857142857 0.572254335 0.686308492       346\n","\n","    accuracy                      0.977960360     51362\n","   macro avg  0.883649985 0.849984797 0.861387945     51362\n","weighted avg  0.978902709 0.977960360 0.977775510     51362\n","\n","ner_metrics {'accuracy_ner': 0.9779603597990733, 'f1_score_macro_ner': 0.8613879451222393, 'f1_score_weighted_ner': 0.9777755099335479}\n","\n","epochs since best performance 0\n","\n","aes_weight_coef : 1.0\n","ged_weight_coef : 1.0\n","ner_weight_coef : 1.0\n","\n","losses {'aes': 0.002694755045393872, 'ged': 0.1028108437393987, 'ner': 0.037919964966212596, 'total_loss': 0.14342556375100515}\n","\n","aes_metrics {'rmse_aes': 4.576510072581994, 'pearson_aes': 0.6511851685692778, 'spearman_aes': 0.6600811837835945, 'kappa_aes': 0.541312583188287}\n","\n","ged               precision    recall  f1-score   support\n","\n","           0       0.95      0.81      0.87     25174\n","           1       0.37      0.71      0.48      3917\n","\n","    accuracy                           0.80     29091\n","   macro avg       0.66      0.76      0.68     29091\n","weighted avg       0.87      0.80      0.82     29091\n","\n","ged_metrics {'accuracy_ged': 0.7951256402323743, 'f1_score_macro_ged': 0.6781286553007915, 'f1_score_weighted_ged': 0.819927213296724, 'f_0_5_ged': 0.5999227567266018}\n","\n","ner               precision    recall  f1-score   support\n","\n","           0  0.996774571 0.997380668 0.997077527     42759\n","           1  0.978260870 0.977198697 0.977729495      1842\n","           2  0.983024691 0.974751339 0.978870534      1307\n","           3  0.940412529 0.917971663 0.929056604      1341\n","           4  0.912925170 0.893475366 0.903095559       751\n","           5  0.933021807 0.978225367 0.955089025      1837\n","           6  0.796116505 0.957198444 0.869257951       257\n","           7  0.910138249 0.856832972 0.882681564       922\n","           8  0.857142857 0.728323699 0.787500000       346\n","\n","    accuracy                      0.987266851     51362\n","   macro avg  0.923090805 0.920150913 0.920039806     51362\n","weighted avg  0.987283119 0.987266851 0.987163553     51362\n","\n","ner_metrics {'accuracy_ner': 0.9872668509793232, 'f1_score_macro_ner': 0.920039806444836, 'f1_score_weighted_ner': 0.9871635530864462}\n","\n","epochs since best performance 0\n","\n","aes_weight_coef : 1.0\n","ged_weight_coef : 1.0\n","ner_weight_coef : 1.0\n","\n","losses {'aes': 0.0028827340981035037, 'ged': 0.10384539670722429, 'ner': 0.03209480167323247, 'total_loss': 0.13882293247856026}\n","\n","aes_metrics {'rmse_aes': 4.7007682587234845, 'pearson_aes': 0.6870986203280882, 'spearman_aes': 0.6718868857609869, 'kappa_aes': 0.6029387209884789}\n","\n","ged               precision    recall  f1-score   support\n","\n","           0       0.94      0.85      0.90     25174\n","           1       0.42      0.68      0.52      3917\n","\n","    accuracy                           0.83     29091\n","   macro avg       0.68      0.76      0.71     29091\n","weighted avg       0.87      0.83      0.84     29091\n","\n","ged_metrics {'accuracy_ged': 0.8284005362483242, 'f1_score_macro_ged': 0.7054968682894713, 'f1_score_weighted_ged': 0.8445147616434509, 'f_0_5_ged': 0.6016145856954964}\n","\n","ner               precision    recall  f1-score   support\n","\n","           0  0.997008857 0.997801632 0.997405087     42759\n","           1  0.987390351 0.977741585 0.982542280      1842\n","           2  0.987711214 0.983932670 0.985818321      1307\n","           3  0.919623461 0.947054437 0.933137399      1341\n","           4  0.960451977 0.905459387 0.932145305       751\n","           5  0.979546711 0.964616222 0.972024136      1837\n","           6  0.937743191 0.937743191 0.937743191       257\n","           7  0.903260870 0.901301518 0.902280130       922\n","           8  0.809782609 0.861271676 0.834733894       346\n","\n","    accuracy                      0.989914723     51362\n","   macro avg  0.942502138 0.941880258 0.941981083     51362\n","weighted avg  0.990007133 0.989914723 0.989935331     51362\n","\n","ner_metrics {'accuracy_ner': 0.9899147229469257, 'f1_score_macro_ner': 0.9419810825668292, 'f1_score_weighted_ner': 0.9899353308113427}\n","\n","epochs since best performance 0\n","\n","aes_weight_coef : 1.0\n","ged_weight_coef : 1.0\n","ner_weight_coef : 1.0\n","\n","losses {'aes': 0.0024523506330889327, 'ged': 0.09840073973633522, 'ner': 0.03251613048446733, 'total_loss': 0.1333692208538915}\n","\n","aes_metrics {'rmse_aes': 4.318886173283313, 'pearson_aes': 0.6773715670310325, 'spearman_aes': 0.6682506948851599, 'kappa_aes': 0.6388164403273675}\n","\n","ged               precision    recall  f1-score   support\n","\n","           0       0.96      0.79      0.86     25174\n","           1       0.36      0.77      0.49      3917\n","\n","    accuracy                           0.78     29091\n","   macro avg       0.66      0.78      0.68     29091\n","weighted avg       0.88      0.78      0.81     29091\n","\n","ged_metrics {'accuracy_ged': 0.7842287992850022, 'f1_score_macro_ged': 0.6764529194092328, 'f1_score_weighted_ged': 0.8129027037165129, 'f_0_5_ged': 0.626143356061866}\n","\n","ner               precision    recall  f1-score   support\n","\n","           0  0.997752967 0.996912931 0.997332772     42759\n","           1  0.979902227 0.979370250 0.979636166      1842\n","           2  0.992242048 0.978576894 0.985362096      1307\n","           3  0.929824561 0.948545861 0.939091916      1341\n","           4  0.911111111 0.928095872 0.919525066       751\n","           5  0.978165939 0.975503538 0.976832925      1837\n","           6  0.938931298 0.957198444 0.947976879       257\n","           7  0.902702703 0.905639913 0.904168923       922\n","           8  0.829131653 0.855491329 0.842105263       346\n","\n","    accuracy                      0.989992602     51362\n","   macro avg  0.939973834 0.947259448 0.943559112     51362\n","weighted avg  0.990095132 0.989992602 0.990036992     51362\n","\n","ner_metrics {'accuracy_ner': 0.9899926015342082, 'f1_score_macro_ner': 0.9435591115735108, 'f1_score_weighted_ner': 0.9900369915169471}\n","\n","epochs since best performance 1\n","\n","aes_weight_coef : 1.0\n","ged_weight_coef : 1.0\n","ner_weight_coef : 1.0\n","\n","losses {'aes': 0.005190740371945985, 'ged': 0.10201981109242107, 'ner': 0.031567730031214485, 'total_loss': 0.13877828149558152}\n","\n","aes_metrics {'rmse_aes': 6.363961030678928, 'pearson_aes': 0.6771336804095193, 'spearman_aes': 0.6702931450753353, 'kappa_aes': 0.47015535568274724}\n","\n","ged               precision    recall  f1-score   support\n","\n","           0       0.95      0.84      0.89     25174\n","           1       0.40      0.72      0.52      3917\n","\n","    accuracy                           0.82     29091\n","   macro avg       0.68      0.78      0.70     29091\n","weighted avg       0.88      0.82      0.84     29091\n","\n","ged_metrics {'accuracy_ged': 0.8194974390705029, 'f1_score_macro_ged': 0.7033694979984377, 'f1_score_weighted_ged': 0.8389882016227038, 'f_0_5_ged': 0.6225706713780919}\n","\n","ner               precision    recall  f1-score   support\n","\n","           0  0.997359073 0.998035501 0.997697172     42759\n","           1  0.984126984 0.976112921 0.980103570      1842\n","           2  0.989205860 0.981637337 0.985407066      1307\n","           3  0.939259259 0.945563013 0.942400595      1341\n","           4  0.955678670 0.918774967 0.936863544       751\n","           5  0.975000000 0.976592270 0.975795485      1837\n","           6  0.898550725 0.964980545 0.930581614       257\n","           7  0.910675381 0.906724512 0.908695652       922\n","           8  0.848837209 0.843930636 0.846376812       346\n","\n","    accuracy                      0.990693509     51362\n","   macro avg  0.944299240 0.945816856 0.944880168     51362\n","weighted avg  0.990700027 0.990693509 0.990684056     51362\n","\n","ner_metrics {'accuracy_ner': 0.99069350881975, 'f1_score_macro_ner': 0.9448801677679306, 'f1_score_weighted_ner': 0.9906840557489757}\n","\n","epochs since best performance 2\n","\n","\n","test results {'rmse_aes': 5.2221483446310994, 'pearson_aes': 0.7855496422615895, 'spearman_aes': 0.7761318199875694, 'kappa_aes': 0.621905254600547, 'accuracy_ged': 0.8010420841683367, 'f1_score_macro_ged': 0.6942368626413744, 'f1_score_weighted_ged': 0.8201925660425594, 'f_0_5_ged': 0.6080579279613813, 'accuracy_ner': 0.9805103908689566, 'f1_score_macro_ner': 0.8880480552793677, 'f1_score_weighted_ner': 0.9809991061137859, 'aes': 0.004814614497479938, 'ged': 0.15325454090322768, 'ner': 0.07074025242278974, 'total_loss': 0.22880940782349735, 'aes_weight_coef': 1.0, 'ged_weight_coef': 1.0, 'ner_weight_coef': 1.0}\n","some model info : ['aes', 'ged', 'ner']_distilroberta-base_lr4e-05\n","        bs8_freNone_share2\n","        outs{'aes': -1, 'ged': 4, 'ner': 4}_norm[40, 0]\n","        pri{'primary_task': 'aes', 'secondary_task': 'ged', 'aux_task': 'ner'}_optfixed\n","        scoscript_eslos\n","model saved to results/raw_results/ 1630831483\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["{'frozen_layers': None, 'lr': 4e-05, 'output_layer': -1, 'shared_encoder_n_layers': 0, 'tasks': ['aes', 'ged', 'ner']}\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["loading configuration file https://huggingface.co/distilroberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/42d6b7c87cbac84fcdf35aa69504a5ccfca878fcee2a1a9b9ff7a3d1297f9094.aa95727ac70adfa1aaf5c88bea30a4f5e50869c68e68bce96ef1ec41b5facf46\n","Model config RobertaConfig {\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"LABEL_0\": 0\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 6,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.10.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading weights file https://huggingface.co/distilroberta-base/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/7a0115a4c463f49bc7ab011872fc4a4b81be681a0434075955d29ac3388e225b.a6127d76576e81475313180aceb31a8688f7a649b80e380d26b5d30302dc83c1\n","Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight']\n","- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","loading configuration file https://huggingface.co/distilroberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/42d6b7c87cbac84fcdf35aa69504a5ccfca878fcee2a1a9b9ff7a3d1297f9094.aa95727ac70adfa1aaf5c88bea30a4f5e50869c68e68bce96ef1ec41b5facf46\n","Model config RobertaConfig {\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 6,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.10.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading configuration file https://huggingface.co/distilroberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/42d6b7c87cbac84fcdf35aa69504a5ccfca878fcee2a1a9b9ff7a3d1297f9094.aa95727ac70adfa1aaf5c88bea30a4f5e50869c68e68bce96ef1ec41b5facf46\n","Model config RobertaConfig {\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\",\n","    \"3\": \"LABEL_3\",\n","    \"4\": \"LABEL_4\",\n","    \"5\": \"LABEL_5\",\n","    \"6\": \"LABEL_6\",\n","    \"7\": \"LABEL_7\",\n","    \"8\": \"LABEL_8\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2,\n","    \"LABEL_3\": 3,\n","    \"LABEL_4\": 4,\n","    \"LABEL_5\": 5,\n","    \"LABEL_6\": 6,\n","    \"LABEL_7\": 7,\n","    \"LABEL_8\": 8\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 6,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.10.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","***** Running training *****\n","  Num examples = 2114\n","  Num Epochs = 8\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 2120\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1855' max='2120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1855/2120 07:55 < 01:07, 3.90 it/s, Epoch 7/8]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>0.381900</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.239100</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.202800</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["aes_weight_coef : 1.0\n","ged_weight_coef : 1.0\n","ner_weight_coef : 1.0\n","\n","losses {'aes': 0.006901818522533705, 'ged': 0.10779153191766074, 'ner': 0.0494878853909498, 'total_loss': 0.16418123583114425}\n","\n","aes_metrics {'rmse_aes': 7.258137195972226, 'pearson_aes': 0.6227820675376955, 'spearman_aes': 0.6084518304500812, 'kappa_aes': 0.3147079521463758}\n","\n","ged               precision    recall  f1-score   support\n","\n","           0       0.94      0.84      0.89     25174\n","           1       0.38      0.65      0.48      3917\n","\n","    accuracy                           0.81     29091\n","   macro avg       0.66      0.74      0.68     29091\n","weighted avg       0.86      0.81      0.83     29091\n","\n","ged_metrics {'accuracy_ged': 0.8131037090509092, 'f1_score_macro_ged': 0.6843867135510301, 'f1_score_weighted_ged': 0.8316650628534809, 'f_0_5_ged': 0.5699784405318001}\n","\n","ner               precision    recall  f1-score   support\n","\n","           0  0.995679791 0.997146800 0.996412755     42759\n","           1  0.967914439 0.982627579 0.975215517      1842\n","           2  0.983895706 0.981637337 0.982765224      1307\n","           3  0.848214286 0.920954512 0.883089024      1341\n","           4  0.831847134 0.869507324 0.850260417       751\n","           5  0.932800000 0.952095808 0.942349138      1837\n","           6  0.801498127 0.832684825 0.816793893       257\n","           7  0.890445860 0.758134490 0.818980668       922\n","           8  0.909090909 0.520231214 0.661764706       346\n","\n","    accuracy                      0.982438379     51362\n","   macro avg  0.906820695 0.868335543 0.880847927     51362\n","weighted avg  0.982445582 0.982438379 0.981937702     51362\n","\n","ner_metrics {'accuracy_ner': 0.9824383785678128, 'f1_score_macro_ner': 0.8808479268737179, 'f1_score_weighted_ner': 0.9819377018757466}\n","\n","epochs since best performance 0\n","\n","aes_weight_coef : 1.0\n","ged_weight_coef : 1.0\n","ner_weight_coef : 1.0\n","\n","losses {'aes': 0.003957730977860994, 'ged': 0.09921742178672968, 'ner': 0.03146693229588658, 'total_loss': 0.13464208506047726}\n","\n","aes_metrics {'rmse_aes': 5.50252467307306, 'pearson_aes': 0.6585313505356476, 'spearman_aes': 0.6459626144004058, 'kappa_aes': 0.4066243485563267}\n","\n","ged               precision    recall  f1-score   support\n","\n","           0       0.95      0.83      0.89     25174\n","           1       0.40      0.72      0.51      3917\n","\n","    accuracy                           0.82     29091\n","   macro avg       0.67      0.77      0.70     29091\n","weighted avg       0.88      0.82      0.84     29091\n","\n","ged_metrics {'accuracy_ged': 0.8163349489532845, 'f1_score_macro_ged': 0.6994872486092805, 'f1_score_weighted_ged': 0.8364129137808624, 'f_0_5_ged': 0.6175667342084398}\n","\n","ner               precision    recall  f1-score   support\n","\n","           0  0.996451417 0.998199210 0.997324548     42759\n","           1  0.987918726 0.976655809 0.982254982      1842\n","           2  0.991439689 0.974751339 0.983024691      1307\n","           3  0.914924297 0.946308725 0.930351906      1341\n","           4  0.911725955 0.921438083 0.916556291       751\n","           5  0.954907162 0.979858465 0.967221924      1837\n","           6  0.911196911 0.918287938 0.914728682       257\n","           7  0.937575030 0.847071584 0.890028490       922\n","           8  0.903010033 0.780346821 0.837209302       346\n","\n","    accuracy                      0.989116467     51362\n","   macro avg  0.945461024 0.926990886 0.935411202     51362\n","weighted avg  0.989051663 0.989116467 0.988996059     51362\n","\n","ner_metrics {'accuracy_ner': 0.9891164674272809, 'f1_score_macro_ner': 0.9354112018835319, 'f1_score_weighted_ner': 0.9889960591670423}\n","\n","epochs since best performance 0\n","\n","aes_weight_coef : 1.0\n","ged_weight_coef : 1.0\n","ner_weight_coef : 1.0\n","\n","losses {'aes': 0.002547483804614045, 'ged': 0.0953481232011041, 'ner': 0.0287739607332231, 'total_loss': 0.12666956773894125}\n","\n","aes_metrics {'rmse_aes': 4.428443418528808, 'pearson_aes': 0.6584907573475299, 'spearman_aes': 0.6586418231995793, 'kappa_aes': 0.6046294567855143}\n","\n","ged               precision    recall  f1-score   support\n","\n","           0       0.96      0.81      0.88     25174\n","           1       0.38      0.76      0.51      3917\n","\n","    accuracy                           0.80     29091\n","   macro avg       0.67      0.78      0.69     29091\n","weighted avg       0.88      0.80      0.83     29091\n","\n","ged_metrics {'accuracy_ged': 0.8034787391289402, 'f1_score_macro_ged': 0.6929869745635158, 'f1_score_weighted_ged': 0.8275688814720207, 'f_0_5_ged': 0.632962804617358}\n","\n","ner               precision    recall  f1-score   support\n","\n","           0  0.997079507 0.998058888 0.997568957     42759\n","           1  0.986361157 0.981541802 0.983945578      1842\n","           2  0.993044822 0.983167559 0.988081507      1307\n","           3  0.954927426 0.932140194 0.943396226      1341\n","           4  0.969740634 0.896138482 0.931487889       751\n","           5  0.973427332 0.977136636 0.975278457      1837\n","           6  0.921052632 0.953307393 0.936902486       257\n","           7  0.891327064 0.925162690 0.907929750       922\n","           8  0.821428571 0.864161850 0.842253521       346\n","\n","    accuracy                      0.990693509     51362\n","   macro avg  0.945376572 0.945646166 0.945204930     51362\n","weighted avg  0.990784174 0.990693509 0.990702163     51362\n","\n","ner_metrics {'accuracy_ner': 0.99069350881975, 'f1_score_macro_ner': 0.945204930231507, 'f1_score_weighted_ner': 0.9907021629446096}\n","\n","epochs since best performance 1\n","\n","aes_weight_coef : 1.0\n","ged_weight_coef : 1.0\n","ner_weight_coef : 1.0\n","\n","losses {'aes': 0.003691661626447079, 'ged': 0.09960510772328045, 'ner': 0.02808691425855423, 'total_loss': 0.13138368360828176}\n","\n","aes_metrics {'rmse_aes': 5.308536102877662, 'pearson_aes': 0.6619085947017269, 'spearman_aes': 0.6633774202747521, 'kappa_aes': 0.5519417618222915}\n","\n","ged               precision    recall  f1-score   support\n","\n","           0       0.95      0.86      0.90     25174\n","           1       0.44      0.71      0.54      3917\n","\n","    accuracy                           0.84     29091\n","   macro avg       0.69      0.78      0.72     29091\n","weighted avg       0.88      0.84      0.85     29091\n","\n","ged_metrics {'accuracy_ged': 0.8369942593929394, 'f1_score_macro_ged': 0.7205437235219578, 'f1_score_weighted_ged': 0.8523605956136271, 'f_0_5_ged': 0.6311471694692472}\n","\n","ner               precision    recall  f1-score   support\n","\n","           0  0.997265269 0.997825019 0.997545066     42759\n","           1  0.986376022 0.982627579 0.984498232      1842\n","           2  0.990030675 0.987758225 0.988893144      1307\n","           3  0.961986036 0.924683072 0.942965779      1341\n","           4  0.975714286 0.909454061 0.941419711       751\n","           5  0.977111717 0.976047904 0.976579521      1837\n","           6  0.929104478 0.968871595 0.948571429       257\n","           7  0.871097684 0.938177874 0.903394256       922\n","           8  0.850704225 0.872832370 0.861626248       346\n","\n","    accuracy                      0.990985554     51362\n","   macro avg  0.948821154 0.950919744 0.949499265     51362\n","weighted avg  0.991140432 0.990985554 0.991010737     51362\n","\n","ner_metrics {'accuracy_ner': 0.9909855535220591, 'f1_score_macro_ner': 0.9494992650664149, 'f1_score_weighted_ner': 0.9910107370836524}\n","\n","epochs since best performance 0\n","\n","aes_weight_coef : 1.0\n","ged_weight_coef : 1.0\n","ner_weight_coef : 1.0\n","\n","losses {'aes': 0.004281043313270391, 'ged': 0.10079328057377837, 'ner': 0.027602372745181934, 'total_loss': 0.1326766966322307}\n","\n","aes_metrics {'rmse_aes': 5.676462121975467, 'pearson_aes': 0.6689628883097604, 'spearman_aes': 0.6710102976507533, 'kappa_aes': 0.5217832636323034}\n","\n","ged               precision    recall  f1-score   support\n","\n","           0       0.95      0.86      0.90     25174\n","           1       0.44      0.72      0.55      3917\n","\n","    accuracy                           0.84     29091\n","   macro avg       0.70      0.79      0.73     29091\n","weighted avg       0.88      0.84      0.85     29091\n","\n","ged_metrics {'accuracy_ged': 0.8398817503695301, 'f1_score_macro_ged': 0.7253686333462162, 'f1_score_weighted_ged': 0.8549510303951693, 'f_0_5_ged': 0.6401595865258195}\n","\n","ner               precision    recall  f1-score   support\n","\n","           0  0.997591995 0.997941954 0.997766944     42759\n","           1  0.984230560 0.982627579 0.983428416      1842\n","           2  0.989280245 0.988523336 0.988901646      1307\n","           3  0.948545861 0.948545861 0.948545861      1341\n","           4  0.964187328 0.932090546 0.947867299       751\n","           5  0.973997833 0.978769733 0.976377953      1837\n","           6  0.897163121 0.984435798 0.938775510       257\n","           7  0.918478261 0.916485900 0.917480999       922\n","           8  0.893292683 0.846820809 0.869436202       346\n","\n","    accuracy                      0.991666991     51362\n","   macro avg  0.951863099 0.952915724 0.952064537     51362\n","weighted avg  0.991663174 0.991666991 0.991646523     51362\n","\n","ner_metrics {'accuracy_ner': 0.9916669911607804, 'f1_score_macro_ner': 0.9520645365658204, 'f1_score_weighted_ner': 0.9916465226188848}\n","\n","epochs since best performance 0\n","\n","aes_weight_coef : 1.0\n","ged_weight_coef : 1.0\n","ner_weight_coef : 1.0\n","\n","losses {'aes': 0.0035227001752964286, 'ged': 0.10795568518860396, 'ner': 0.027523996947376533, 'total_loss': 0.13900238231127693}\n","\n","aes_metrics {'rmse_aes': 5.158595846847387, 'pearson_aes': 0.6489108770520691, 'spearman_aes': 0.6640032197641317, 'kappa_aes': 0.5842969041402462}\n","\n","ged               precision    recall  f1-score   support\n","\n","           0       0.95      0.88      0.91     25174\n","           1       0.47      0.69      0.56      3917\n","\n","    accuracy                           0.85     29091\n","   macro avg       0.71      0.79      0.74     29091\n","weighted avg       0.88      0.85      0.87     29091\n","\n","ged_metrics {'accuracy_ged': 0.854353580145062, 'f1_score_macro_ged': 0.7372725178203765, 'f1_score_weighted_ged': 0.8654286528273714, 'f_0_5_ged': 0.6341611427504436}\n","\n","ner               precision    recall  f1-score   support\n","\n","           0  0.997684969 0.997801632 0.997743297     42759\n","           1  0.985302123 0.982627579 0.983963033      1842\n","           2  0.988523336 0.988523336 0.988523336      1307\n","           3  0.957239310 0.951528710 0.954375467      1341\n","           4  0.964432285 0.938748336 0.951417004       751\n","           5  0.978189749 0.976592270 0.977390357      1837\n","           6  0.925925926 0.972762646 0.948766603       257\n","           7  0.905520170 0.925162690 0.915236052       922\n","           8  0.875000000 0.869942197 0.872463768       346\n","\n","    accuracy                      0.991900627     51362\n","   macro avg  0.953090874 0.955965488 0.954430991     51362\n","weighted avg  0.991928308 0.991900627 0.991906788     51362\n","\n","ner_metrics {'accuracy_ner': 0.9919006269226276, 'f1_score_macro_ner': 0.9544309908710166, 'f1_score_weighted_ner': 0.9919067876468457}\n","\n","epochs since best performance 1\n","\n","aes_weight_coef : 1.0\n","ged_weight_coef : 1.0\n","ner_weight_coef : 1.0\n","\n","losses {'aes': 0.004896512406683246, 'ged': 0.1251930871675181, 'ner': 0.027838817727210564, 'total_loss': 0.15792841730141188}\n","\n","aes_metrics {'rmse_aes': 6.121455890735652, 'pearson_aes': 0.6604392927990116, 'spearman_aes': 0.6695868248109432, 'kappa_aes': 0.507273514576287}\n","\n","ged               precision    recall  f1-score   support\n","\n","           0       0.94      0.91      0.92     25174\n","           1       0.52      0.64      0.57      3917\n","\n","    accuracy                           0.87     29091\n","   macro avg       0.73      0.77      0.75     29091\n","weighted avg       0.88      0.87      0.88     29091\n","\n","ged_metrics {'accuracy_ged': 0.8713004021862432, 'f1_score_macro_ged': 0.747712120719373, 'f1_score_weighted_ged': 0.8767389906737593, 'f_0_5_ged': 0.6086128607001611}\n","\n","ner               precision    recall  f1-score   support\n","\n","           0  0.997475574 0.998012114 0.997743772     42759\n","           1  0.985294118 0.982084691 0.983686786      1842\n","           2  0.987776929 0.989288447 0.988532110      1307\n","           3  0.948698885 0.951528710 0.950111690      1341\n","           4  0.965564738 0.933422104 0.949221395       751\n","           5  0.978177851 0.976047904 0.977111717      1837\n","           6  0.926199262 0.976653696 0.950757576       257\n","           7  0.912809473 0.919739696 0.916261480       922\n","           8  0.885196375 0.846820809 0.865583456       346\n","\n","    accuracy                      0.991744870     51362\n","   macro avg  0.954132578 0.952622019 0.953223331     51362\n","weighted avg  0.991728764 0.991744870 0.991726128     51362\n","\n","ner_metrics {'accuracy_ner': 0.9917448697480628, 'f1_score_macro_ner': 0.9532233313812145, 'f1_score_weighted_ner': 0.9917261282673869}\n","\n","epochs since best performance 2\n","\n","\n","test results {'rmse_aes': 5.251983752196243, 'pearson_aes': 0.7741527429317344, 'spearman_aes': 0.7717306476684351, 'kappa_aes': 0.6115833168610398, 'accuracy_ged': 0.8543219772879092, 'f1_score_macro_ged': 0.733783205108095, 'f1_score_weighted_ged': 0.8586394125619509, 'f_0_5_ged': 0.5803022015588678, 'accuracy_ner': 0.9808764940239044, 'f1_score_macro_ner': 0.8876301312961363, 'f1_score_weighted_ner': 0.981411617204632, 'aes': 0.004939785737189509, 'ged': 0.1979340882528396, 'ner': 0.07329511349754673, 'total_loss': 0.27616898748757585, 'aes_weight_coef': 1.0, 'ged_weight_coef': 1.0, 'ner_weight_coef': 1.0}\n","some model info : ['aes', 'ged', 'ner']_distilroberta-base_lr4e-05\n","        bs8_freNone_share0\n","        outs{'aes': -1, 'ged': -1, 'ner': -1}_norm[40, 0]\n","        pri{'primary_task': 'aes', 'secondary_task': 'ged', 'aux_task': 'ner'}_optfixed\n","        scoscript_eslos\n","model saved to results/raw_results/ 1630831962\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["{'frozen_layers': None, 'lr': 4e-05, 'output_layer': -1, 'shared_encoder_n_layers': 1, 'tasks': ['aes', 'ged', 'ner']}\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["loading configuration file https://huggingface.co/distilroberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/42d6b7c87cbac84fcdf35aa69504a5ccfca878fcee2a1a9b9ff7a3d1297f9094.aa95727ac70adfa1aaf5c88bea30a4f5e50869c68e68bce96ef1ec41b5facf46\n","Model config RobertaConfig {\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"LABEL_0\": 0\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 6,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.10.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading weights file https://huggingface.co/distilroberta-base/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/7a0115a4c463f49bc7ab011872fc4a4b81be681a0434075955d29ac3388e225b.a6127d76576e81475313180aceb31a8688f7a649b80e380d26b5d30302dc83c1\n","Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight']\n","- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","loading configuration file https://huggingface.co/distilroberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/42d6b7c87cbac84fcdf35aa69504a5ccfca878fcee2a1a9b9ff7a3d1297f9094.aa95727ac70adfa1aaf5c88bea30a4f5e50869c68e68bce96ef1ec41b5facf46\n","Model config RobertaConfig {\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 1,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.10.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading weights file https://huggingface.co/distilroberta-base/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/7a0115a4c463f49bc7ab011872fc4a4b81be681a0434075955d29ac3388e225b.a6127d76576e81475313180aceb31a8688f7a649b80e380d26b5d30302dc83c1\n","Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaModel: ['roberta.encoder.layer.4.attention.output.dense.weight', 'roberta.encoder.layer.1.output.LayerNorm.bias', 'roberta.encoder.layer.1.attention.self.query.bias', 'roberta.encoder.layer.5.attention.self.key.bias', 'roberta.encoder.layer.2.attention.self.query.bias', 'lm_head.layer_norm.bias', 'roberta.encoder.layer.4.intermediate.dense.bias', 'lm_head.dense.weight', 'roberta.encoder.layer.5.attention.self.value.weight', 'roberta.encoder.layer.1.intermediate.dense.weight', 'roberta.encoder.layer.1.output.LayerNorm.weight', 'roberta.encoder.layer.5.attention.self.key.weight', 'roberta.encoder.layer.3.attention.self.key.bias', 'roberta.encoder.layer.1.output.dense.weight', 'roberta.encoder.layer.2.attention.self.key.bias', 'roberta.encoder.layer.4.intermediate.dense.weight', 'roberta.encoder.layer.3.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.output.dense.bias', 'roberta.encoder.layer.5.attention.self.query.weight', 'roberta.encoder.layer.3.attention.output.LayerNorm.bias', 'roberta.encoder.layer.3.attention.self.value.bias', 'roberta.encoder.layer.5.attention.output.LayerNorm.weight', 'roberta.encoder.layer.2.output.dense.weight', 'roberta.encoder.layer.4.attention.self.key.weight', 'roberta.encoder.layer.3.attention.output.dense.weight', 'roberta.encoder.layer.2.attention.self.value.bias', 'roberta.encoder.layer.5.attention.self.value.bias', 'roberta.encoder.layer.2.attention.self.query.weight', 'roberta.encoder.layer.3.attention.self.query.bias', 'roberta.encoder.layer.5.intermediate.dense.bias', 'roberta.encoder.layer.1.attention.self.key.weight', 'roberta.encoder.layer.3.attention.self.key.weight', 'lm_head.bias', 'roberta.encoder.layer.3.attention.output.dense.bias', 'roberta.encoder.layer.4.output.LayerNorm.bias', 'roberta.encoder.layer.5.intermediate.dense.weight', 'roberta.encoder.layer.1.attention.output.dense.weight', 'roberta.encoder.layer.1.attention.output.dense.bias', 'roberta.encoder.layer.1.attention.output.LayerNorm.bias', 'roberta.encoder.layer.4.attention.self.value.weight', 'roberta.encoder.layer.2.output.LayerNorm.bias', 'roberta.encoder.layer.1.attention.self.value.weight', 'roberta.encoder.layer.5.output.LayerNorm.bias', 'roberta.encoder.layer.3.output.dense.bias', 'roberta.encoder.layer.4.attention.output.LayerNorm.bias', 'roberta.encoder.layer.4.output.dense.weight', 'roberta.encoder.layer.4.attention.self.query.weight', 'roberta.encoder.layer.4.attention.self.key.bias', 'roberta.encoder.layer.3.output.LayerNorm.bias', 'roberta.encoder.layer.4.output.dense.bias', 'roberta.encoder.layer.3.attention.self.query.weight', 'roberta.encoder.layer.3.output.dense.weight', 'roberta.encoder.layer.1.attention.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.output.LayerNorm.weight', 'roberta.encoder.layer.5.output.dense.weight', 'roberta.encoder.layer.2.output.LayerNorm.weight', 'roberta.encoder.layer.5.attention.output.dense.weight', 'roberta.encoder.layer.1.attention.self.key.bias', 'roberta.encoder.layer.3.intermediate.dense.weight', 'roberta.encoder.layer.2.attention.self.key.weight', 'roberta.encoder.layer.5.attention.output.LayerNorm.bias', 'roberta.encoder.layer.3.attention.output.LayerNorm.weight', 'roberta.encoder.layer.5.attention.self.query.bias', 'lm_head.decoder.weight', 'roberta.encoder.layer.2.intermediate.dense.bias', 'roberta.encoder.layer.5.output.LayerNorm.weight', 'roberta.encoder.layer.4.attention.self.value.bias', 'roberta.encoder.layer.2.attention.output.LayerNorm.weight', 'roberta.encoder.layer.2.attention.output.dense.weight', 'lm_head.dense.bias', 'roberta.encoder.layer.2.attention.output.LayerNorm.bias', 'roberta.encoder.layer.3.attention.self.value.weight', 'roberta.encoder.layer.2.attention.self.value.weight', 'roberta.encoder.layer.1.attention.self.value.bias', 'roberta.encoder.layer.5.attention.output.dense.bias', 'lm_head.layer_norm.weight', 'roberta.encoder.layer.2.attention.output.dense.bias', 'roberta.encoder.layer.4.attention.self.query.bias', 'roberta.encoder.layer.2.output.dense.bias', 'roberta.encoder.layer.2.intermediate.dense.weight', 'roberta.encoder.layer.5.output.dense.bias', 'roberta.encoder.layer.4.output.LayerNorm.weight', 'roberta.encoder.layer.1.attention.self.query.weight', 'roberta.encoder.layer.3.intermediate.dense.bias', 'roberta.encoder.layer.1.intermediate.dense.bias', 'roberta.encoder.layer.1.output.dense.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the weights of RobertaModel were initialized from the model checkpoint at distilroberta-base.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaModel for predictions without further training.\n","loading configuration file https://huggingface.co/distilroberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/42d6b7c87cbac84fcdf35aa69504a5ccfca878fcee2a1a9b9ff7a3d1297f9094.aa95727ac70adfa1aaf5c88bea30a4f5e50869c68e68bce96ef1ec41b5facf46\n","Model config RobertaConfig {\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 6,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.10.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","loading configuration file https://huggingface.co/distilroberta-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/42d6b7c87cbac84fcdf35aa69504a5ccfca878fcee2a1a9b9ff7a3d1297f9094.aa95727ac70adfa1aaf5c88bea30a4f5e50869c68e68bce96ef1ec41b5facf46\n","Model config RobertaConfig {\n","  \"architectures\": [\n","    \"RobertaForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": null,\n","  \"eos_token_id\": 2,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\",\n","    \"3\": \"LABEL_3\",\n","    \"4\": \"LABEL_4\",\n","    \"5\": \"LABEL_5\",\n","    \"6\": \"LABEL_6\",\n","    \"7\": \"LABEL_7\",\n","    \"8\": \"LABEL_8\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2,\n","    \"LABEL_3\": 3,\n","    \"LABEL_4\": 4,\n","    \"LABEL_5\": 5,\n","    \"LABEL_6\": 6,\n","    \"LABEL_7\": 7,\n","    \"LABEL_8\": 8\n","  },\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 514,\n","  \"model_type\": \"roberta\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 6,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 1,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.10.0\",\n","  \"type_vocab_size\": 1,\n","  \"use_cache\": true,\n","  \"vocab_size\": 50265\n","}\n","\n","***** Running training *****\n","  Num examples = 2114\n","  Num Epochs = 8\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 2120\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='988' max='2120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 988/2120 04:45 < 05:27, 3.46 it/s, Epoch 3.72/8]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>0.384500</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["aes_weight_coef : 1.0\n","ged_weight_coef : 1.0\n","ner_weight_coef : 1.0\n","\n","losses {'aes': 0.0037696647652706436, 'ged': 0.11997245633324911, 'ner': 0.04723094620330389, 'total_loss': 0.17097306730182366}\n","\n","aes_metrics {'rmse_aes': 5.381294763654314, 'pearson_aes': 0.5512287341264823, 'spearman_aes': 0.5548952201795083, 'kappa_aes': 0.3752124460713818}\n","\n","ged               precision    recall  f1-score   support\n","\n","           0       0.92      0.91      0.91     25174\n","           1       0.46      0.52      0.49      3917\n","\n","    accuracy                           0.85     29091\n","   macro avg       0.69      0.71      0.70     29091\n","weighted avg       0.86      0.85      0.86     29091\n","\n","ged_metrics {'accuracy_ged': 0.8542160805747482, 'f1_score_macro_ged': 0.7025750520363769, 'f1_score_weighted_ged': 0.8577567073242721, 'f_0_5_ged': 0.5079720976581964}\n","\n","ner               precision    recall  f1-score   support\n","\n","           0  0.995982810 0.997310508 0.996646217     42759\n","           1  0.979902227 0.979370250 0.979636166      1842\n","           2  0.985395849 0.980872226 0.983128834      1307\n","           3  0.854816825 0.939597315 0.895204263      1341\n","           4  0.830000000 0.884154461 0.856221792       751\n","           5  0.949675325 0.955362003 0.952510176      1837\n","           6  0.808270677 0.836575875 0.822179732       257\n","           7  0.921717172 0.791757050 0.851808635       922\n","           8  0.879464286 0.569364162 0.691228070       346\n","\n","    accuracy                      0.984210116     51362\n","   macro avg  0.911691686 0.881595983 0.892062654     51362\n","weighted avg  0.984310534 0.984210116 0.983881471     51362\n","\n","ner_metrics {'accuracy_ner': 0.984210116428488, 'f1_score_macro_ner': 0.892062654023925, 'f1_score_weighted_ner': 0.9838814712976254}\n","\n","epochs since best performance 0\n","\n","aes_weight_coef : 1.0\n","ged_weight_coef : 1.0\n","ner_weight_coef : 1.0\n","\n","losses {'aes': 0.005694416200005731, 'ged': 0.10985943120579388, 'ner': 0.032586830841420694, 'total_loss': 0.1481406782472203}\n","\n","aes_metrics {'rmse_aes': 6.584915421712804, 'pearson_aes': 0.622821087668539, 'spearman_aes': 0.6248674030952489, 'kappa_aes': 0.4003718963065592}\n","\n","ged               precision    recall  f1-score   support\n","\n","           0       0.94      0.89      0.91     25174\n","           1       0.47      0.62      0.53      3917\n","\n","    accuracy                           0.85     29091\n","   macro avg       0.70      0.76      0.72     29091\n","weighted avg       0.87      0.85      0.86     29091\n","\n","ged_metrics {'accuracy_ged': 0.8530473342270806, 'f1_score_macro_ged': 0.7230210110338189, 'f1_score_weighted_ged': 0.8616909664883222, 'f_0_5_ged': 0.5839311334289814}\n","\n","ner               precision    recall  f1-score   support\n","\n","           0  0.997172038 0.997825019 0.997498422     42759\n","           1  0.987348735 0.974484256 0.980874317      1842\n","           2  0.988434850 0.980872226 0.984639017      1307\n","           3  0.950540958 0.917225951 0.933586338      1341\n","           4  0.951590595 0.916111851 0.933514247       751\n","           5  0.936950904 0.986935220 0.961293743      1837\n","           6  0.906367041 0.941634241 0.923664122       257\n","           7  0.907449210 0.872017354 0.889380531       922\n","           8  0.822535211 0.843930636 0.833095578       346\n","\n","    accuracy                      0.989291694     51362\n","   macro avg  0.938709949 0.936781862 0.937505146     51362\n","weighted avg  0.989318180 0.989291694 0.989258117     51362\n","\n","ner_metrics {'accuracy_ner': 0.9892916942486664, 'f1_score_macro_ner': 0.9375051460750868, 'f1_score_weighted_ner': 0.9892581167555298}\n","\n","epochs since best performance 0\n","\n","aes_weight_coef : 1.0\n","ged_weight_coef : 1.0\n","ner_weight_coef : 1.0\n","\n","losses {'aes': 0.0038339971391440826, 'ged': 0.10828892505446146, 'ner': 0.029723444282142228, 'total_loss': 0.14184636647574778}\n","\n","aes_metrics {'rmse_aes': 5.444160990353692, 'pearson_aes': 0.6501819230113971, 'spearman_aes': 0.660545746849283, 'kappa_aes': 0.5249872158430571}\n","\n","ged               precision    recall  f1-score   support\n","\n","           0       0.94      0.89      0.91     25174\n","           1       0.47      0.66      0.55      3917\n","\n","    accuracy                           0.86     29091\n","   macro avg       0.71      0.77      0.73     29091\n","weighted avg       0.88      0.86      0.86     29091\n","\n","ged_metrics {'accuracy_ged': 0.8551785775669452, 'f1_score_macro_ged': 0.7317305443553518, 'f1_score_weighted_ged': 0.8647058581274628, 'f_0_5_ged': 0.6092476786052682}\n","\n","ner               precision    recall  f1-score   support\n","\n","           0  0.997612974 0.996959704 0.997286232     42759\n","           1  0.986361157 0.981541802 0.983945578      1842\n","           2  0.985474006 0.986228003 0.985850860      1307\n","           3  0.936201780 0.941088740 0.938638899      1341\n","           4  0.961538462 0.932090546 0.946585531       751\n","           5  0.969713359 0.976047904 0.972870320      1837\n","           6  0.961240310 0.964980545 0.963106796       257\n","           7  0.905331882 0.902386117 0.903856600       922\n","           8  0.798969072 0.895953757 0.844686649       346\n","\n","    accuracy                      0.990440403     51362\n","   macro avg  0.944715889 0.953030791 0.948536385     51362\n","weighted avg  0.990595156 0.990440403 0.990494839     51362\n","\n","ner_metrics {'accuracy_ner': 0.9904404034110821, 'f1_score_macro_ner': 0.9485363850405627, 'f1_score_weighted_ner': 0.9904948390705736}\n","\n","epochs since best performance 0\n","\n"]},{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1854' max='2120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1854/2120 08:58 < 01:17, 3.44 it/s, Epoch 6.99/8]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>0.384500</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.241900</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.203500</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["aes_weight_coef : 1.0\n","ged_weight_coef : 1.0\n","ner_weight_coef : 1.0\n","\n","losses {'aes': 0.003126571501800141, 'ged': 0.09568054870117543, 'ner': 0.02922817625560213, 'total_loss': 0.1280352964585777}\n","\n","aes_metrics {'rmse_aes': 4.873397172404482, 'pearson_aes': 0.6400987161843409, 'spearman_aes': 0.6576192098900012, 'kappa_aes': 0.5645848724214354}\n","\n","ged               precision    recall  f1-score   support\n","\n","           0       0.96      0.82      0.88     25174\n","           1       0.40      0.77      0.53      3917\n","\n","    accuracy                           0.81     29091\n","   macro avg       0.68      0.80      0.71     29091\n","weighted avg       0.88      0.81      0.84     29091\n","\n","ged_metrics {'accuracy_ged': 0.8140662060431061, 'f1_score_macro_ged': 0.7057519140399675, 'f1_score_weighted_ged': 0.8362015970490734, 'f_0_5_ged': 0.6502242152466369}\n","\n","ner               precision    recall  f1-score   support\n","\n","           0  0.997637758 0.997567764 0.997602760     42759\n","           1  0.983188720 0.984256243 0.983722192      1842\n","           2  0.984756098 0.988523336 0.986636121      1307\n","           3  0.948910594 0.941834452 0.945359281      1341\n","           4  0.969230769 0.922769640 0.945429741       751\n","           5  0.974428727 0.974959173 0.974693878      1837\n","           6  0.942965779 0.964980545 0.953846154       257\n","           7  0.907327586 0.913232104 0.910270270       922\n","           8  0.826666667 0.895953757 0.859916782       346\n","\n","    accuracy                      0.991141311     51362\n","   macro avg  0.948345855 0.953786335 0.950830798     51362\n","weighted avg  0.991227652 0.991141311 0.991165495     51362\n","\n","ner_metrics {'accuracy_ner': 0.9911413106966239, 'f1_score_macro_ner': 0.9508307976252603, 'f1_score_weighted_ner': 0.9911654946036688}\n","\n","epochs since best performance 1\n","\n","aes_weight_coef : 1.0\n","ged_weight_coef : 1.0\n","ner_weight_coef : 1.0\n","\n","losses {'aes': 0.0027128895934194672, 'ged': 0.10029707537140957, 'ner': 0.028731413429256444, 'total_loss': 0.13174137839408548}\n","\n","aes_metrics {'rmse_aes': 4.6022337571613585, 'pearson_aes': 0.6526184316242668, 'spearman_aes': 0.6606464447554814, 'kappa_aes': 0.6188136775994417}\n","\n","ged               precision    recall  f1-score   support\n","\n","           0       0.96      0.84      0.90     25174\n","           1       0.42      0.75      0.54      3917\n","\n","    accuracy                           0.83     29091\n","   macro avg       0.69      0.80      0.72     29091\n","weighted avg       0.88      0.83      0.85     29091\n","\n","ged_metrics {'accuracy_ged': 0.8295692825959919, 'f1_score_macro_ged': 0.7189862850871687, 'f1_score_weighted_ged': 0.8477967830895281, 'f_0_5_ged': 0.6510866197494799}\n","\n","ner               precision    recall  f1-score   support\n","\n","           0  0.997545754 0.998105662 0.997825630     42759\n","           1  0.989577619 0.979370250 0.984447476      1842\n","           2  0.990776326 0.986228003 0.988496933      1307\n","           3  0.935225619 0.958240119 0.946593002      1341\n","           4  0.970752089 0.928095872 0.948944860       751\n","           5  0.972899729 0.977136636 0.975013580      1837\n","           6  0.936329588 0.972762646 0.954198473       257\n","           7  0.916757941 0.907809111 0.912261580       922\n","           8  0.881656805 0.861271676 0.871345029       346\n","\n","    accuracy                      0.991647522     51362\n","   macro avg  0.954613497 0.952113331 0.953236285     51362\n","weighted avg  0.991650159 0.991647522 0.991633935     51362\n","\n","ner_metrics {'accuracy_ner': 0.9916475215139597, 'f1_score_macro_ner': 0.9532362847696754, 'f1_score_weighted_ner': 0.9916339346302235}\n","\n","epochs since best performance 0\n","\n","aes_weight_coef : 1.0\n","ged_weight_coef : 1.0\n","ner_weight_coef : 1.0\n","\n","losses {'aes': 0.00301313700782525, 'ged': 0.10769254592962044, 'ner': 0.028533194750157552, 'total_loss': 0.13923887768760324}\n","\n","aes_metrics {'rmse_aes': 4.8218253804964775, 'pearson_aes': 0.656306506544008, 'spearman_aes': 0.6617046911295797, 'kappa_aes': 0.5898123324396782}\n","\n","ged               precision    recall  f1-score   support\n","\n","           0       0.95      0.86      0.91     25174\n","           1       0.45      0.72      0.56      3917\n","\n","    accuracy                           0.84     29091\n","   macro avg       0.70      0.79      0.73     29091\n","weighted avg       0.89      0.84      0.86     29091\n","\n","ged_metrics {'accuracy_ged': 0.8443161115121516, 'f1_score_macro_ged': 0.7308577415389986, 'f1_score_weighted_ged': 0.8585464629769121, 'f_0_5_ged': 0.6461237132185478}\n","\n","ner               precision    recall  f1-score   support\n","\n","           0  0.997615430 0.997988728 0.997802044     42759\n","           1  0.987431694 0.980998914 0.984204793      1842\n","           2  0.989263804 0.986993114 0.988127154      1307\n","           3  0.952167414 0.950037286 0.951101157      1341\n","           4  0.965706447 0.937416778 0.951351351       751\n","           5  0.971891892 0.978769733 0.975318687      1837\n","           6  0.923076923 0.980544747 0.950943396       257\n","           7  0.910560345 0.916485900 0.913513514       922\n","           8  0.889552239 0.861271676 0.875183554       346\n","\n","    accuracy                      0.991803279     51362\n","   macro avg  0.954140687 0.954500764 0.954171739     51362\n","weighted avg  0.991800846 0.991803279 0.991792032     51362\n","\n","ner_metrics {'accuracy_ner': 0.9918032786885246, 'f1_score_macro_ner': 0.9541717389026488, 'f1_score_weighted_ner': 0.9917920324385411}\n","\n","epochs since best performance 0\n","\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-1281098a7af5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0mprev_task\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tasks'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1282\u001b[0m                         \u001b[0mtr_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1283\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1284\u001b[0;31m                     \u001b[0mtr_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1285\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_flos\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloating_point_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   1805\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepspeed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1806\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    147\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"KjNwpv3CSG89","executionInfo":{"status":"aborted","timestamp":1630768546274,"user_tz":-60,"elapsed":22,"user":{"displayName":"Cameron Stronge","photoUrl":"","userId":"13361440774782721572"}}},"source":[""],"execution_count":null,"outputs":[]}]}