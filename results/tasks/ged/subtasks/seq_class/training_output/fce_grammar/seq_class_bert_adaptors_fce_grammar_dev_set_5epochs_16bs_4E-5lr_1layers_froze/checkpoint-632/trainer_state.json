{
  "best_metric": 0.8472222222222222,
  "best_model_checkpoint": "results/tasks/ged/subtasks/seq_class//training_output/fce_grammar/seq_class_bert_adaptors_fce_grammar_dev_set_5epochs_16bs_4E-5lr_1layers_froze/checkpoint-316",
  "epoch": 2.0,
  "global_step": 632,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 1.0,
      "eval_accuracy": 0.7698744769874477,
      "eval_f1": 0.8472222222222222,
      "eval_loss": 0.45090213418006897,
      "step": 316,
      "train_accuracy": 0.7895569620253164,
      "train_f1": 0.8486486486486486,
      "train_loss": 0.43301111459732056
    },
    {
      "epoch": 1.58,
      "learning_rate": 2.7341772151898737e-05,
      "loss": 0.4805,
      "step": 500
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.7615062761506276,
      "eval_f1": 0.8251533742331288,
      "eval_loss": 0.48181912302970886,
      "step": 632,
      "train_accuracy": 0.7824367088607594,
      "train_f1": 0.8290863890615288,
      "train_loss": 0.4402145743370056
    }
  ],
  "max_steps": 1580,
  "num_train_epochs": 5,
  "total_flos": 430893118685184.0,
  "trial_name": null,
  "trial_params": null
}
