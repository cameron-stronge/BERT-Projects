{
  "best_metric": 0.8359133126934984,
  "best_model_checkpoint": "results/tasks/ged/subtasks/seq_class//training_output/fce_grammar/seq_class_bert_fce_grammar_dev_set_5epochs_16bs_4E-5lr_1layers_froze/checkpoint-632",
  "epoch": 2.0,
  "global_step": 632,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 1.0,
      "eval_accuracy": 0.7552301255230126,
      "eval_f1": 0.8157480314960631,
      "eval_loss": 0.45173999667167664,
      "step": 316,
      "train_accuracy": 0.8659018987341772,
      "train_f1": 0.896266829865361,
      "train_loss": 0.2945241630077362
    },
    {
      "epoch": 1.58,
      "learning_rate": 2.7341772151898737e-05,
      "loss": 0.4083,
      "step": 500
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.7782426778242678,
      "eval_f1": 0.8359133126934984,
      "eval_loss": 0.4962863624095917,
      "step": 632,
      "train_accuracy": 0.9497626582278481,
      "train_f1": 0.9628654970760233,
      "train_loss": 0.1403019279241562
    }
  ],
  "max_steps": 1580,
  "num_train_epochs": 5,
  "total_flos": 425126385844224.0,
  "trial_name": null,
  "trial_params": null
}
