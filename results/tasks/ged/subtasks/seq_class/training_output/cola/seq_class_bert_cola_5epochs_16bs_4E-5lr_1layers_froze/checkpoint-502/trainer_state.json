{
  "best_metric": 0.895483870967742,
  "best_model_checkpoint": "results/tasks/ged/subtasks/seq_class//training_output/cola/seq_class_bert_cola_5epochs_16bs_4E-5lr_1layers_froze/checkpoint-502",
  "epoch": 1.0,
  "global_step": 502,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 1.0,
      "learning_rate": 3.203187250996016e-05,
      "loss": 0.479,
      "step": 500
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.8462998102466793,
      "eval_f1": 0.895483870967742,
      "eval_loss": 0.38110587000846863,
      "step": 502,
      "train_accuracy": 0.9231056829511466,
      "train_f1": 0.9468790357296599,
      "train_loss": 0.21820060908794403
    }
  ],
  "max_steps": 2510,
  "num_train_epochs": 5,
  "total_flos": 337343168514048.0,
  "trial_name": null,
  "trial_params": null
}
