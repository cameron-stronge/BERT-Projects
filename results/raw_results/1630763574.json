{"best": {"ner": {"accuracy_ner": 0.016763365912542346, "f1_score_macro_ner": 0.016883011771703454, "f1_score_weighted_ner": 0.010696173150122055, "ner": 2.2695125088547217, "ner_weight_coef": 1.0}}, "train": {"loss": [2.2019], "learning_rate": [2.1203007518796993e-05], "epoch": [3.76], "step": [500]}, "eval": {"accuracy_ner": [0.015108445932790779, 0.015614656750126552, 0.016763365912542346, 0.015887231805615045, 0.015205794166893813], "f1_score_macro_ner": [0.015083243932050258, 0.015389261761070978, 0.016883011771703454, 0.015001929830145465, 0.014713108402412843], "f1_score_weighted_ner": [0.008679031704810524, 0.00975898340496965, 0.010696173150122055, 0.010310684972779288, 0.00967992547449719], "ner": [2.2693869200619785, 2.2690252246278706, 2.2695125088547217, 2.26914449894067, 2.2689765800129282], "total_loss": [2.2693869200619785, 2.2690252246278706, 2.2695125088547217, 2.26914449894067, 2.2689765800129282], "ner_weight_coef": [1.0, 1.0, 1.0, 1.0, 1.0], "epoch": [0.99, 1.99, 2.99, 3.99, 4.99], "step": [132, 265, 398, 531, 664]}, "test": {"accuracy_ner": 0.014278023042963281, "f1_score_macro_ner": 0.01426108167585254, "f1_score_weighted_ner": 0.009529312342050051, "ner": 2.2778315623601277, "total_loss": 2.2778315623601277, "ner_weight_coef": 1.0}, "info": {"tasks": ["ner"], "outputs": ["loss", "labels", "preds"], "map_out_to_task": {"ner_loss": "ner", "ner_labels": "ner", "ner_preds": "ner"}, "map_out_to_out": {"ner_loss": "loss", "ner_labels": "labels", "ner_preds": "preds"}, "map_task_index": {"ner": 0}, "map_index_task": {"0": "ner"}, "optimizer_weighting": "fixed", "epochs_to_avg_over": 2, "temp": 2, "init_task_weightings": {"aes": 1.0, "ged": 1.0, "ner": 1.0}, "metrics_to_track_by_task": {"aes": "pearson_aes", "ged": "f_0_5_ged", "ner": "f1_score_macro_ner"}, "regression_tasks": ["aes"], "classification_tasks": ["ner", "ged"], "fce_tasks": ["aes", "ged"], "task_priorities_priority_as_key": {"primary_task": "ner"}, "early_stopping_patience": 2, "early_stopping_metric": null, "pretrained_model": "distilroberta-base", "frozen_layers": 6, "scoring": "script", "shared_encoder_n_layers": 0, "normalised_values": [40, 0], "output_layer_by_task": {"aes": -1, "ged": -1, "ner": -1}, "save_results": true, "learning_rate": 4e-05, "batch_size": 8, "weight_decay": 0.01, "adam_epsilon": 1e-08, "runtime": 76.42703557014465, "steps_per_sec": 0.11510095718395279, "model_name": "1630763574"}, "preds": {}}